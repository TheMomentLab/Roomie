#!/usr/bin/env python3
"""
Button OCR Tool (Monitoring Screen Version)
- YOLO-based elevator button detection
- EasyOCR text reading (multiple preprocessing methods applied)
- Real-time preprocessing results monitoring screen
- Combined original video and preprocessing results display
- Automatic button_id mapping
"""

import cv2
import numpy as np
import time
import os
import sys
from typing import Optional, List, Tuple

# EasyOCR import
try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    EASYOCR_AVAILABLE = False
    print("EasyOCR is not installed. Please install it with: pip install easyocr")

# YOLO import
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("Ultralytics YOLO is not installed.")


class ButtonOCRTool:
    """Simple Button OCR Tool"""
    
    def __init__(self):
        self.cap = None
        self.yolo_model = None
        self.ocr_reader = None
        self.is_running = False
        
        # ì„¤ì •
        self.confidence_threshold = 0.5
        self.auto_mode = True
        self.last_test_time = 0
        self.test_interval = 1.0  # 1ì´ˆë§ˆë‹¤
        
        # YOLO í´ë˜ìŠ¤ (elevator ëª¨ë¸ ê¸°ì¤€)
        self.model_classes = ['button', 'direction_light', 'display', 'door']
        
        # ëª¨ë‹ˆí„°ë§ í™”ë©´ ì„¤ì •
        self.show_preprocessing = True
        self.current_button_rois = []  # í˜„ì¬ í”„ë ˆì„ì˜ ë²„íŠ¼ ROIë“¤
        self.preprocessed_results = []  # ì „ì²˜ë¦¬ ê²°ê³¼ë“¤
        
    def initialize(self) -> bool:
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("Initializing Button OCR Tool...")
        
        # 1. ì›¹ìº  ì´ˆê¸°í™”
        if not self._init_webcam():
            return False
        
        # 2. YOLO ëª¨ë¸ ì´ˆê¸°í™”
        if not self._init_yolo():
            return False
        
        # 3. EasyOCR ì´ˆê¸°í™”
        if not self._init_easyocr():
            return False
        
        self.is_running = True
        print("Initialization completed!")
        return True
    
    def _init_webcam(self) -> bool:
        """ì›¹ìº  ì´ˆê¸°í™”"""
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ì°¾ê¸°
            for camera_id in [0, 1, 2, 3]:
                cap = cv2.VideoCapture(camera_id)
                if cap.isOpened():
                    ret, frame = cap.read()
                    if ret and frame is not None:
                        self.cap = cap
                        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                        print(f"Webcam initialized successfully (ID: {camera_id})")
                        return True
                    cap.release()
            
            print("No available webcam found")
            return False
            
        except Exception as e:
            print(f"Webcam initialization failed: {e}")
            return False
    
    def _init_yolo(self) -> bool:
        """YOLO ëª¨ë¸ ì´ˆê¸°í™”"""
        if not YOLO_AVAILABLE:
            print("YOLO not available")
            return False
        
        try:
            # elevator ëª¨ë¸ ì°¾ê¸°
            model_paths = [
                "/home/jinhyuk2me/project_ws/Roomie/ros2_ws/src/roomie_vs/training/elevator/best.pt",
                "training/elevator/best.pt",
                "../training/elevator/best.pt"
            ]
            
            model_path = None
            for path in model_paths:
                if os.path.exists(path):
                    model_path = path
                    break
            
            if not model_path:
                print("Elevator model not found")
                return False
            
            self.yolo_model = YOLO(model_path)
            
            # GPU ì‚¬ìš© ì‹œë„
            try:
                self.yolo_model.to('cuda')
                print(f"YOLO model loaded (GPU): {model_path}")
            except:
                print(f"YOLO model loaded (CPU): {model_path}")
            
            return True
            
        except Exception as e:
            print(f"YOLO initialization failed: {e}")
            return False
    
    def _init_easyocr(self) -> bool:
        """EasyOCR ì´ˆê¸°í™”"""
        if not EASYOCR_AVAILABLE:
            return False
        
        try:
            print("Initializing EasyOCR... (This may take a while on first run)")
            self.ocr_reader = easyocr.Reader(['en', 'ko'])
            print("EasyOCR initialization completed")
            return True
            
        except Exception as e:
            print(f"EasyOCR initialization failed: {e}")
            return False
    
    def detect_buttons(self, image: np.ndarray) -> List[dict]:
        """ë²„íŠ¼ ê°ì²´ ê°ì§€"""
        try:
            if self.yolo_model is None:
                return []
            
            results = self.yolo_model(image, conf=self.confidence_threshold, verbose=False)
            
            buttons = []
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        cls_id = int(box.cls.cpu().numpy())
                        if cls_id < len(self.model_classes):
                            class_name = self.model_classes[cls_id]
                        else:
                            class_name = f"class_{cls_id}"
                        
                        # ë²„íŠ¼ë§Œ í•„í„°ë§
                        if class_name == 'button':
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            buttons.append({
                                'bbox': (int(x1), int(y1), int(x2-x1), int(y2-y1)),
                                'confidence': float(box.conf.cpu().numpy())
                            })
            
            return buttons
            
        except Exception as e:
            print(f"Button detection failed: {e}")
            return []
    
    def _preprocess_roi(self, roi: np.ndarray) -> List[np.ndarray]:
        """ROI ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì—¬ëŸ¬ ë²„ì „ ìƒì„±) - ì›í˜• ë²„íŠ¼ ê°ì§€ í¬í•¨"""
        processed_images = []
        
        # ì›í˜• ë²„íŠ¼ ê°ì§€
        circle_info = self._detect_circle_in_roi(roi)
        
        # 1. ì›ë³¸
        processed_images.append(('Original', roi))
        
        # 2. ì›í˜• ROI ì ìš©ëœ ì›ë³¸ (ê°ì§€ëœ ê²½ìš°ë§Œ)
        if circle_info:
            circular_roi = self._apply_circular_roi(roi, circle_info)
            processed_images.append(('Circular_ROI', circular_roi))
            
            # ì›í˜• ROIì— ëŒ€í•œ ì´ì§„í™” ì²˜ë¦¬ë“¤
            circular_binary_results = self._apply_circular_binarization(circular_roi)
            processed_images.extend(circular_binary_results)
        
        # 3. ê·¸ë ˆì´ìŠ¤ì¼€ì¼
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        processed_images.append(('Grayscale', gray))
        
        # 4. ê¸°ë³¸ ì´ì§„í™” ë°©ë²•ë“¤
        basic_binary_results = self._apply_basic_binarization(gray)
        processed_images.extend(basic_binary_results)
        
        # ìµœëŒ€ 8ê°œë§Œ ë°˜í™˜ (í™”ë©´ ê³µê°„ ê³ ë ¤)
        return processed_images[:8]
    
    def _apply_circular_binarization(self, circular_roi: np.ndarray) -> List[tuple]:
        """ì›í˜• ROIì— íŠ¹í™”ëœ ì´ì§„í™” ì²˜ë¦¬"""
        binary_results = []
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(circular_roi.shape) == 3:
            gray = cv2.cvtColor(circular_roi, cv2.COLOR_BGR2GRAY)
        else:
            gray = circular_roi.copy()
        
        # 1. Otsu ì´ì§„í™”
        try:
            _, otsu_binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            binary_results.append(('Otsu_Binary', otsu_binary))
        except:
            pass
        
        # 2. ë°˜ì „ + Otsu ì´ì§„í™” (í°ìƒ‰ ë°°ê²½ì— ê²€ì€ ê¸€ì”¨ë¡œ)
        try:
            inverted = cv2.bitwise_not(gray)
            _, inv_otsu = cv2.threshold(inverted, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            binary_results.append(('Inv_Otsu', inv_otsu))
        except:
            pass
        
        # 3. ì ì ì œê±° + Otsu (ìƒë‹¨ ì˜ì—­ë§Œ)
        try:
            top_region = self._extract_number_region(gray)
            _, top_otsu = cv2.threshold(top_region, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            binary_results.append(('Top_Otsu', top_otsu))
        except:
            pass
            
        # 4. ì ì ì œê±° + ë°˜ì „ Otsu (ìƒë‹¨ ì˜ì—­ë§Œ)
        try:
            top_region = self._extract_number_region(gray)
            top_inverted = cv2.bitwise_not(top_region)
            _, top_inv_otsu = cv2.threshold(top_inverted, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            binary_results.append(('Top_Inv_Otsu', top_inv_otsu))
        except:
            pass
        
        # 5. ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì ì ì œê±°
        try:
            braille_removed = self._remove_braille_noise(gray)
            _, morph_otsu = cv2.threshold(braille_removed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            binary_results.append(('Morph_Clean', morph_otsu))
        except:
            pass
        
        # 6. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ + ì ì‘ì  ì„ê³„ê°’
        try:
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            adaptive_gauss = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
            binary_results.append(('Blur_Adaptive', adaptive_gauss))
        except:
            pass
        
        return binary_results
    
    def _apply_basic_binarization(self, gray: np.ndarray) -> List[tuple]:
        """ê¸°ë³¸ ì´ì§„í™” ì²˜ë¦¬"""
        binary_results = []
        
        # 1. ì ì‘ì  ì„ê³„ê°’
        try:
            adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
            binary_results.append(('Adaptive', adaptive))
        except:
            pass
        
        # 2. ìƒ‰ìƒ ë°˜ì „
        try:
            inverted = cv2.bitwise_not(gray)
            binary_results.append(('Inverted', inverted))
        except:
            pass
        
        # 3. CLAHE (ëŒ€ë¹„ ê°œì„ )
        try:
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            clahe_img = clahe.apply(gray)
            binary_results.append(('CLAHE', clahe_img))
        except:
            pass
        
        return binary_results
    
    def _update_button_preprocessing(self, image: np.ndarray, buttons: List[dict]):
        """Update preprocessing results for detected buttons"""
        self.current_button_rois = []
        self.preprocessed_results = []
        
        for i, button in enumerate(buttons):
            x, y, w, h = button['bbox']
            roi = image[y:y+h, x:x+w]
            
            if roi.size > 0:
                # Save ROI
                self.current_button_rois.append(roi)
                
                # Save preprocessing results
                processed_images = self._preprocess_roi(roi)
                self.preprocessed_results.append({
                    'index': i,
                    'bbox': button['bbox'],
                    'confidence': button['confidence'],
                    'processed': processed_images
                })
    
    def _resize_for_display(self, image: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """Resize image for display"""
        target_w, target_h = target_size
        h, w = image.shape[:2]
        
        # Resize while maintaining aspect ratio
        scale = min(target_w / w, target_h / h)
        new_w = int(w * scale)
        new_h = int(h * scale)
        
        resized = cv2.resize(image, (new_w, new_h))
        
        # Add padding to center the image
        if len(image.shape) == 3:
            padded = np.zeros((target_h, target_w, 3), dtype=np.uint8)
        else:
            padded = np.zeros((target_h, target_w), dtype=np.uint8)
        
        y_offset = (target_h - new_h) // 2
        x_offset = (target_w - new_w) // 2
        
        if len(image.shape) == 3:
            padded[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
        else:
            padded[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
        
        return padded
    
    def _create_monitoring_display(self, main_frame: np.ndarray) -> np.ndarray:
        """Create simple display - just return main frame"""
        return main_frame
    
    def ocr_button(self, image: np.ndarray, bbox: tuple) -> Optional[dict]:
        """ë²„íŠ¼ ì˜ì—­ OCR (Otsu ë°©ë²• ìš°ì„  ì‹œë„)"""
        try:
            if self.ocr_reader is None:
                return None
            
            # ROI ì¶”ì¶œ
            x, y, w, h = bbox
            roi = image[y:y+h, x:x+w]
            
            if roi.size == 0:
                return None
            
            # ì›í˜• ROI ê°ì§€
            circle_info = self._detect_circle_in_roi(roi)
            
            best_result = None
            best_confidence = 0.0
            best_method = ""
            
            # 1ì°¨: ì›í˜• ROIê°€ ê°ì§€ëœ ê²½ìš° Otsu ë°©ë²•ë“¤ ìš°ì„  ì‹œë„
            if circle_info:
                circular_roi = self._apply_circular_roi(roi, circle_info)
                otsu_methods = self._get_otsu_processed_images(circular_roi)
                
                for method_name, processed_roi in otsu_methods:
                    try:
                        results = self.ocr_reader.readtext(processed_roi)
                        
                        if results:
                            current_best = max(results, key=lambda x: x[2])
                            text = current_best[1].strip()
                            confidence = current_best[2]
                            
                            if confidence > best_confidence and text:
                                best_confidence = confidence
                                best_result = text
                                best_method = method_name
                                
                    except Exception as e:
                        continue
                
                # Otsu ë°©ë²•ìœ¼ë¡œ ì¶©ë¶„íˆ ì¢‹ì€ ê²°ê³¼ê°€ ë‚˜ì™”ìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
                if best_confidence > 0.7:  # 70% ì´ìƒì´ë©´ ì¶©ë¶„íˆ ì¢‹ìŒ
                    return {
                        'text': best_result,
                        'confidence': best_confidence,
                        'method': best_method + '_priority'
                    }
            
            # 2ì°¨: ëª¨ë“  ì „ì²˜ë¦¬ ë°©ë²• ì‹œë„ (ë°±ì—…ìš©)
            processed_images = self._preprocess_roi(roi)
            
            for method_name, processed_roi in processed_images:
                try:
                    results = self.ocr_reader.readtext(processed_roi)
                    
                    if results:
                        current_best = max(results, key=lambda x: x[2])
                        text = current_best[1].strip()
                        confidence = current_best[2]
                        
                        if confidence > best_confidence and text:
                            best_confidence = confidence
                            best_result = text
                            best_method = method_name
                            
                except Exception as e:
                    continue
            
            if best_result:
                return {
                    'text': best_result,
                    'confidence': best_confidence,
                    'method': best_method
                }
            
            return None
            
        except Exception as e:
            print(f"OCR execution failed: {e}")
            return None
    
    def _get_otsu_processed_images(self, circular_roi: np.ndarray) -> List[tuple]:
        """Otsu ë°©ë²•ë“¤ë§Œ ì¶”ì¶œ (ì ì ì œê±° í¬í•¨)"""
        otsu_results = []
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(circular_roi.shape) == 3:
            gray = cv2.cvtColor(circular_roi, cv2.COLOR_BGR2GRAY)
        else:
            gray = circular_roi.copy()
        
        # 1. ì ì ì œê±° + Otsu ì´ì§„í™” (ìš°ì„ ìˆœìœ„ 1)
        try:
            top_region = self._extract_number_region(gray)
            _, top_otsu = cv2.threshold(top_region, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            otsu_results.append(('Top_Otsu', top_otsu))
        except:
            pass
        
        # 2. ì ì ì œê±° + ë°˜ì „ Otsu (ìš°ì„ ìˆœìœ„ 2)
        try:
            top_region = self._extract_number_region(gray)
            top_inverted = cv2.bitwise_not(top_region)
            _, top_inv_otsu = cv2.threshold(top_inverted, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            otsu_results.append(('Top_Inv_Otsu', top_inv_otsu))
        except:
            pass
        
        # 3. ëª¨í´ë¡œì§€ ì ì ì œê±° + Otsu (ìš°ì„ ìˆœìœ„ 3)
        try:
            braille_removed = self._remove_braille_noise(gray)
            _, morph_otsu = cv2.threshold(braille_removed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            otsu_results.append(('Morph_Clean', morph_otsu))
        except:
            pass
        
        # 4. ê¸°ë³¸ Otsu ì´ì§„í™” (ë°±ì—…ìš©)
        try:
            _, otsu_binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            otsu_results.append(('Otsu_Binary', otsu_binary))
        except:
            pass
        
        # 5. ê¸°ë³¸ ë°˜ì „ + Otsu ì´ì§„í™” (ë°±ì—…ìš©)
        try:
            inverted = cv2.bitwise_not(gray)
            _, inv_otsu = cv2.threshold(inverted, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            otsu_results.append(('Inv_Otsu', inv_otsu))
        except:
            pass
        
        return otsu_results
    
    def map_text_to_button_id(self, text: str) -> Optional[int]:
        """í…ìŠ¤íŠ¸ë¥¼ button_idë¡œ ë§¤í•‘"""
        if not text:
            return None
        
        text = text.strip().upper()
        
        # ì¸µìˆ˜ ë²„íŠ¼
        floor_mapping = {
            '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6,
            '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12,
            'B1': 13, 'B2': 14
        }
        
        # ë°©í–¥ ë²„íŠ¼
        direction_mapping = {
            'â–¼': 100, 'â†“': 100, 'DOWN': 100,
            'â–²': 101, 'â†‘': 101, 'UP': 101,
            'â—€': 102, 'OPEN': 102,
            'â–¶': 103, 'CLOSE': 103
        }
        
        # ë§¤í•‘ ì‹œë„
        if text in direction_mapping:
            return direction_mapping[text]
        
        if text in floor_mapping:
            return floor_mapping[text]
        
        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°
        try:
            num = int(text)
            if 1 <= num <= 12:
                return num
        except:
            pass
        
        return None
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        print("\n" + "="*50)
        print("Button OCR Tool Running")
        print("="*50)
        print("Keyboard Controls:")
        print("  SPACE: Manual OCR")
        print("  'a': Auto mode ON/OFF")
        print("  '+/-': Adjust confidence")
        print("  'q': Quit")
        print("="*50)
        
        try:
            while self.is_running:
                # í”„ë ˆì„ íšë“
                ret, frame = self.cap.read()
                if not ret:
                    continue
                
                # ë²„íŠ¼ ê°ì§€
                buttons = self.detect_buttons(frame)
                
                # ì‹œê°í™”
                display_frame = self._draw_buttons(frame, buttons)
                
                # ëª¨ë‹ˆí„°ë§ í™”ë©´ ìƒì„±
                final_display = self._create_monitoring_display(display_frame)
                
                # ìë™ ëª¨ë“œ OCR
                current_time = time.time()
                if (self.auto_mode and buttons and 
                    current_time - self.last_test_time > self.test_interval):
                    
                    self._process_buttons(frame, buttons)
                    self.last_test_time = current_time
                
                # í™”ë©´ ì¶œë ¥
                cv2.imshow('Button OCR Tool', final_display)
                
                # í‚¤ë³´ë“œ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if not self._handle_keyboard(key, frame, buttons):
                    break
                    
        except KeyboardInterrupt:
            print("\nUser interrupted")
        except Exception as e:
            print(f"Runtime error: {e}")
        finally:
            self.cleanup()
    
    def _draw_buttons(self, image: np.ndarray, buttons: List[dict]) -> np.ndarray:
        """ë²„íŠ¼ ì‹œê°í™” + OCR ê²°ê³¼ ì˜¤ë²„ë ˆì´"""
        display_image = image.copy()
        
        for i, button in enumerate(buttons):
            x, y, w, h = button['bbox']
            conf = button['confidence']
            
            # ë°”ìš´ë”©ë°•ìŠ¤ (ë§ˆì  íƒ€ìƒ‰)
            cv2.rectangle(display_image, (x, y), (x + w, y + h), (255, 0, 255), 2)
            
            # OCR ê²°ê³¼ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ ì˜¤ë²„ë ˆì´
            try:
                ocr_result = self.ocr_button(image, button['bbox'])
                if ocr_result:
                    text = ocr_result['text']
                    ocr_conf = ocr_result['confidence']
                    button_id = self.map_text_to_button_id(text)
                    
                    # OCR ê²°ê³¼ í‘œì‹œ (ë²„íŠ¼ ì¤‘ì•™ì— í° ê¸€ì”¨ë¡œ)
                    center_x = x + w // 2
                    center_y = y + h // 2
                    
                    # ë°°ê²½ ë°•ìŠ¤ (ë°˜íˆ¬ëª…)
                    overlay = display_image.copy()
                    cv2.rectangle(overlay, (x, y), (x + w, y + h), (0, 0, 0), -1)
                    cv2.addWeighted(overlay, 0.3, display_image, 0.7, 0, display_image)
                    
                    # ì¸ì‹ëœ ê¸€ì”¨ (ì¤‘ì•™, í° ê¸€ì”¨)
                    cv2.putText(display_image, f"{text}", 
                               (center_x - 15, center_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
                    
                    # Button ID (ì‘ì€ ê¸€ì”¨, ìš°ìƒë‹¨)
                    if button_id:
                        cv2.putText(display_image, f"ID:{button_id}", 
                                   (x + w - 40, y + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
                    
                    # OCR ì‹ ë¢°ë„ (ì‘ì€ ê¸€ì”¨, ì¢Œìƒë‹¨)
                    cv2.putText(display_image, f"{ocr_conf:.2f}", 
                               (x + 5, y + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
                else:
                    # OCR ì‹¤íŒ¨ì‹œ
                    center_y = y + h // 2
                    cv2.putText(display_image, "?", 
                               (x + w//2 - 10, center_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)
            except:
                pass
            
            # ë²„íŠ¼ ë²ˆí˜¸ (ì¢Œí•˜ë‹¨)
            cv2.putText(display_image, f"#{i+1}", 
                       (x, y + h - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
        
        # ìƒíƒœ ì •ë³´ (ê°„ë‹¨í•˜ê²Œ)
        info_y = 30
        cv2.putText(display_image, f"Confidence: {self.confidence_threshold:.2f}", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        info_y += 25
        mode_text = "AUTO" if self.auto_mode else "MANUAL"
        cv2.putText(display_image, f"Mode: {mode_text}", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        info_y += 25
        cv2.putText(display_image, f"Buttons: {len(buttons)}", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return display_image
    
    def _handle_keyboard(self, key: int, frame: np.ndarray, buttons: List[dict]) -> bool:
        """í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬"""
        if key == ord('q'):
            return False
        
        elif key == ord(' '):  # SPACE
            if buttons:
                self._process_buttons(frame, buttons)
            else:
                print("No button detected")
        
        elif key == ord('a'):
            self.auto_mode = not self.auto_mode
            print(f"Auto mode: {'ON' if self.auto_mode else 'OFF'}")
        

        
        elif key == ord('+') or key == ord('='):
            self.confidence_threshold = min(0.95, self.confidence_threshold + 0.05)
            print(f"Confidence: {self.confidence_threshold:.2f}")
        
        elif key == ord('-'):
            self.confidence_threshold = max(0.1, self.confidence_threshold - 0.05)
            print(f"Confidence: {self.confidence_threshold:.2f}")
        
        return True
    
    def _process_buttons(self, image: np.ndarray, buttons: List[dict]):
        """ë²„íŠ¼ OCR ì²˜ë¦¬"""
        if not buttons:
            return
        
        print(f"\nProcessing OCR for {len(buttons)} buttons...")
        
        results = []
        for i, button in enumerate(buttons):
            bbox = button['bbox']
            conf = button['confidence']
            
            # OCR ì‹¤í–‰
            ocr_result = self.ocr_button(image, bbox)
            
            if ocr_result:
                text = ocr_result['text']
                ocr_conf = ocr_result['confidence']
                method = ocr_result.get('method', 'default')
                button_id = self.map_text_to_button_id(text)
                
                results.append({
                    'index': i + 1,
                    'text': text,
                    'button_id': button_id,
                    'detection_conf': conf,
                    'ocr_conf': ocr_conf,
                    'method': method
                })
            else:
                results.append({
                    'index': i + 1,
                    'text': '?',
                    'button_id': None,
                    'detection_conf': conf,
                    'ocr_conf': 0.0,
                    'method': 'failed'
                })
        
        # ê²°ê³¼ ì¶œë ¥ (ì¸µìˆ˜ ë²„íŠ¼ë§Œ)
        floor_results = [r for r in results if r['button_id'] is not None and 1 <= r['button_id'] <= 14]
        
        if floor_results:
            print("Floor button OCR results:")
            for result in floor_results:
                idx = result['index']
                text = result['text']
                btn_id = result['button_id']
                det_conf = result['detection_conf']
                ocr_conf = result['ocr_conf']
                method = result['method']
                
                print(f"  #{idx}: '{text}' -> button_id={btn_id} (detection:{det_conf:.2f}, OCR:{ocr_conf:.2f}, {method})")
        else:
            print("No floor button recognition results")
        
        print("-" * 40)
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.is_running = False
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        print("Cleanup completed")

    def _detect_circle_in_roi(self, roi: np.ndarray) -> Optional[tuple]:
        """ROIì—ì„œ ì›í˜• ë²„íŠ¼ ê°ì§€"""
        try:
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape) == 3 else roi
            
            # ë…¸ì´ì¦ˆ ì œê±°
            blurred = cv2.GaussianBlur(gray, (9, 9), 2)
            
            # HoughCirclesë¡œ ì› ê°ì§€
            circles = cv2.HoughCircles(
                blurred,
                cv2.HOUGH_GRADIENT,
                dp=1,
                minDist=max(roi.shape[0], roi.shape[1]) // 4,
                param1=50,
                param2=30,
                minRadius=min(roi.shape[0], roi.shape[1]) // 6,
                maxRadius=min(roi.shape[0], roi.shape[1]) // 2
            )
            
            if circles is not None:
                circles = np.round(circles[0, :]).astype("int")
                # ê°€ì¥ í° ì› ì„ íƒ (ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ë²„íŠ¼)
                if len(circles) > 0:
                    largest_circle = max(circles, key=lambda c: c[2])  # ë°˜ì§€ë¦„ ê¸°ì¤€
                    return tuple(largest_circle)  # (x, y, radius)
            
            return None
            
        except Exception as e:
            return None
    
    def _create_circular_mask(self, shape: tuple, center: tuple, radius: int) -> np.ndarray:
        """ì›í˜• ë§ˆìŠ¤í¬ ìƒì„±"""
        h, w = shape[:2]
        y, x = np.ogrid[:h, :w]
        cx, cy = center
        
        # ì›í˜• ë§ˆìŠ¤í¬ (í…Œë‘ë¦¬ ë§ì´ ì œê±°)
        mask_radius = max(1, int(radius * 0.75))  # ë°˜ì§€ë¦„ì˜ 65%ë§Œ ì‚¬ìš©
        mask = (x - cx) ** 2 + (y - cy) ** 2 <= mask_radius ** 2
        
        return mask.astype(np.uint8) * 255
    
    def _apply_circular_roi(self, roi: np.ndarray, circle_info: tuple) -> np.ndarray:
        """ì›í˜• ROI ì ìš©"""
        try:
            cx, cy, radius = circle_info
            
            # ì›í˜• ë§ˆìŠ¤í¬ ìƒì„±
            mask = self._create_circular_mask(roi.shape, (cx, cy), radius)
            
            # ê¸€ì”¨ ìƒ‰ìƒ ê°ì§€ (ë°ì€ ë¶€ë¶„ê³¼ ì–´ë‘ìš´ ë¶€ë¶„ ë¶„ì„)
            if len(roi.shape) == 3:
                gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
            else:
                gray_roi = roi.copy()
            
            # ë§ˆìŠ¤í¬ ì˜ì—­ ë‚´ë¶€ì—ì„œ ê¸€ì”¨ ìƒ‰ìƒ ê°ì§€
            button_area = gray_roi[mask > 0]
            if len(button_area) > 0:
                # ë°ì€ í”½ì…€(í°ìƒ‰ ê¸€ì”¨ í›„ë³´)ê³¼ ì–´ë‘ìš´ í”½ì…€ ë¹„ìœ¨ ê³„ì‚°
                bright_pixels = np.sum(button_area > 200)  # ë°ì€ í”½ì…€
                dark_pixels = np.sum(button_area < 100)    # ì–´ë‘ìš´ í”½ì…€
                total_pixels = len(button_area)
                
                bright_ratio = bright_pixels / total_pixels
                dark_ratio = dark_pixels / total_pixels
                
                # ê¸€ì”¨ê°€ í°ìƒ‰ì¸ì§€ ê²€ì€ìƒ‰ì¸ì§€ íŒë‹¨
                is_white_text = bright_ratio > 0.1 and bright_ratio > dark_ratio
            else:
                is_white_text = False  # ê¸°ë³¸ê°’
            
            # ê¸€ì”¨ë§Œ ì¶”ì¶œí•´ì„œ ë°°ê²½ ì„¤ì •
            if len(roi.shape) == 3:
                # ì»¬ëŸ¬ ì´ë¯¸ì§€ ì²˜ë¦¬
                gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
                
                if is_white_text:
                    # í°ìƒ‰ ê¸€ì”¨ ì¶”ì¶œ: ì ì‘í˜• ì´ì§„í™” ì‚¬ìš©
                    # ê°€ìš°ì‹œì•ˆ ì ì‘í˜• ì´ì§„í™” (í°ìƒ‰ ê¸€ì”¨ë¥¼ ìœ„í•´ THRESH_BINARY ì‚¬ìš©)
                    text_mask = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, -10)
                    text_mask = cv2.bitwise_and(text_mask, mask)  # ì›í˜• ë§ˆìŠ¤í¬ì™€ ê²°í•©
                    
                    # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ê¸€ì”¨ ë¹ˆ ê³µê°„ ì±„ìš°ê¸°
                    kernel = np.ones((3,3), np.uint8)
                    text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_CLOSE, kernel)  # êµ¬ë© ë©”ìš°ê¸°
                    text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_DILATE, kernel, iterations=1)  # ê¸€ì”¨ ë‘ê»ê²Œ
                    
                    # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (ê²€ì€ ë°°ê²½)
                    masked = np.zeros_like(roi)
                    masked[text_mask > 0] = [255, 255, 255]  # ê¸€ì”¨ëŠ” í°ìƒ‰
                else:
                    # ê²€ì€ìƒ‰ ê¸€ì”¨ ì¶”ì¶œ: ì ì‘í˜• ì´ì§„í™” ì‚¬ìš©
                    # ê°€ìš°ì‹œì•ˆ ì ì‘í˜• ì´ì§„í™” (ê²€ì€ìƒ‰ ê¸€ì”¨ë¥¼ ìœ„í•´ THRESH_BINARY_INV ì‚¬ìš©)
                    text_mask = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 10)
                    text_mask = cv2.bitwise_and(text_mask, mask)  # ì›í˜• ë§ˆìŠ¤í¬ì™€ ê²°í•©
                    
                    # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ê¸€ì”¨ ë¹ˆ ê³µê°„ ì±„ìš°ê¸°
                    kernel = np.ones((3,3), np.uint8)
                    text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_CLOSE, kernel)  # êµ¬ë© ë©”ìš°ê¸°
                    text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_DILATE, kernel, iterations=1)  # ê¸€ì”¨ ë‘ê»ê²Œ
                    
                    # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (í° ë°°ê²½)
                    masked = np.full_like(roi, [255, 255, 255])
                    masked[text_mask > 0] = [0, 0, 0]  # ê¸€ì”¨ëŠ” ê²€ì€ìƒ‰
            else:
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬
                if is_white_text:
                    # í°ìƒ‰ ê¸€ì”¨ ì¶”ì¶œ: ì ì‘í˜• ì´ì§„í™” ì‚¬ìš©
                    # ê°€ìš°ì‹œì•ˆ ì ì‘í˜• ì´ì§„í™” (í°ìƒ‰ ê¸€ì”¨ë¥¼ ìœ„í•´ THRESH_BINARY ì‚¬ìš©)
                    text_mask = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, -10)
                    text_mask = cv2.bitwise_and(text_mask, mask)  # ì›í˜• ë§ˆìŠ¤í¬ì™€ ê²°í•©
                    
                    # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ê¸€ì”¨ ë¹ˆ ê³µê°„ ì±„ìš°ê¸°
                    kernel = np.ones((3,3), np.uint8)
                    text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_CLOSE, kernel)  # êµ¬ë© ë©”ìš°ê¸°
                    text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_DILATE, kernel, iterations=1)  # ê¸€ì”¨ ë‘ê»ê²Œ
                    
                    # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (ê²€ì€ ë°°ê²½)
                    masked = np.zeros_like(gray_roi)
                    masked[text_mask > 0] = 255  # ê¸€ì”¨ëŠ” í°ìƒ‰
                else:
                    # ê²€ì€ìƒ‰ ê¸€ì”¨ ì¶”ì¶œ: ì ì‘í˜• ì´ì§„í™” ì‚¬ìš©
                    # ê°€ìš°ì‹œì•ˆ ì ì‘í˜• ì´ì§„í™” (ê²€ì€ìƒ‰ ê¸€ì”¨ë¥¼ ìœ„í•´ THRESH_BINARY_INV ì‚¬ìš©)
                    text_mask = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 10)
                    text_mask = cv2.bitwise_and(text_mask, mask)  # ì›í˜• ë§ˆìŠ¤í¬ì™€ ê²°í•©
                    
                    # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ê¸€ì”¨ ë¹ˆ ê³µê°„ ì±„ìš°ê¸°
                    kernel = np.ones((3,3), np.uint8)
                    text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_CLOSE, kernel)  # êµ¬ë© ë©”ìš°ê¸°
                    text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_DILATE, kernel, iterations=1)  # ê¸€ì”¨ ë‘ê»ê²Œ
                    
                    # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (í° ë°°ê²½)
                    masked = np.full_like(gray_roi, 255)
                    masked[text_mask > 0] = 0  # ê¸€ì”¨ëŠ” ê²€ì€ìƒ‰
            
            return masked
            
        except Exception as e:
            return roi

    def _extract_number_region(self, gray: np.ndarray) -> np.ndarray:
        """ìˆ«ì ì˜ì—­ë§Œ ì¶”ì¶œ (ìƒë‹¨ 60% ì˜ì—­)"""
        try:
            h, w = gray.shape
            # ë²„íŠ¼ì˜ ìƒë‹¨ 60% ì˜ì—­ë§Œ ì‚¬ìš© (ìˆ«ìëŠ” ë³´í†µ ìœ„ìª½ì— ìˆìŒ)
            top_region = gray[:int(h * 0.6), :]
            
            # í¬ê¸°ê°€ ë„ˆë¬´ ì‘ì•„ì§€ì§€ ì•Šë„ë¡ ìµœì†Œ í¬ê¸° ë³´ì¥
            if top_region.shape[0] < 20 or top_region.shape[1] < 20:
                return gray
            
            return top_region
        except:
            return gray
    
    def _remove_braille_noise(self, gray: np.ndarray) -> np.ndarray:
        """ì ì ë…¸ì´ì¦ˆ ì œê±°"""
        try:
            # 1. ì‘ì€ ì ë“¤ ì œê±°ë¥¼ ìœ„í•œ ëª¨í´ë¡œì§€ ì—°ì‚°
            kernel_small = np.ones((2, 2), np.uint8)
            
            # Opening ì—°ì‚°ìœ¼ë¡œ ì‘ì€ ì ë“¤ ì œê±°
            opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel_small)
            
            # 2. í° êµ¬ì¡°ë¬¼(ìˆ«ì) ë³´ì¡´ì„ ìœ„í•œ Closing
            kernel_large = np.ones((3, 3), np.uint8)
            cleaned = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel_large)
            
            # 3. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ì ìì˜ ì‘ì€ íŠ¹ì§• ì œê±°
            blurred = cv2.GaussianBlur(cleaned, (3, 3), 0)
            
            return blurred
        except:
            return gray


def main():
    if not EASYOCR_AVAILABLE or not YOLO_AVAILABLE:
        print("âŒ Required libraries are not installed")
        return -1
    
    print("ğŸš€ Button OCR Tool")
    print("   - EasyOCR + YOLO based button detection and OCR")
    print("   - Real-time OCR results overlay on original video")
    print("   - Automatic button_id mapping")
    
    tool = ButtonOCRTool()
    
    if not tool.initialize():
        print("âŒ Initialization failed")
        return -1
    
    tool.run()
    print("âœ… Program ended")
    return 0


if __name__ == "__main__":
    exit(main()) 