"""
PersonTracker: DeepSORT + YOLOv8n ê¸°ë°˜ ì‚¬ëŒ ì¶”ì  ëª¨ë“ˆ
ê¸°ì¡´ roomie_vs ì¸í„°í˜ì´ìŠ¤ (/vs/tracking, /vs/action/enroll ë“±)ì™€ ì™„ì „ í˜¸í™˜
"""

import numpy as np
import cv2
import time
import threading
from collections import deque
from typing import Optional, Dict, List, Any, Tuple
import rclpy
from rclpy.node import Node
from roomie_msgs.msg import Tracking

try:
    from deep_sort_realtime.deepsort_tracker import DeepSort
    DEEPSORT_AVAILABLE = True
except ImportError:
    print("Warning: DeepSort not available. Install with: pip install deep-sort-realtime")
    DEEPSORT_AVAILABLE = False


class PersonTracker:
    """
    ì‚¬ëŒ ì¶”ì  ëª¨ë“ˆ - vs_nodeì™€ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘
    
    ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜:
    - ëª¨ë“œ 0: ëŒ€ê¸° (ë¹„í™œì„±)
    - ëª¨ë“œ 1: ë“±ë¡ ì¤€ë¹„
    - ëª¨ë“œ 2: ì¶”ì  í™œì„±
    """
    
    def __init__(self, vs_node: Node, yolo_model=None):
        self.vs_node = vs_node
        self.yolo_model = yolo_model
        self.logger = vs_node.get_logger()
        
        # ëª¨ë¸ë³„ person í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ë™ì  í•´ì„ (ê¸°ë³¸ 0)
        self.person_class_index = 0
        self._resolve_person_class_index()
        
        # ì¶”ì  ìƒíƒœ
        self.current_mode = 0
        self.target_registered = False
        self.target_id = None
        self.tracking_active = False
        
        # DeepSORT ì´ˆê¸°í™”
        if DEEPSORT_AVAILABLE:
            self.tracker = DeepSort(
                max_age=30,
                n_init=3,
                nms_max_overlap=0.5,
                max_cosine_distance=0.5
            )
        else:
            self.tracker = None
            self.logger.warning("DeepSORT not available, tracking disabled")
        
        # í”„ë ˆì„ ë²„í¼ (ìŠ¤ë ˆë“œ ì•ˆì „)
        self.frame_buffer = deque(maxlen=5)
        self.frame_lock = threading.Lock()
        
        # ë“±ë¡ ê´€ë ¨
        self.registration_candidates = []
        self.registration_start_time = None
        self.registration_duration = 3.0  # ê¸°ë³¸ 3ì´ˆ
        self.track_appearances = {}  # track_idë³„ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡
        
        # ì¶”ì  í†µê³„
        self.last_seen_time = None
        self.lost_count = 0
        self.reacquired_count = 0
        
        # ìƒ‰ìƒ ê¸°ë°˜ ì¶”ì ì„ ìœ„í•œ íƒ€ê²Ÿ íŠ¹ì„± ì €ì¥
        self.target_color_features = None  # Dict with color histograms
        self.target_bbox_features = None   # Last known bbox dimensions
        self.fallback_tracking_enabled = True  # YOLO í´ë°± ì¶”ì  í™œì„±í™”
        
        # bbox ê´€ë¦¬ (DeepSORT vs í´ë°±)
        self.deepsort_bbox = None  # DeepSORTì˜ ì •í™•í•œ bbox
        self.fallback_bbox = None  # í´ë°± ì¶”ì ì˜ YOLO bbox
        
        # ìƒíƒœ ì „í™˜ ê°ì§€ë¥¼ ìœ„í•œ ì´ì „ ìƒíƒœ ì €ì¥
        self.previous_tracking_state = None  # "tracking", "lost", None
        self.is_target_distant = False  # íƒ€ê²Ÿì´ ë©€ì–´ì§„ ìƒíƒœì¸ì§€ ì¶”ì 
        
        # í”„ë ˆì„ ê¸°ë°˜ ë³´ìˆ˜ì  íŒë‹¨ì„ ìœ„í•œ ì¹´ìš´í„°
        self.distant_frame_count = 0  # ë©€ì–´ì§ ì¡°ê±´ì„ ë§Œì¡±í•œ ì—°ì† í”„ë ˆì„ ìˆ˜
        self.normal_frame_count = 0   # ì •ìƒ ì¡°ê±´ì„ ë§Œì¡±í•œ ì—°ì† í”„ë ˆì„ ìˆ˜
        self.required_frames = 5      # ìƒíƒœ ë³€ê²½ì— í•„ìš”í•œ ì—°ì† í”„ë ˆì„ ìˆ˜
        
        # ROS í¼ë¸”ë¦¬ì…” (vs_node í†µí•´ í¼ë¸”ë¦¬ì‹œ)
        self.tracking_pub = vs_node.create_publisher(
            Tracking, 
            '/vs/tracking', 
            10
        )
        
        self.logger.info("PersonTracker ì´ˆê¸°í™” ì™„ë£Œ (DeepSORT)")
        
        # ì˜¤ë²„ë ˆì´ í‘œì‹œìš© ìµœê·¼ ê²€ì¶œ/ì¶”ì  ìƒíƒœ
        self.last_detections = []  # List[Tuple[x1,y1,x2,y2,conf]]
        self.last_tracks = []      # List[Tuple[x1,y1,x2,y2]]
        self.last_target_bbox = None  # Tuple[x1,y1,x2,y2] | None

    def _resolve_person_class_index(self):
        """YOLO ëª¨ë¸ì˜ namesì—ì„œ 'person' ê³„ì—´ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ ì„¤ì •"""
        if not self.yolo_model:
            self.person_class_index = 0
            return
        try:
            names = getattr(self.yolo_model, 'names', None)
            if names is None:
                self.person_class_index = 0
                self.logger.warning("YOLO ëª¨ë¸ namesê°€ ì—†ì–´ person ì¸ë±ìŠ¤ë¥¼ 0ìœ¼ë¡œ ì„¤ì •")
                return
            if isinstance(names, list):
                name_map = {i: n for i, n in enumerate(names)}
            elif isinstance(names, dict):
                name_map = names
            else:
                name_map = {}
            candidates = [k for k, v in name_map.items() if str(v).lower() in ("person", "people", "human")]
            if candidates:
                self.person_class_index = int(candidates[0])
                self.logger.info(f"person í´ë˜ìŠ¤ ì¸ë±ìŠ¤: {self.person_class_index} ({name_map[self.person_class_index]})")
            else:
                # ê¸°ë³¸ê°’ ìœ ì§€í•˜ë˜ ê²½ê³ 
                self.person_class_index = 0
                self.logger.warning("ëª¨ë¸ namesì— 'person'ì´ ì—†ì–´ ê¸°ë³¸ ì¸ë±ìŠ¤ 0 ì‚¬ìš©")
        except Exception as e:
            self.person_class_index = 0
            self.logger.warning(f"person ì¸ë±ìŠ¤ í•´ì„ ì‹¤íŒ¨, ê¸°ë³¸ 0 ì‚¬ìš©: {e}")
    
    def set_mode(self, mode_id: int):
        """ëª¨ë“œ ë³€ê²½ - vs_node.set_vs_mode_callbackì—ì„œ í˜¸ì¶œ"""
        prev_mode = self.current_mode
        self.current_mode = mode_id
        
        if mode_id == 1:  # ë“±ë¡ëª¨ë“œ
            self._prepare_registration()
        elif mode_id == 2:  # ì¶”ì ëª¨ë“œ
            self._start_tracking()
        else:  # ê¸°íƒ€ ëª¨ë“œ (0, 3, 4, 5, 6)
            self._stop_tracking()
        
        self.logger.info(f"PersonTracker ëª¨ë“œ ë³€ê²½: {prev_mode} â†’ {mode_id}")
    
    def push_frame(self, frame: np.ndarray, timestamp: float = None):
        """
        í›„ë°© ì¹´ë©”ë¼ í”„ë ˆì„ ì „ë‹¬
        vs_node._rear_camera_streaming_loopì—ì„œ í˜¸ì¶œ
        """
        if timestamp is None:
            timestamp = time.time()
        
        with self.frame_lock:
            self.frame_buffer.append((frame.copy(), timestamp))
        
        # í˜„ì¬ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬
        if self.current_mode == 1:  # ë“±ë¡ëª¨ë“œ
            self._process_registration_frame(frame, timestamp)
        elif self.current_mode == 2:  # ì¶”ì ëª¨ë“œ
            self._process_tracking_frame(frame, timestamp)
        else:
            # ëŒ€ê¸° ë“± ê¸°íƒ€ ëª¨ë“œì—ì„œë„ YOLOë¡œ ìƒì‹œ ê°ì§€ (ë””ë²„ê¹…/í™•ì¸ìš©)
            self._process_idle_detection_frame(frame, timestamp)

    def _process_idle_detection_frame(self, frame: np.ndarray, timestamp: float):
        """ëŒ€ê¸° ë“± ê¸°íƒ€ ëª¨ë“œì—ì„œì˜ ìƒì‹œ ê°ì§€ ì²˜ë¦¬ (YOLOë§Œ)"""
        detections = self._detect_persons(frame)
        
        # ë””ë²„ê¹…: ëŒ€ê¸°ëª¨ë“œ ê°ì§€ ê²°ê³¼ (ì£¼ê¸°ì ìœ¼ë¡œë§Œ)
        if not hasattr(self, '_idle_frame_count'):
            self._idle_frame_count = 0
        self._idle_frame_count += 1
        
        # 30í”„ë ˆì„ë§ˆë‹¤ í•œ ë²ˆì”© ë¡œê·¸ (ì•½ 2ì´ˆë§ˆë‹¤) - ê°„ì†Œí™”
        if self._idle_frame_count % 30 == 0:
            if detections.size > 0:
                self.logger.debug(f"ğŸ”µ ëŒ€ê¸°ëª¨ë“œ: {len(detections)}ëª… ê°ì§€")
            else:
                self.logger.debug("ğŸ”µ ëŒ€ê¸°ëª¨ë“œ: ê°ì§€ ì—†ìŒ")
        
        self.last_detections = [
            (float(x1), float(y1), float(x2), float(y2), float(conf))
            for x1, y1, x2, y2, conf, cls in detections
        ] if detections.size > 0 else []
        # íŠ¸ë™/íƒ€ê²Ÿì€ í‘œì‹œí•˜ì§€ ì•ŠìŒ
        self.last_tracks = []
        self.last_target_bbox = None
    
    def register_target(self, duration_sec: float = 3.0) -> Dict[str, Any]:
        """
        íƒ€ê²Ÿ ë“±ë¡ ì‹œì‘ - enroll ì•¡ì…˜ì—ì„œ í˜¸ì¶œ
        duration_sec ë™ì•ˆ ê°€ì¥ ì í•©í•œ person ì„ íƒ
        """
        if self.current_mode != 1:
            return {"success": False, "message": "ë“±ë¡ëª¨ë“œê°€ ì•„ë‹™ë‹ˆë‹¤"}
        
        self.registration_duration = duration_sec
        self.registration_start_time = time.time()
        self.registration_candidates = []
        self.track_appearances = {}  # ë“±ë¡ ì‹œì‘ ì‹œ ì´ˆê¸°í™”
        
        self.logger.info(f"íƒ€ê²Ÿ ë“±ë¡ ì‹œì‘ (duration: {duration_sec}ì´ˆ)")
        return {"success": True, "message": "ë“±ë¡ ì‹œì‘"}
    
    def stop_tracking(self) -> Dict[str, Any]:
        """ì¶”ì  ì¤‘ì§€ - stop_tracking ì„œë¹„ìŠ¤ì—ì„œ í˜¸ì¶œ"""
        self._stop_tracking()
        return {"success": True, "message": "ì¶”ì ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤"}
    
    def get_registration_progress(self) -> float:
        """ë“±ë¡ ì§„í–‰ë¥  ë°˜í™˜ - enroll ì•¡ì…˜ í”¼ë“œë°±ìš©"""
        if not self.registration_start_time or not self.registration_duration:
            return 0.0
        
        # ì•ˆì „í•œ ì‹œê°„ ê³„ì‚°
        try:
            if self.registration_start_time is None:
                return 0.0
            elapsed = time.time() - self.registration_start_time
            progress = min(elapsed / self.registration_duration, 1.0)
            return progress
        except (TypeError, ValueError):
            return 0.0
    
    def _prepare_registration(self):
        """ë“±ë¡ëª¨ë“œ ì¤€ë¹„"""
        self.target_registered = False
        self.target_id = None
        self.registration_candidates = []
        
        # ì´ì „ íƒ€ê²Ÿ íŠ¹ì„± ì´ˆê¸°í™”
        self.target_color_features = None
        self.target_bbox_features = None
        self.deepsort_bbox = None
        self.fallback_bbox = None
        
        # ìƒíƒœ ì „í™˜ ì¶”ì  ì´ˆê¸°í™”
        self.previous_tracking_state = None
        self.is_target_distant = False
        self.distant_frame_count = 0
        self.normal_frame_count = 0
        self.lost_count = 0
        
        if DEEPSORT_AVAILABLE:
            self.tracker = DeepSort(
                max_age=30,
                n_init=3,
                nms_max_overlap=0.5,
                max_cosine_distance=0.5
            )
        # íŠ¸ë™ê³¼ íƒ€ê²Ÿë§Œ ë¦¬ì…‹ (ê°ì§€ëŠ” ìœ ì§€)
        self.last_tracks = []
        self.last_target_bbox = None
    
    def _start_tracking(self):
        """ì¶”ì ëª¨ë“œ ì‹œì‘"""
        if not self.target_registered:
            self.logger.warning("ë“±ë¡ëœ íƒ€ê²Ÿì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        self.tracking_active = True
        self.last_seen_time = time.time()
        self.lost_count = 0
        
        # ì¶”ì  ì‹œì‘ ì‹œ ìƒíƒœ ì´ˆê¸°í™” (ë“±ë¡ ì§í›„ ì •ìƒ ìƒíƒœë¡œ ê°€ì •)
        self.previous_tracking_state = "tracking"
        
        self.logger.info("ì¶”ì  ì‹œì‘ (ì´ˆê¸° ìƒíƒœ: tracking)")
    
    def _stop_tracking(self):
        """ì¶”ì  ì¤‘ì§€"""
        self.tracking_active = False
        self.target_registered = False
        self.target_id = None
        
        # íƒ€ê²Ÿ íŠ¹ì„± ì´ˆê¸°í™”
        self.target_color_features = None
        self.target_bbox_features = None
        self.deepsort_bbox = None
        self.fallback_bbox = None
        
        # ìƒíƒœ ì „í™˜ ì¶”ì  ì´ˆê¸°í™”
        self.previous_tracking_state = None
        self.is_target_distant = False
        self.distant_frame_count = 0
        self.normal_frame_count = 0
        self.lost_count = 0
        
        self.logger.info("ì¶”ì  ì¤‘ì§€ (íƒ€ê²Ÿ íŠ¹ì„± ë° ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ)")
        # ì¶”ì  ì¤‘ì§€ ì‹œ ìµœê·¼ ìƒíƒœ ë¦¬ì…‹
        self.last_detections = []
        self.last_tracks = []
        self.last_target_bbox = None
    
    def _process_registration_frame(self, frame: np.ndarray, timestamp: float):
        """ë“±ë¡ í”„ë ˆì„ ì²˜ë¦¬ - ëŒ€ê¸°ëª¨ë“œì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬"""
        # YOLOë¡œ ì‚¬ëŒ ê²€ì¶œ (ëŒ€ê¸°ëª¨ë“œì™€ ë™ì¼)
        detections = self._detect_persons(frame)
        
        # ë””ë²„ê¹…: í”„ë ˆì„ë§ˆë‹¤ ì¸ì‹ ê²°ê³¼ ë¡œê·¸ (ê°„ì†Œí™”)
        if detections.size > 0:
            self.logger.debug(f"ğŸŸ¡ ë“±ë¡í”„ë ˆì„: {len(detections)}ëª… ê°ì§€")
        else:
            self.logger.debug("ğŸŸ¡ ë“±ë¡í”„ë ˆì„: ê°ì§€ ì—†ìŒ")
        
        # ì˜¤ë²„ë ˆì´ìš© ìµœê·¼ ê²€ì¶œ ì €ì¥ (ëŒ€ê¸°ëª¨ë“œì™€ ë™ì¼)
        self.last_detections = [
            (float(x1), float(y1), float(x2), float(y2), float(conf))
            for x1, y1, x2, y2, conf, cls in detections
        ] if detections.size > 0 else []
        
        # ë“±ë¡ í”„ë¡œì„¸ìŠ¤ëŠ” ë”°ë¡œ ì²˜ë¦¬ (ë°”ìš´ë”©ë°•ìŠ¤ í‘œì‹œì™€ ë¬´ê´€)
        if self.registration_start_time:
            try:
                if self.registration_start_time is None:
                    return
                elapsed = time.time() - self.registration_start_time
                progress = elapsed / self.registration_duration * 100
                self.logger.info(f"ğŸŸ¡ ë“±ë¡ì§„í–‰: {progress:.1f}% ({elapsed:.1f}/{self.registration_duration:.1f}ì´ˆ)")
                
                if elapsed > self.registration_duration:
                    self.logger.info("ğŸŸ¡ ë“±ë¡ì‹œê°„ ì™„ë£Œ - ìµœì¢… ì²˜ë¦¬ ì‹œì‘")
                    self._finalize_registration()
                    return
            except (TypeError, ValueError) as e:
                self.logger.warning(f"ë“±ë¡ ì§„í–‰ë¥  ê³„ì‚° ì˜¤ë¥˜: {e}")
                return
        if detections.size == 0:
            return
        
        # DeepSORTë¡œ ì¶”ì  (ë“±ë¡ ê¸°ê°„ ë™ì•ˆ ì•ˆì •ì„± í™•ì¸)
        if self.tracker:
            ds_dets: List = []
            for x1, y1, x2, y2, conf, cls in detections:
                ds_dets.append(([float(x1), float(y1), float(x2), float(y2)], float(conf), int(cls)))
            
            # DeepSORT ì²˜ë¦¬ (ë””ë²„ê¹… ë¡œê·¸ ê°„ì†Œí™”)
            self.logger.debug(f"ğŸ”¥ DeepSORT ì…ë ¥: {len(ds_dets)}ê°œ ê°ì§€")
            tracks = self.tracker.update_tracks(ds_dets, frame=frame)
            
            confirmed_count = sum(1 for tr in tracks if getattr(tr, 'is_confirmed', lambda: True)())
            self.logger.debug(f"ğŸ”¥ DeepSORT ì¶œë ¥: {len(tracks)}ê°œ íŠ¸ë™ ({confirmed_count}ê°œ í™•ì •)")
            # ì˜¤ë²„ë ˆì´ìš© ìµœê·¼ íŠ¸ë™ ì €ì¥ (ë“±ë¡ ë‹¨ê³„ì—ì„œëŠ” íƒ€ê²Ÿ ë¯¸ì§€ì •)
            self.last_tracks = []
            for tr in tracks:
                if not getattr(tr, 'is_confirmed', lambda: True)():
                    continue
                bbox_tlbr = tr.to_tlbr() if hasattr(tr, 'to_tlbr') else None
                if bbox_tlbr is not None:
                    x1, y1, x2, y2 = bbox_tlbr
                    self.last_tracks.append((float(x1), float(y1), float(x2), float(y2)))
            
            # í›„ë³´ ì¶”ê°€ (track_id, bbox) - ë¡œê·¸ ê°„ì†Œí™”
            for track in tracks:
                if not getattr(track, 'is_confirmed', lambda: True)():
                    continue
                    
                track_id = getattr(track, 'track_id', None)
                bbox = track.to_tlbr() if hasattr(track, 'to_tlbr') else None
                if track_id is None or bbox is None:
                    continue
                
                stability = self._calculate_stability(track_id)
                
                candidate = {
                    'track_id': track_id,
                    'bbox': bbox,
                    'score': float(getattr(track, 'det_confidence', 1.0)),
                    'timestamp': timestamp,
                    'stability': stability
                }
                self.registration_candidates.append(candidate)
                
                # track_appearances ê¸°ë¡
                if track_id not in self.track_appearances:
                    self.track_appearances[track_id] = 0
                self.track_appearances[track_id] += 1
                
                self.logger.debug(f"ğŸ”¥ í›„ë³´ì¶”ê°€: track_id={track_id}, stability={stability:.3f}")
    
    def _process_tracking_frame(self, frame: np.ndarray, timestamp: float):
        """ì¶”ì  í”„ë ˆì„ ì²˜ë¦¬"""
        if not self.tracking_active or not self.target_registered:
            return
        
        # YOLO ê²€ì¶œ
        detections = self._detect_persons(frame)
        # ì˜¤ë²„ë ˆì´ìš© ìµœê·¼ ê²€ì¶œ ì €ì¥
        self.last_detections = [
            (float(x1), float(y1), float(x2), float(y2), float(conf))
            for x1, y1, x2, y2, conf, cls in detections
        ] if detections.size > 0 else []
        
        # DeepSORT ì—…ë°ì´íŠ¸
        if self.tracker:
            ds_dets: List = []
            for x1, y1, x2, y2, conf, cls in detections:
                ds_dets.append(([float(x1), float(y1), float(x2), float(y2)], float(conf), int(cls)))
            tracks = self.tracker.update_tracks(ds_dets, frame=frame)
            # ì˜¤ë²„ë ˆì´ìš© ìµœê·¼ íŠ¸ë™ ì €ì¥
            self.last_tracks = []
            self.last_target_bbox = None
            for tr in tracks:
                if not getattr(tr, 'is_confirmed', lambda: True)():
                    continue
                bbox_tlbr = tr.to_tlbr() if hasattr(tr, 'to_tlbr') else None
                if bbox_tlbr is not None:
                    x1, y1, x2, y2 = bbox_tlbr
                    self.last_tracks.append((float(x1), float(y1), float(x2), float(y2)))
            
            # ë“±ë¡ëœ íƒ€ê²Ÿ ì°¾ê¸°
            target_track = None
            for track in tracks:
                if getattr(track, 'track_id', None) == self.target_id:
                    target_track = track
                    # íƒ€ê²Ÿì˜ YOLO ê²€ì¶œ ê²°ê³¼ ì°¾ê¸° (DeepSORT bbox ëŒ€ì‹  ì‚¬ìš©)
                    if hasattr(track, 'to_tlbr'):
                        ds_bbox = track.to_tlbr()
                        if ds_bbox is not None:
                            # DeepSORT bbox ì¤‘ì‹¬ê³¼ ê°€ì¥ ê°€ê¹Œìš´ YOLO ê²€ì¶œ ì°¾ê¸°
                            ds_center_x = (ds_bbox[0] + ds_bbox[2]) / 2
                            ds_center_y = (ds_bbox[1] + ds_bbox[3]) / 2
                            
                            best_yolo_bbox = None
                            min_distance = float('inf')
                            
                            for x1, y1, x2, y2, conf in self.last_detections:
                                yolo_center_x = (x1 + x2) / 2
                                yolo_center_y = (y1 + y2) / 2
                                distance = ((ds_center_x - yolo_center_x)**2 + (ds_center_y - yolo_center_y)**2)**0.5
                                
                                if distance < min_distance:
                                    min_distance = distance
                                    best_yolo_bbox = (x1, y1, x2, y2)
                            
                            if best_yolo_bbox:
                                # YOLO bboxë¥¼ ì‹¤ì œ íƒ€ê²Ÿ bboxë¡œ ì‚¬ìš©
                                self.deepsort_bbox = best_yolo_bbox
                                self.last_target_bbox = best_yolo_bbox
                                # ì¶”ì  ì¤‘ íƒ€ê²Ÿ íŠ¹ì„± ì—…ë°ì´íŠ¸ (YOLO bbox ê¸°ì¤€)
                                self._update_target_features_during_tracking(frame, best_yolo_bbox)
                    break
            
            # DeepSORT ì¶”ì  ì‹¤íŒ¨ ì‹œ í´ë°± ì¶”ì  ì‹œë„
            if target_track is None and self.fallback_tracking_enabled:
                target_track = self._attempt_fallback_tracking(frame, detections, timestamp)
            
            # ì¶”ì  ìƒíƒœ í¼ë¸”ë¦¬ì‹œ
            self._publish_tracking_result(target_track, frame.shape, timestamp)
    
    def _detect_persons(self, frame: np.ndarray) -> np.ndarray:
        """YOLOë¡œ person ê²€ì¶œ"""
        if not self.yolo_model:
            if not hasattr(self, '_no_model_logged') or not self._no_model_logged:
                self.logger.warning("âŒ PersonTracker: YOLO ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
                self._no_model_logged = True
            return np.empty((0, 6))
        
        try:
            # YOLOv8nìœ¼ë¡œ personë§Œ ê²€ì¶œ (confidence threshold 0.5)
            results = self.yolo_model(frame, classes=[self.person_class_index], conf=0.7, verbose=False)
            
            detections = []
            for r in results:
                if hasattr(r, 'boxes') and r.boxes is not None:
                    for box in r.boxes:
                        # ì¢Œí‘œ/ì‹ ë¢°ë„ë¥¼ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜
                        x1, y1, x2, y2 = [float(v) for v in box.xyxy[0].tolist()]
                        try:
                            conf = float(box.conf[0].item())
                        except Exception:
                            conf = float(box.conf[0]) if hasattr(box.conf[0], '__float__') else 0.0
                        detections.append([x1, y1, x2, y2, conf, 0])
            
            return np.array(detections) if detections else np.empty((0, 6))
            
        except Exception as e:
            self.logger.warning(f"YOLO ê²€ì¶œ ì˜¤ë¥˜: {e}")
            return np.empty((0, 6))
    
    def _finalize_registration(self):
        """ë“±ë¡ ì™„ë£Œ ì²˜ë¦¬"""
        self.logger.info(f"ğŸ¯ ë“±ë¡ ì™„ë£Œ ì²˜ë¦¬ ì‹œì‘: í›„ë³´ìˆ˜={len(self.registration_candidates)}")
        if len(self.registration_candidates) > 0:
            best_candidate = max(self.registration_candidates, key=lambda x: x['stability'])
            self.logger.debug(f"ğŸ¯ ìµœê³  í›„ë³´: track_id={best_candidate['track_id']}, stability={best_candidate['stability']:.3f}")
        
        if not self.registration_candidates:
            # DeepSORT í›„ë³´ê°€ ì—†ì–´ë„ ìµœê·¼ ê°ì§€ëœ ì‚¬ëŒìœ¼ë¡œ ë“±ë¡ ì‹œë„
            if self.last_detections:
                # ê°€ì¥ ë†’ì€ confidenceì˜ ê°ì§€ ê²°ê³¼ë¡œ ë“±ë¡
                best_detection = max(self.last_detections, key=lambda x: x[4])  # confidence ê¸°ì¤€
                self.target_id = 1  # ê¸°ë³¸ ID
                self.target_registered = True
                
                # YOLO ê¸°ë°˜ ë“±ë¡ ì‹œì—ë„ ìƒ‰ìƒ íŠ¹ì„± ì €ì¥
                self._save_target_features_from_detection(best_detection)
                
                self.logger.info(f"YOLO ê°ì§€ ê¸°ë°˜ ë“±ë¡ ì™„ë£Œ: target_id={self.target_id}, conf={best_detection[4]:.2f}")
            else:
                self.logger.warning("ë“±ë¡í•  í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
                self.target_registered = False
                self.target_id = None
            
            # ë“±ë¡ ìƒíƒœ ë¦¬ì…‹
            self.registration_start_time = None
            self.registration_candidates = []
            return
        
        # DeepSORT í›„ë³´ ì¤‘ ìµœì†Œ ì•ˆì •ì„± ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ” í›„ë³´ ì„ íƒ
        stable_candidates = [
            c for c in self.registration_candidates 
            if c['stability'] >= 0.1  # ìµœì†Œ 10% ì•ˆì •ì„± ìš”êµ¬
        ]
        
        if not stable_candidates:
            self.logger.warning("ğŸ‘¤ ì•ˆì •ì„± ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ” í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
            # YOLO ê¸°ë°˜ ë“±ë¡ìœ¼ë¡œ í´ë°±
            if self.last_detections:
                best_detection = max(self.last_detections, key=lambda x: x[4])
                self.target_id = 1
                self.target_registered = True
                
                # YOLO ê¸°ë°˜ ë“±ë¡ ì‹œì—ë„ ìƒ‰ìƒ íŠ¹ì„± ì €ì¥
                self._save_target_features_from_detection(best_detection)
                
                self.logger.info(f"YOLO ê°ì§€ ê¸°ë°˜ ë“±ë¡ ì™„ë£Œ: target_id={self.target_id}, conf={best_detection[4]:.2f}")
            else:
                self.logger.warning("ğŸ‘¤ YOLO ê°ì§€ ë°ì´í„°ë„ ì—†ì–´ ë“±ë¡ ì‹¤íŒ¨")
                self.target_registered = False
                self.target_id = None
            
            # ë“±ë¡ ìƒíƒœ ë¦¬ì…‹
            self.registration_start_time = None
            self.registration_candidates = []
            return
        
        # ê°€ì¥ ì•ˆì •ì ì¸ í›„ë³´ ì„ íƒ
        best_candidate = max(stable_candidates, key=lambda x: x['stability'])
        
        self.target_id = best_candidate['track_id']
        self.target_registered = True
        
        # íƒ€ê²Ÿì˜ ìƒ‰ìƒ íŠ¹ì„± ì €ì¥ (ìµœê·¼ í”„ë ˆì„ ê¸°ì¤€)
        self._save_target_features(best_candidate)
        
        # ë“±ë¡ ì™„ë£Œ í›„ ë“±ë¡ ìƒíƒœ ë¦¬ì…‹
        self.registration_start_time = None
        self.registration_candidates = []
        
        self.logger.info(f"DeepSORT ê¸°ë°˜ ë“±ë¡ ì™„ë£Œ: track_id={self.target_id}")
    
    def _calculate_stability(self, track_id: int) -> float:
        """track_idì˜ ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚°"""
        if not self.registration_start_time:
            return 0.0
        
        # í˜„ì¬ track_idì˜ ì¶œí˜„ íšŸìˆ˜
        appearance_count = self.track_appearances.get(track_id, 0)
        
        # ì§€ì†ì„± ì ìˆ˜ (ì¶œí˜„ íšŸìˆ˜ / ì „ì²´ í”„ë ˆì„ ìˆ˜)
        try:
            duration = time.time() - self.registration_start_time
            expected_frames = duration * 10  # 10fps ê°€ì • (í”„ë ˆì„ ì²˜ë¦¬ ì†ë„ ê³ ë ¤)
            stability = appearance_count / max(expected_frames, 1)
            return min(stability, 1.0)  # ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ
        except (TypeError, ValueError):
            return 0.0
    
    def _publish_tracking_result(self, target_track, frame_shape, timestamp):
        """ì¶”ì  ê²°ê³¼ í¼ë¸”ë¦¬ì‹œ (/vs/tracking) - ìƒíƒœ ì „í™˜ ì‹œì—ë§Œ ë°œí–‰"""
        current_state = None
        event_to_publish = None
        
        if target_track and hasattr(target_track, 'to_tlbr'):
            # ì¶”ì  ì„±ê³µ
            current_state = "tracking"
            
            # LOST/REACQUIRED ì´ë²¤íŠ¸ ì²˜ë¦¬ (2,3)
            reacquired_event = None
            if self.lost_count > 0:
                reacquired_event = 3  # REACQUIRED
                self.reacquired_count += 1
                
                # ì¬íšë“ ë¡œê·¸ëŠ” lost_countê°€ í´ ë•Œë§Œ ìƒì„¸íˆ ì¶œë ¥
                if self.lost_count > 5:
                    self.logger.info(f"ğŸ¯ íƒ€ê²Ÿ ì¬íšë“! (lost_count: {self.lost_count})")
                else:
                    self.logger.debug(f"ğŸ¯ íƒ€ê²Ÿ ì¬íšë“! (lost_count: {self.lost_count})")
            
            # ë©€ì–´ì§/ì •ìƒìƒíƒœ ì´ë²¤íŠ¸ ì²˜ë¦¬ (0,1) - ë…ë¦½ì ìœ¼ë¡œ ì²´í¬
            distance_event = None
            if target_track.to_tlbr() is not None and len(frame_shape) >= 2:
                bbox = target_track.to_tlbr()
                bbox_width = bbox[2] - bbox[0]  # x2 - x1
                frame_width = frame_shape[1]    # width (cols)
                width_ratio = bbox_width / frame_width
                
                # í”„ë ˆì„ ê¸°ë°˜ ë³´ìˆ˜ì  íŒë‹¨: ì—°ì† 5í”„ë ˆì„ ì¡°ê±´ ë§Œì¡± ì‹œì—ë§Œ ìƒíƒœ ë³€ê²½ (íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ì œê±°, 0.2 ê¸°ì¤€)
                if width_ratio < 0.2:
                    # ë©€ì–´ì§ ì¡°ê±´ ë§Œì¡±
                    self.distant_frame_count += 1
                    self.normal_frame_count = 0  # ë¦¬ì…‹
                    
                    if self.distant_frame_count >= self.required_frames and not self.is_target_distant:
                        # ì—°ì† 5í”„ë ˆì„ ë©€ì–´ì§ â†’ ìƒíƒœ ë³€ê²½
                        distance_event = 1  # ë©€ì–´ì§
                        self.is_target_distant = True
                        self.logger.info(f"ğŸ“ íƒ€ê²Ÿ ë©€ì–´ì§ ê°ì§€! ë„ˆë¹„ ë¹„ìœ¨: {width_ratio:.3f} < 0.2 ({self.distant_frame_count}í”„ë ˆì„ ì—°ì†)")
                        
                elif width_ratio >= 0.2:
                    # ì •ìƒ ì¡°ê±´ ë§Œì¡±
                    self.normal_frame_count += 1
                    self.distant_frame_count = 0  # ë¦¬ì…‹
                    
                    if self.normal_frame_count >= self.required_frames and self.is_target_distant:
                        # ì—°ì† 5í”„ë ˆì„ ì •ìƒ â†’ ìƒíƒœ ë³€ê²½
                        distance_event = 0  # ì •ìƒìƒíƒœ ë³µê·€
                        self.is_target_distant = False
                        self.logger.info(f"ğŸ“ íƒ€ê²Ÿ ì •ìƒìƒíƒœ ë³µê·€! ë„ˆë¹„ ë¹„ìœ¨: {width_ratio:.3f} >= 0.2 ({self.normal_frame_count}í”„ë ˆì„ ì—°ì†)")
            
            # ê° ì´ë²¤íŠ¸ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„ ì—†ìŒ)
            # REACQUIRED ì´ë²¤íŠ¸ ë°œí–‰ (2,3)
            if reacquired_event is not None:
                self._publish_single_event(reacquired_event, target_track, current_state)
            
            # ê±°ë¦¬ ì´ë²¤íŠ¸ ë°œí–‰ (0,1) - ì™„ì „ ë…ë¦½ì 
            if distance_event is not None:
                self._publish_single_event(distance_event, target_track, current_state)
            
            self.lost_count = 0
            self.last_seen_time = timestamp
        
        else:
            # ì¶”ì  ì‹¤íŒ¨
            self.lost_count += 1
            
            if self.lost_count == 1:
                # Tracking â†’ Lost ìƒíƒœ ì „í™˜ (ì²˜ìŒ ìƒìŒ)
                current_state = "lost"
                event_to_publish = 2  # LOST
                self.logger.warning("âŒ íƒ€ê²Ÿ ì¶”ì  ì‹¤íŒ¨")
            else:
                # ê³„ì† Lost ìƒíƒœ (ìƒíƒœ ë³€í™” ì—†ìŒ)
                current_state = "lost"
        
        # LOST ì´ë²¤íŠ¸ë§Œ ìƒíƒœ ì „í™˜ì— ë”°ë¼ ë°œí–‰ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        if (self.previous_tracking_state != current_state and 
            current_state == "lost"):
            self._publish_single_event(2, None, current_state)  # LOST
        
        # ì´ì „ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.previous_tracking_state = current_state
    
    def _publish_single_event(self, event_id, target_track, current_state):
        """ë‹¨ì¼ ì´ë²¤íŠ¸ ë°œí–‰"""
        msg = Tracking()
        msg.id = int(self.target_id) if self.target_id is not None else -1
        msg.event = int(event_id)
        
        # ì°¸ê³ : Tracking.msgì—ëŠ” ìœ„ì¹˜ ì •ë³´ í•„ë“œê°€ ì—†ìŒ (id, eventë§Œ ìˆìŒ)
        
        self.tracking_pub.publish(msg)
        
        # ë¡œê·¸ ì¶œë ¥
        event_names = {0: "ì •ìƒìƒíƒœë³µê·€", 1: "ë©€ì–´ì§", 2: "LOST", 3: "REACQUIRED"}
        event_name = event_names.get(event_id, f"UNKNOWN({event_id})")
        
        if event_id in [0, 1]:  # ê±°ë¦¬ ì´ë²¤íŠ¸
            self.logger.info(f"ğŸ“¡ ê±°ë¦¬ ìƒíƒœ ë³€í™”: (ì´ë²¤íŠ¸: {event_name})")
        else:  # ì¶”ì  ì´ë²¤íŠ¸
            state_change = f"{self.previous_tracking_state} â†’ {current_state}"
            self.logger.info(f"ğŸ“¡ ì¶”ì  ìƒíƒœ ë³€í™”: {state_change} (ì´ë²¤íŠ¸: {event_name})")
    
    def get_overlay_frame(self, base_frame: np.ndarray) -> np.ndarray:
        """
        UDP ìŠ¤íŠ¸ë¦¬ë°ìš© ì˜¤ë²„ë ˆì´ í”„ë ˆì„ ìƒì„±
        vs_nodeì—ì„œ ì„ íƒì ìœ¼ë¡œ í˜¸ì¶œ
        """
        overlay = base_frame.copy()
        

        
        # ëª¨ë“œë³„ ì˜¤ë²„ë ˆì´ ì •ë³´ í‘œì‹œ
        if self.current_mode == 1:  # ë“±ë¡ëª¨ë“œ
            # ë“±ë¡ìš© ë°”ìš´ë”©ë°•ìŠ¤ í‘œì‹œ (ëŒ€ê¸°ëª¨ë“œì™€ ë™ì¼í•œ ì´ˆë¡ìƒ‰)
            for i, det in enumerate(self.last_detections):
                x1, y1, x2, y2, conf = det
                p1, p2 = (int(x1), int(y1)), (int(x2), int(y2))
                center = (int((x1 + x2) / 2), int((y1 + y2) / 2))
                
                # ì´ˆë¡ìƒ‰ ë°”ìš´ë”©ë°•ìŠ¤ ì œê±°
                
                # ì¤‘ì•™ì— ì‘ì€ ì›
                cv2.circle(overlay, center, 5, (0, 255, 0), -1)
                cv2.circle(overlay, center, 8, (255, 255, 255), 2)
                
                # confidence í‘œì‹œ
                cv2.putText(overlay, f"P{i+1}: {conf:.2f}", (p1[0], max(0, p1[1]-10)), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # ë“±ë¡ ìƒíƒœ í‘œì‹œ (í™”ë©´ í•˜ë‹¨)
            if self.target_registered:
                # ë“±ë¡ ì™„ë£Œ ìƒíƒœ í‘œì‹œ
                text = f"REGISTERED: ID {self.target_id}"
                cv2.rectangle(overlay, (10, 450), (300, 480), (0, 100, 0), -1)  # ë…¹ìƒ‰ ë°°ê²½
                cv2.putText(overlay, text, (20, 470), cv2.FONT_HERSHEY_SIMPLEX, 
                           0.6, (255, 255, 255), 2)
            elif self.registration_start_time and self.registration_duration:
                # ë“±ë¡ ì§„í–‰ë¥  í‘œì‹œ (ì•ˆì „í•œ ì¡°ê±´ì—ì„œë§Œ)
                try:
                    progress = self.get_registration_progress()
                    text = f"REGISTRATION: {progress:.1%}"
                    cv2.rectangle(overlay, (10, 450), (300, 480), (0, 0, 0), -1)  # ê²€ì€ ë°°ê²½
                    cv2.putText(overlay, text, (20, 470), cv2.FONT_HERSHEY_SIMPLEX, 
                               0.6, (0, 255, 255), 2)
                except Exception:
                    # ì—ëŸ¬ ë°œìƒ ì‹œ ë¬´ì‹œ
                    pass
            else:
                # ë“±ë¡ ëŒ€ê¸° ìƒíƒœ - íŒŒë€ ë°°ê²½ ì œê±°
                text = "REGISTRATION MODE"
                cv2.putText(overlay, text, (20, 470), cv2.FONT_HERSHEY_SIMPLEX, 
                           0.6, (255, 255, 255), 2)
        
        elif self.current_mode == 2:  # ì¶”ì ëª¨ë“œ
            status = "TRACKING" if self.target_registered else "NO TARGET"
            color = (0, 255, 0) if self.target_registered else (0, 0, 255)
            cv2.putText(overlay, status, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 
                       0.7, color, 2)
            
            # ì¶”ì  ìƒíƒœ ì •ë³´ í‘œì‹œ
            if self.lost_count > 0:
                cv2.putText(overlay, f"LOST: {self.lost_count}", (10, 60), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                
                # í´ë°± ì¶”ì  í™œì„±í™” í‘œì‹œ
                if self.fallback_tracking_enabled:
                    cv2.putText(overlay, "FALLBACK MODE", (10, 90), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            
            # YOLO ê²€ì¶œ ê²°ê³¼ í‘œì‹œ (ë°•ìŠ¤ ì œê±°)
            for i, det in enumerate(self.last_detections):
                x1, y1, x2, y2, conf = det
                p1, p2 = (int(x1), int(y1)), (int(x2), int(y2))
                # ì´ˆë¡ìƒ‰ ë°•ìŠ¤ ì œê±°
                cv2.putText(overlay, f"YOLO:{conf:.2f}", (p1[0], p1[1]-50), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        else:
            # ê¸°íƒ€ ëª¨ë“œ(ëŒ€ê¸° ë“±): ìµœê·¼ YOLO ê²€ì¶œë§Œ í‘œì‹œ (ì ì ˆí•œ í¬ê¸°ë¡œ)
            for i, det in enumerate(self.last_detections):
                x1, y1, x2, y2, conf = det
                p1, p2 = (int(x1), int(y1)), (int(x2), int(y2))
                center = (int((x1 + x2) / 2), int((y1 + y2) / 2))
                
                # ì´ˆë¡ìƒ‰ ë°”ìš´ë”©ë°•ìŠ¤ ì œê±°
                
                # ì¤‘ì•™ì— ì‘ì€ ì›
                cv2.circle(overlay, center, 5, (0, 255, 0), -1)
                cv2.circle(overlay, center, 8, (255, 255, 255), 2)
                
                # confidence í‘œì‹œ
                cv2.putText(overlay, f"P{i+1}: {conf:.2f}", (p1[0], max(0, p1[1]-10)), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        return overlay 
    
    def _extract_color_features(self, image: np.ndarray, bbox: Tuple[float, float, float, float]) -> Dict[str, np.ndarray]:
        """
        ë°”ìš´ë”©ë°•ìŠ¤ ì˜ì—­ì—ì„œ ìƒ‰ìƒ íŠ¹ì„± ì¶”ì¶œ
        ìƒì²´/í•˜ì²´ë¥¼ ë¶„ë¦¬í•˜ì—¬ ê°ê°ì˜ ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
        """
        try:
            x1, y1, x2, y2 = [int(coord) for coord in bbox]
            h, w = image.shape[:2]
            
            # ë°”ìš´ë”©ë°•ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(w, x2), min(h, y2)
            
            if x2 <= x1 or y2 <= y1:
                return {}
            
            # ì‚¬ëŒ ì˜ì—­ í¬ë¡­
            person_crop = image[y1:y2, x1:x2]
            crop_h, crop_w = person_crop.shape[:2]
            
            if crop_h < 20 or crop_w < 10:  # ë„ˆë¬´ ì‘ì€ ì˜ì—­ì€ ì œì™¸
                return {}
            
            # ìƒì²´/í•˜ì²´ ë¶„ë¦¬ (ëŒ€ëµ 2:3 ë¹„ìœ¨)
            upper_end = int(crop_h * 0.4)  # ìƒì²´ 40%
            lower_start = int(crop_h * 0.6)  # í•˜ì²´ëŠ” 60%ë¶€í„°
            
            upper_body = person_crop[:upper_end, :] if upper_end > 0 else person_crop
            lower_body = person_crop[lower_start:, :] if lower_start < crop_h else person_crop
            
            features = {}
            
            # RGB íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
            for region_name, region_img in [("upper", upper_body), ("lower", lower_body), ("full", person_crop)]:
                if region_img.size > 0:
                    # RGB ê° ì±„ë„ë³„ íˆìŠ¤í† ê·¸ë¨ (16 bins each)
                    hist_r = cv2.calcHist([region_img], [0], None, [16], [0, 256])
                    hist_g = cv2.calcHist([region_img], [1], None, [16], [0, 256])
                    hist_b = cv2.calcHist([region_img], [2], None, [16], [0, 256])
                    
                    # ì •ê·œí™”
                    hist_r = cv2.normalize(hist_r, hist_r, 0, 1, cv2.NORM_MINMAX).flatten()
                    hist_g = cv2.normalize(hist_g, hist_g, 0, 1, cv2.NORM_MINMAX).flatten()
                    hist_b = cv2.normalize(hist_b, hist_b, 0, 1, cv2.NORM_MINMAX).flatten()
                    
                    # HSVë„ ì¶”ê°€ (ìƒ‰ìƒ ì •ë³´ ê°•í™”)
                    hsv_img = cv2.cvtColor(region_img, cv2.COLOR_BGR2HSV)
                    hist_h = cv2.calcHist([hsv_img], [0], None, [16], [0, 180])
                    hist_s = cv2.calcHist([hsv_img], [1], None, [16], [0, 256])
                    hist_v = cv2.calcHist([hsv_img], [2], None, [16], [0, 256])
                    
                    hist_h = cv2.normalize(hist_h, hist_h, 0, 1, cv2.NORM_MINMAX).flatten()
                    hist_s = cv2.normalize(hist_s, hist_s, 0, 1, cv2.NORM_MINMAX).flatten()
                    hist_v = cv2.normalize(hist_v, hist_v, 0, 1, cv2.NORM_MINMAX).flatten()
                    
                    # ê²°í•©ëœ íŠ¹ì„± ë²¡í„°
                    features[f"{region_name}_rgb"] = np.concatenate([hist_r, hist_g, hist_b])
                    features[f"{region_name}_hsv"] = np.concatenate([hist_h, hist_s, hist_v])
            
            return features
            
        except Exception as e:
            self.logger.warning(f"ìƒ‰ìƒ íŠ¹ì„± ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {}
    
    def _calculate_color_similarity(self, features1: Dict[str, np.ndarray], features2: Dict[str, np.ndarray]) -> float:
        """ë‘ ìƒ‰ìƒ íŠ¹ì„±ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0~1, ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)"""
        if not features1 or not features2:
            return 0.0
        
        try:
            similarities = []
            
            # ê° ì˜ì—­ë³„ ìœ ì‚¬ë„ ê³„ì‚°
            for key in features1:
                if key in features2:
                    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                    feat1, feat2 = features1[key], features2[key]
                    
                    norm1 = np.linalg.norm(feat1)
                    norm2 = np.linalg.norm(feat2)
                    
                    if norm1 > 0 and norm2 > 0:
                        cosine_sim = np.dot(feat1, feat2) / (norm1 * norm2)
                        similarities.append(max(0, cosine_sim))  # ìŒìˆ˜ ì œê±°
            
            # í‰ê·  ìœ ì‚¬ë„ ë°˜í™˜
            return np.mean(similarities) if similarities else 0.0
            
        except Exception as e:
            self.logger.warning(f"ìƒ‰ìƒ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    def _calculate_bbox_similarity(self, bbox1: Tuple[float, float, float, float], 
                                  bbox2: Tuple[float, float, float, float]) -> float:
        """ë°”ìš´ë”©ë°•ìŠ¤ í¬ê¸°/ë¹„ìœ¨ ìœ ì‚¬ë„ ê³„ì‚° (0~1)"""
        try:
            x1, y1, x2, y2 = bbox1
            w1, h1 = x2 - x1, y2 - y1
            
            x1_, y1_, x2_, y2_ = bbox2  
            w2, h2 = x2_ - x1_, y2_ - y1_
            
            if w1 <= 0 or h1 <= 0 or w2 <= 0 or h2 <= 0:
                return 0.0
            
            # í¬ê¸° ë¹„ìœ¨ ìœ ì‚¬ë„
            size_ratio = min(w1/w2, w2/w1) * min(h1/h2, h2/h1)
            
            # ì¢…íš¡ë¹„ ìœ ì‚¬ë„  
            aspect1, aspect2 = w1/h1, w2/h2
            aspect_ratio = min(aspect1/aspect2, aspect2/aspect1)
            
            # ì¢…í•© ìœ ì‚¬ë„ (í¬ê¸° 70%, ì¢…íš¡ë¹„ 30%)
            return 0.7 * size_ratio + 0.3 * aspect_ratio
            
        except Exception as e:
            self.logger.warning(f"ë°”ìš´ë”©ë°•ìŠ¤ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    def _calculate_position_proximity(self, bbox1: Tuple[float, float, float, float],
                                    bbox2: Tuple[float, float, float, float],
                                    frame_shape: Tuple[int, int]) -> float:
        """ë°”ìš´ë”©ë°•ìŠ¤ ìœ„ì¹˜ ê·¼ì ‘ë„ ê³„ì‚° (0~1, ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ìŒ)"""
        try:
            # ì¤‘ì‹¬ì  ê³„ì‚°
            cx1, cy1 = (bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2
            cx2, cy2 = (bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2
            
            # ì •ê·œí™”ëœ ê±°ë¦¬ ê³„ì‚°
            h, w = frame_shape[:2]
            norm_dist = np.sqrt(((cx1-cx2)/w)**2 + ((cy1-cy2)/h)**2)
            
            # ê·¼ì ‘ë„ë¡œ ë³€í™˜ (ìµœëŒ€ 0.5 í™”ë©´ ê±°ë¦¬ê¹Œì§€ ê³ ë ¤)
            proximity = max(0, 1 - norm_dist / 0.5)
            return proximity
            
        except Exception as e:
            self.logger.warning(f"ìœ„ì¹˜ ê·¼ì ‘ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    def _save_target_features(self, candidate: Dict):
        """DeepSORT í›„ë³´ë¡œë¶€í„° íƒ€ê²Ÿ íŠ¹ì„± ì €ì¥"""
        try:
            # ìµœê·¼ í”„ë ˆì„ì—ì„œ ìƒ‰ìƒ íŠ¹ì„± ì¶”ì¶œ
            with self.frame_lock:
                if self.frame_buffer:
                    recent_frame, _ = self.frame_buffer[-1]
                    bbox = candidate['bbox']
                    
                    # ìƒ‰ìƒ íŠ¹ì„± ì¶”ì¶œ ë° ì €ì¥
                    color_features = self._extract_color_features(recent_frame, bbox)
                    if color_features:
                        self.target_color_features = color_features
                        self.target_bbox_features = {
                            'width': bbox[2] - bbox[0],
                            'height': bbox[3] - bbox[1],
                            'aspect_ratio': (bbox[2] - bbox[0]) / (bbox[3] - bbox[1]) if bbox[3] > bbox[1] else 1.0
                        }
                        self.logger.info(f"ğŸ¨ íƒ€ê²Ÿ ìƒ‰ìƒ íŠ¹ì„± ì €ì¥ ì™„ë£Œ (DeepSORT ê¸°ë°˜)")
                    else:
                        self.logger.warning("ğŸ¨ íƒ€ê²Ÿ ìƒ‰ìƒ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨")
        except Exception as e:
            self.logger.warning(f"íƒ€ê²Ÿ íŠ¹ì„± ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _save_target_features_from_detection(self, detection: Tuple[float, float, float, float, float]):
        """YOLO ê²€ì¶œ ê²°ê³¼ë¡œë¶€í„° íƒ€ê²Ÿ íŠ¹ì„± ì €ì¥"""
        try:
            # ìµœê·¼ í”„ë ˆì„ì—ì„œ ìƒ‰ìƒ íŠ¹ì„± ì¶”ì¶œ
            with self.frame_lock:
                if self.frame_buffer:
                    recent_frame, _ = self.frame_buffer[-1]
                    x1, y1, x2, y2, conf = detection
                    bbox = (x1, y1, x2, y2)
                    
                    # ìƒ‰ìƒ íŠ¹ì„± ì¶”ì¶œ ë° ì €ì¥
                    color_features = self._extract_color_features(recent_frame, bbox)
                    if color_features:
                        self.target_color_features = color_features
                        self.target_bbox_features = {
                            'width': x2 - x1,
                            'height': y2 - y1,
                            'aspect_ratio': (x2 - x1) / (y2 - y1) if y2 > y1 else 1.0
                        }
                        self.logger.info(f"ğŸ¨ íƒ€ê²Ÿ ìƒ‰ìƒ íŠ¹ì„± ì €ì¥ ì™„ë£Œ (YOLO ê¸°ë°˜)")
                    else:
                        self.logger.warning("ğŸ¨ íƒ€ê²Ÿ ìƒ‰ìƒ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨")
        except Exception as e:
            self.logger.warning(f"íƒ€ê²Ÿ íŠ¹ì„± ì €ì¥ ì˜¤ë¥˜ (YOLO): {e}")
    
    def _update_target_features_during_tracking(self, frame: np.ndarray, bbox: Tuple[float, float, float, float]):
        """ì¶”ì  ì¤‘ íƒ€ê²Ÿ íŠ¹ì„± ì£¼ê¸°ì  ì—…ë°ì´íŠ¸ (í”„ë ˆì„ 30ê°œë§ˆë‹¤)"""
        try:
            if not hasattr(self, '_feature_update_counter'):
                self._feature_update_counter = 0
            
            self._feature_update_counter += 1
            
            # 30í”„ë ˆì„(ì•½ 2ì´ˆ)ë§ˆë‹¤ í•œë²ˆì”© íŠ¹ì„± ì—…ë°ì´íŠ¸
            if self._feature_update_counter % 30 == 0:
                new_color_features = self._extract_color_features(frame, bbox)
                if new_color_features and self.target_color_features:
                    # ê¸°ì¡´ íŠ¹ì„±ê³¼ ìƒˆ íŠ¹ì„±ì„ ë¸”ë Œë”© (90% ê¸°ì¡´, 10% ìƒˆë¡œìš´)
                    for key in new_color_features:
                        if key in self.target_color_features:
                            self.target_color_features[key] = (
                                0.9 * self.target_color_features[key] + 
                                0.1 * new_color_features[key]
                            )
                    self.logger.debug("ğŸ¨ íƒ€ê²Ÿ ìƒ‰ìƒ íŠ¹ì„± ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                
        except Exception as e:
            self.logger.warning(f"íƒ€ê²Ÿ íŠ¹ì„± ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
    
    def _attempt_fallback_tracking(self, frame: np.ndarray, detections: np.ndarray, timestamp: float):
        """DeepSORT ì‹¤íŒ¨ ì‹œ YOLO + ìƒ‰ìƒ/ìœ„ì¹˜ ê¸°ë°˜ í´ë°± ì¶”ì """
        if detections.size == 0 or not self.target_color_features or not self.target_bbox_features:
            return None
        
        try:
            self.logger.debug("ğŸ”„ í´ë°± ì¶”ì  ì‹œë„: ìƒ‰ìƒ/ìœ„ì¹˜/í¬ê¸° ê¸°ë°˜ ë§¤ì¹­")
            
            best_match = None
            best_score = 0.0
            
            # ê° YOLO ê²€ì¶œì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
            for x1, y1, x2, y2, conf, cls in detections:
                detection_bbox = (float(x1), float(y1), float(x2), float(y2))
                
                # 1. ìƒ‰ìƒ ìœ ì‚¬ë„ ê³„ì‚°
                detection_color_features = self._extract_color_features(frame, detection_bbox)
                color_similarity = 0.0
                if detection_color_features:
                    color_similarity = self._calculate_color_similarity(
                        self.target_color_features, detection_color_features
                    )
                
                # 2. í¬ê¸°/ë¹„ìœ¨ ìœ ì‚¬ë„ ê³„ì‚°
                target_bbox = (0, 0, self.target_bbox_features['width'], self.target_bbox_features['height'])
                bbox_similarity = self._calculate_bbox_similarity(target_bbox, 
                    (0, 0, x2-x1, y2-y1))  # ìƒëŒ€ì  í¬ê¸° ë¹„êµ
                
                # 3. ìœ„ì¹˜ ê·¼ì ‘ë„ ê³„ì‚° (ë§ˆì§€ë§‰ ì•Œë ¤ì§„ ìœ„ì¹˜ ê¸°ì¤€)
                position_proximity = 0.0
                if self.last_target_bbox:
                    position_proximity = self._calculate_position_proximity(
                        self.last_target_bbox, detection_bbox, frame.shape
                    )
                
                # 4. YOLO confidence ì ìˆ˜
                conf_score = float(conf)
                
                # 5. ì¢…í•© ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
                # ìƒ‰ìƒ 50%, í¬ê¸° 20%, ìœ„ì¹˜ 20%, confidence 10%
                composite_score = (
                    0.5 * color_similarity +
                    0.2 * bbox_similarity + 
                    0.2 * position_proximity +
                    0.1 * conf_score
                )
                
                self.logger.debug(f"ğŸ”„ í›„ë³´ ë¶„ì„: conf={conf:.2f}, "
                               f"ìƒ‰ìƒ={color_similarity:.2f}, í¬ê¸°={bbox_similarity:.2f}, "
                               f"ìœ„ì¹˜={position_proximity:.2f} â†’ ì¢…í•©={composite_score:.2f}")
                
                # ìµœê³  ì ìˆ˜ í›„ë³´ ì„ íƒ (ìµœì†Œ ì„ê³„ê°’ 0.4 ì´ìƒ)
                if composite_score > best_score and composite_score > 0.4:
                    best_score = composite_score
                    best_match = {
                        'bbox': detection_bbox,
                        'confidence': conf_score,
                        'composite_score': composite_score,
                        'color_sim': color_similarity,
                        'bbox_sim': bbox_similarity,
                        'pos_prox': position_proximity
                    }
            
            # ë§¤ì¹­ ì„±ê³µ ì‹œ ê°€ìƒ íŠ¸ë™ ê°ì²´ ìƒì„±
            if best_match:
                # ì„±ê³µ ë¡œê·¸ëŠ” ì£¼ê¸°ì ìœ¼ë¡œë§Œ ì¶œë ¥ (30í”„ë ˆì„ë§ˆë‹¤)
                if not hasattr(self, '_fallback_success_count'):
                    self._fallback_success_count = 0
                self._fallback_success_count += 1
                
                if self._fallback_success_count % 60 == 1:  # ì²« ë²ˆì§¸ì™€ 60ì˜ ë°°ìˆ˜ë§ˆë‹¤ (ë” ì ê²Œ)
                    self.logger.info(f"ğŸ¯ í´ë°± ì¶”ì  ì„±ê³µ! ì¢…í•©ì ìˆ˜: {best_score:.2f} "
                                   f"(ìƒ‰ìƒ:{best_match['color_sim']:.2f}, "
                                   f"í¬ê¸°:{best_match['bbox_sim']:.2f}, "
                                   f"ìœ„ì¹˜:{best_match['pos_prox']:.2f})")
                else:
                    self.logger.debug(f"ğŸ¯ í´ë°± ì¶”ì  ì„±ê³µ! ì¢…í•©ì ìˆ˜: {best_score:.2f}")
                
                # íƒ€ê²Ÿ ë°”ìš´ë”©ë°•ìŠ¤ ì—…ë°ì´íŠ¸ (YOLO bboxë¥¼ ì•½ê°„ ì¶•ì†Œí•˜ì—¬ DeepSORTì™€ ìœ ì‚¬í•˜ê²Œ)
                x1, y1, x2, y2 = best_match['bbox']
                width = x2 - x1
                height = y2 - y1
                
                # ë„ˆë¹„/ë†’ì´ë¥¼ 40% ì¶•ì†Œ (ì¤‘ì•™ ê¸°ì¤€) - ë“±ë¡ëª¨ë“œ í¬ê¸°ì— ë§ì¶”ê¸° ìœ„í•´
                shrink_ratio = 0.6
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                new_width = width * shrink_ratio
                new_height = height * shrink_ratio
                
                adjusted_bbox = (
                    center_x - new_width/2,
                    center_y - new_height/2,
                    center_x + new_width/2,
                    center_y + new_height/2
                )
                # í´ë°± bbox ì €ì¥ (ì¶•ì†Œëœ í¬ê¸°)
                self.fallback_bbox = adjusted_bbox
                self.last_target_bbox = adjusted_bbox
                
                # ê°€ìƒ íŠ¸ë™ ê°ì²´ ìƒì„± (DeepSORT íŠ¸ë™ê³¼ í˜¸í™˜)
                return self._create_virtual_track(best_match)
            else:
                self.logger.debug("ğŸ”„ í´ë°± ì¶”ì  ì‹¤íŒ¨: ìœ ì‚¬ë„ ì„ê³„ê°’ ë¯¸ë‹¬")
                return None
                
        except Exception as e:
            self.logger.warning(f"í´ë°± ì¶”ì  ì˜¤ë¥˜: {e}")
            return None
    
    def _create_virtual_track(self, match_data: Dict):
        """í´ë°± ë§¤ì¹­ì„ ìœ„í•œ ê°€ìƒ íŠ¸ë™ ê°ì²´ ìƒì„±"""
        class VirtualTrack:
            def __init__(self, bbox, track_id):
                self._bbox = bbox
                self.track_id = track_id
                
            def to_tlbr(self):
                return self._bbox
                
            def is_confirmed(self):
                return True
        
        return VirtualTrack(match_data['bbox'], self.target_id)