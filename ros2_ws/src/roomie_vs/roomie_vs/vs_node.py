#!/usr/bin/env python3

# ğŸ”§ ROS2 ë™ì  ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ìˆœì„œ ë¬¸ì œ í•´ê²° (ì‹œìŠ¤í…œ ë ˆë²¨ í•´ê²°ë¡œ ë” ì´ìƒ ë¶ˆí•„ìš”)
# import ctypes
# import os
# try:
#     # roomie_msgs ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ìˆœì„œëŒ€ë¡œ ê°•ì œ ë¡œë“œ
#     roomie_lib_path = '/home/jinhyuk2me/project_ws/Roomie/ros2_ws/install/roomie_msgs/lib'
#     
#     # í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ë§Œ ëª…ì‹œì ìœ¼ë¡œ ë¡œë“œ
#     essential_libs = [
#         'libroomie_msgs__rosidl_generator_c.so',
#         'libroomie_msgs__rosidl_typesupport_c.so',
#         'libroomie_msgs__rosidl_typesupport_fastrtps_c.so', 
#         'libroomie_msgs__rosidl_typesupport_introspection_c.so',
#         'libroomie_msgs__rosidl_generator_py.so',
#     ]
#     
#     loaded_count = 0
#     for lib_name in essential_libs:
#         lib_path = f'{roomie_lib_path}/{lib_name}'
#         try:
#             if os.path.exists(lib_path):
#                 ctypes.CDLL(lib_path)
#                 loaded_count += 1
#         except Exception:
#             pass  # ê°œë³„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
#     
#     print(f"âœ… roomie_msgs ë¼ì´ë¸ŒëŸ¬ë¦¬ pre-loading ì™„ë£Œ ({loaded_count}/{len(essential_libs)})")
# except Exception as e:
#     print(f"âš ï¸ roomie_msgs ë¼ì´ë¸ŒëŸ¬ë¦¬ pre-loading ì‹¤íŒ¨: {e}")

import rclpy
from rclpy.node import Node
from rclpy.executors import MultiThreadedExecutor
from rclpy.action import ActionServer
import threading
import time
import os
import numpy as np
import cv2
import cv2
from typing import Optional, Tuple, List

# CNN ë²„íŠ¼ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì¶”ê°€ import
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision.transforms as transforms
    from PIL import Image
    import yaml
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# ì¥ì• ë¬¼ ê°ì§€ import
from .obstacle_detector import ObstacleDetector

# UDP ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° import
from .udp_streamer import UDPVideoStreamer

# ì‚¬ëŒ ì¶”ì  ëª¨ë“ˆ import
from .person_tracking import PersonTracker

# CNN ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜ (ì‹¤ì œ í›ˆë ¨ëœ ëª¨ë¸ê³¼ ì¼ì¹˜)
class BalancedButtonCNN(nn.Module):
    """ì„±ëŠ¥ê³¼ ë©”ëª¨ë¦¬ ê· í˜•ì„ ë§ì¶˜ CNN ëª¨ë¸"""
    
    def __init__(self, num_classes=18):
        super(BalancedButtonCNN, self).__init__()
        
        # ê· í˜•ì¡íŒ íŠ¹ì§• ì¶”ì¶œ
        self.features = nn.Sequential(
            # Block 1: ì ë‹¹í•œ ì‹œì‘
            nn.Conv2d(3, 24, kernel_size=3, padding=1),
            nn.BatchNorm2d(24),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(0.2),
            
            # Block 2: ì¤‘ê°„ í™•ì¥
            nn.Conv2d(24, 48, kernel_size=3, padding=1),
            nn.BatchNorm2d(48),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(0.3),
            
            # Block 3: ì¶©ë¶„í•œ íŠ¹ì§•
            nn.Conv2d(48, 96, kernel_size=3, padding=1),
            nn.BatchNorm2d(96),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((4, 4)),  # ì ë‹¹í•œ ì¶œë ¥
            nn.Dropout(0.3),
        )
        
        # ê· í˜•ì¡íŒ ë¶„ë¥˜ê¸°
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(96 * 4 * 4, 192),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(192, num_classes)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

# ë””ìŠ¤í”Œë ˆì´ OCR ëª¨ë“ˆ
from .display_ocr import DisplayOCR, MultiModelOCR

# ROS2 ë©”ì‹œì§€ íƒ€ì…ë“¤
from geometry_msgs.msg import Point

# ì»¤ìŠ¤í…€ ì„œë¹„ìŠ¤
from roomie_msgs.srv import (
    ButtonStatus, 
    SetVSMode,
    ElevatorStatus, 
    DoorStatus,
    Location
)
from roomie_msgs.msg import Obstacle, GlassDoorStatus
from roomie_msgs.action import Enroll
from std_srvs.srv import Trigger

# OpenNI2 í™˜ê²½ë³€ìˆ˜ ì„¤ì •
import os

def setup_openni2_environment():
    """OpenNI2 ì‹¤í–‰ì„ ìœ„í•œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •"""
    # ìš°ì„  ì‹¤ì œ Downloads ë””ë ‰í† ë¦¬ì˜ OpenNI2 ê²½ë¡œ í™•ì¸
    downloads_openni_path = os.path.expanduser("~/Downloads/OpenNI_SDK_ROS2_v1.0.2_20220809_b32e47_linux/ros2_astra_camera/astra_camera/openni2_redist/x64")
    project_openni_path = os.path.expanduser("~/project_ws/Roomie/ros2_ws/src/roomie_vs/OpenNI_SDK_ROS2_v1.0.2_20220809_b32e47_linux/ros2_astra_camera/astra_camera/openni2_redist/x64")
    
    # Downloadsì— ìˆëŠ” ê²ƒì„ ìš°ì„  í™•ì¸
    if os.path.exists(downloads_openni_path):
        openni_path = downloads_openni_path
        print(f"âœ… OpenNI2 ê²½ë¡œ ë°œê²¬ (Downloads): {openni_path}")
    elif os.path.exists(project_openni_path):
        openni_path = project_openni_path
        print(f"âœ… OpenNI2 ê²½ë¡œ ë°œê²¬ (Project): {openni_path}")
    else:
        print(f"âŒ OpenNI2 ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   í™•ì¸í•œ ê²½ë¡œë“¤:")
        print(f"   - {downloads_openni_path}")
        print(f"   - {project_openni_path}")
        return False
    
    # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
    os.environ['OPENNI2_REDIST'] = openni_path
    if 'LD_LIBRARY_PATH' in os.environ:
        os.environ['LD_LIBRARY_PATH'] += f":{openni_path}"
    else:
        os.environ['LD_LIBRARY_PATH'] = openni_path
    
    # PYTHONPATHì— ì‚¬ìš©ì ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ì¶”ê°€
    user_lib_path = "/home/jinhyuk2me/.local/lib/python3.12/site-packages"
    if 'PYTHONPATH' in os.environ:
        os.environ['PYTHONPATH'] += f":{user_lib_path}"
    else:
        os.environ['PYTHONPATH'] = user_lib_path
    
    print(f"âœ… OpenNI2 í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ: {openni_path}")
    print(f"   OPENNI2_REDIST: {os.environ.get('OPENNI2_REDIST')}")
    print(f"   LD_LIBRARY_PATHì— ì¶”ê°€ë¨: {openni_path}")
    return True

# í™˜ê²½ì„¤ì • ë¨¼ì € ì‹¤í–‰
if not setup_openni2_environment():
    import sys
    sys.exit(1)

# í™˜ê²½ì„¤ì • í›„ OpenNI2 import
try:
    from primesense import openni2
    from primesense import _openni2 as c_api
    print("âœ… primesense ëª¨ë“ˆ import ì„±ê³µ")
except ImportError as e:
    print(f"âŒ primesense ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    print("pip install primesense --break-system-packages ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”")
    import sys
    sys.exit(1)

class OpenNI2Camera:
    """OpenNI2ë¥¼ ì§ì ‘ ì‚¬ìš©í•œ ì•ˆì •ì ì¸ Astra ì¹´ë©”ë¼ í´ë˜ìŠ¤"""
    
    def __init__(self, logger):
        self.logger = logger
        self.is_running = False
        self.device = None
        self.rgb_stream = None
        self.depth_stream = None
        
        # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° (Astra ì‹¤ì œê°’ ì¶”ì •)
        self.depth_fx = 1140.6  # 2ë°° ì¦ê°€ (ìŠ¤ì¼€ì¼ ë³´ì •)
        self.depth_fy = 1140.6  # 2ë°° ì¦ê°€ (ìŠ¤ì¼€ì¼ ë³´ì •)
        self.depth_cx = 320.0
        self.depth_cy = 240.0
        
        # í˜„ì¬ í”„ë ˆì„ë“¤
        self.current_depth = None
        self.current_color = None
        self.frame_lock = threading.Lock()
        
    def initialize(self) -> bool:
        """OpenNI2 ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        try:
            self.logger.info("OpenNI2 ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹œì‘...")
            
            # OpenNI2 ì´ˆê¸°í™”
            openni2.initialize()
            self.logger.info("OpenNI2 ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ì¥ì¹˜ ì—´ê¸°
            self.device = openni2.Device.open_any()
            self.logger.info("ì¥ì¹˜ ì—´ê¸° ì™„ë£Œ")
            
            # ì¥ì¹˜ ì •ë³´ ì¶œë ¥
            device_info = self.device.get_device_info()
            self.logger.info(f"ì¥ì¹˜: {device_info.name.decode()} ({device_info.vendor.decode()})")
            
            # RGB ìŠ¤íŠ¸ë¦¼ ìƒì„±
            try:
                self.rgb_stream = self.device.create_color_stream()
                self.rgb_stream.start()
                video_mode = self.rgb_stream.get_video_mode()
                self.logger.info(f"RGB ìŠ¤íŠ¸ë¦¼: {video_mode.resolutionX}x{video_mode.resolutionY}@{video_mode.fps}fps")
            except Exception as e:
                self.logger.warning(f"RGB ìŠ¤íŠ¸ë¦¼ ìƒì„± ì‹¤íŒ¨: {e}")
                self.rgb_stream = None
            
            # Depth ìŠ¤íŠ¸ë¦¼ ìƒì„±
            try:
                self.depth_stream = self.device.create_depth_stream()
                self.depth_stream.start()
                video_mode = self.depth_stream.get_video_mode()
                self.logger.info(f"Depth ìŠ¤íŠ¸ë¦¼: {video_mode.resolutionX}x{video_mode.resolutionY}@{video_mode.fps}fps")
            except Exception as e:
                self.logger.warning(f"Depth ìŠ¤íŠ¸ë¦¼ ìƒì„± ì‹¤íŒ¨: {e}")
                self.depth_stream = None
            
            if not self.rgb_stream and not self.depth_stream:
                self.logger.error("RGBì™€ Depth ìŠ¤íŠ¸ë¦¼ ëª¨ë‘ ìƒì„± ì‹¤íŒ¨")
                return False
            
            self.is_running = True
            self.logger.info("OpenNI2 ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ!")
            return True
            
        except Exception as e:
            self.logger.error(f"OpenNI2 ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def get_frames(self) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """OpenNI2ì—ì„œ RGBì™€ Depth í”„ë ˆì„ íšë“"""
        if not self.is_running:
            raise RuntimeError("ì¹´ë©”ë¼ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            depth_image = None
            color_image = None
            
            # RGB í”„ë ˆì„ íšë“
            if self.rgb_stream:
                try:
                    rgb_frame = self.rgb_stream.read_frame()
                    rgb_data = rgb_frame.get_buffer_as_uint8()
                    rgb_array = np.frombuffer(rgb_data, dtype=np.uint8)
                    
                    h = rgb_frame.height
                    w = rgb_frame.width
                    rgb_image = rgb_array.reshape((h, w, 3))
                    
                    # BGRë¡œ ë³€í™˜
                    color_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)
                    
                except Exception as e:
                    self.logger.warning(f"RGB í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            # Depth í”„ë ˆì„ íšë“
            if self.depth_stream:
                try:
                    depth_frame = self.depth_stream.read_frame()
                    depth_data = depth_frame.get_buffer_as_uint16()
                    depth_array = np.frombuffer(depth_data, dtype=np.uint16)
                    
                    h = depth_frame.height
                    w = depth_frame.width  
                    depth_image = depth_array.reshape((h, w))
                    
                except Exception as e:
                    self.logger.warning(f"Depth í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            # í˜„ì¬ í”„ë ˆì„ ì €ì¥
            with self.frame_lock:
                if depth_image is not None:
                    self.current_depth = depth_image.copy()
                if color_image is not None:
                    self.current_color = color_image.copy()
            
            return depth_image, color_image
            
        except Exception as e:
            self.logger.error(f"í”„ë ˆì„ íšë“ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ì¹´ë©”ë¼ í”„ë ˆì„ íšë“ ì‹¤íŒ¨: {e}")
    
    def pixel_to_3d(self, u: int, v: int, depth_mm: int, is_flipped: bool = False) -> Tuple[float, float, float]:
        """2D í”½ì…€ ì¢Œí‘œë¥¼ 3D ì›”ë“œ ì¢Œí‘œë¡œ ë³€í™˜ (ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ê¸°ë°˜)"""
        if depth_mm <= 0:
            return 0.0, 0.0, 0.0
        
        # ì¢Œìš°ë°˜ì „ëœ ê²½ìš° ì›ë³¸ ì¢Œí‘œë¡œ ë³€í™˜
        if is_flipped:
            u = int(self.depth_cx * 2) - u  # 640 - u (í•´ìƒë„ê°€ 640x480ì¸ ê²½ìš°)
            
        # Zì¶• ê³„ì‚°: ì—­ì‚°ìœ¼ë¡œ ìˆ˜ì •
        z = 1000.0 / depth_mm if depth_mm > 0 else 0.0  # ì—­ì‚°
        
        # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ 3D ì¢Œí‘œ ê³„ì‚°
        # Xì¶• ê³„ì‚°: í”½ì…€ ì˜¤í”„ì…‹ì„ ì‹¤ì œ ê±°ë¦¬ë¡œ ë³€í™˜ (ìŠ¤ì¼€ì¼ë§ ì¡°ì •)
        pixel_offset_x = u - self.depth_cx  # ì¤‘ì‹¬ì—ì„œ í”½ì…€ ì°¨ì´
        x = (pixel_offset_x * z) / self.depth_fx  # ì›ë˜ í¬ê¸°ë¡œ ì¡°ì •
        
        # Yì¶• ê³„ì‚°: í”½ì…€ ì˜¤í”„ì…‹ì„ ì‹¤ì œ ê±°ë¦¬ë¡œ ë³€í™˜ (ìŠ¤ì¼€ì¼ë§ ì¡°ì •)
        pixel_offset_y = v - self.depth_cy  # ì¤‘ì‹¬ì—ì„œ í”½ì…€ ì°¨ì´
        y = (pixel_offset_y * z) / self.depth_fy  # ì›ë˜ í¬ê¸°ë¡œ ì¡°ì •
        
        return x, y, z
    
    def cleanup(self):
        """ì¹´ë©”ë¼ ì •ë¦¬"""
        self.is_running = False
        
        try:
            if self.rgb_stream:
                self.rgb_stream.stop()
                self.rgb_stream = None
                
            if self.depth_stream:
                self.depth_stream.stop()
                self.depth_stream = None
                
            if self.device:
                self.device.close()
                self.device = None
                
            openni2.unload()
            self.logger.info("OpenNI2 ì¹´ë©”ë¼ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ì¹´ë©”ë¼ ì •ë¦¬ ì¤‘ ì—ëŸ¬: {e}")

class WebCamCamera:
    """ì¼ë°˜ ì›¹ìº ì„ ìœ„í•œ ì¹´ë©”ë¼ í´ë˜ìŠ¤ (ìë™ íƒì§€ ì§€ì›)"""
    
    def __init__(self, logger, camera_id=None, camera_ids_to_try=None, camera_name="Webcam"):
        self.logger = logger
        self.preferred_camera_id = camera_id  # ìš°ì„  ì‹œë„í•  ID
        self.camera_ids_to_try = camera_ids_to_try or [0, 1, 2, 3]  # ì‹œë„í•  ID ëª©ë¡
        self.camera_name = camera_name
        self.actual_camera_id = None  # ì‹¤ì œ ì‘ë™í•˜ëŠ” ID
        self.is_running = False
        self.cap = None
        
        # í˜„ì¬ í”„ë ˆì„
        self.current_color = None
        self.current_depth = None  # ì›¹ìº ì€ depthê°€ ì—†ì§€ë§Œ ì¼ê´€ì„±ì„ ìœ„í•´ Noneìœ¼ë¡œ ì´ˆê¸°í™”
        self.frame_lock = threading.Lock()
        
    def initialize(self) -> bool:
        """ì›¹ìº  ì¹´ë©”ë¼ ìë™ íƒì§€ ì´ˆê¸°í™” (ë°±ì—”ë“œ ì •ë³´ ê³ ë ¤)"""
        try:
            # ìš°ì„  ì§€ì •ëœ camera_id ì‹œë„ (ìˆëŠ” ê²½ìš°)
            if self.preferred_camera_id is not None:
                if self._try_camera_id(self.preferred_camera_id):
                    return True
            
            # ëª¨ë“  ì¹´ë©”ë¼ ìŠ¤ìº”í•´ì„œ ë°±ì—”ë“œ ì •ë³´ ê³ ë ¤í•˜ì—¬ ì„ íƒ
            self.logger.info(f"{self.camera_name} ìë™ íƒì§€ ì‹œì‘... (ì‹œë„í•  ID: {self.camera_ids_to_try})")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë“¤ì„ ëª¨ë‘ ìŠ¤ìº”
            available_cameras = self._scan_available_cameras()
            
            if not available_cameras:
                self.logger.error(f"{self.camera_name} ìë™ íƒì§€ ì‹¤íŒ¨: ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ì—†ìŒ")
                return False
            
            # ì¹´ë©”ë¼ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ì¹´ë©”ë¼ ì„ íƒ
            selected_camera = self._select_appropriate_camera(available_cameras)
            
            if selected_camera is not None:
                return self._try_camera_id(selected_camera['id'])
            
            self.logger.error(f"{self.camera_name} ìë™ íƒì§€ ì‹¤íŒ¨: ì ì ˆí•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return False
            
        except Exception as e:
            self.logger.error(f"{self.camera_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _scan_available_cameras(self) -> list:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ì¹´ë©”ë¼ ìŠ¤ìº”í•˜ì—¬ ì •ë³´ ìˆ˜ì§‘"""
        available_cameras = []
        
        for camera_id in self.camera_ids_to_try:
            if self.preferred_camera_id is not None and camera_id == self.preferred_camera_id:
                continue  # ì´ë¯¸ ì‹œë„í–ˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ
                
            try:
                cap = cv2.VideoCapture(camera_id)
                if not cap.isOpened():
                    cap.release()
                    continue
                
                # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì½ê¸°
                ret, frame = cap.read()
                if not ret or frame is None:
                    cap.release()
                    continue
                
                # ì¹´ë©”ë¼ ì •ë³´ ìˆ˜ì§‘
                backend = cap.getBackendName()
                height, width = frame.shape[:2]
                
                # ì¹´ë©”ë¼ ë””ë°”ì´ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (v4l2-ctl ì‚¬ìš©)
                device_name = self._get_camera_device_name(camera_id)
                
                camera_info = {
                    'id': camera_id,
                    'backend': backend,
                    'width': width,
                    'height': height,
                    'device_name': device_name
                }
                
                available_cameras.append(camera_info)
                self.logger.info(f"ë°œê²¬ëœ ì¹´ë©”ë¼: ID={camera_id}, {width}x{height}, backend={backend}, device='{device_name}'")
                
                cap.release()
                
            except Exception as e:
                self.logger.debug(f"camera_id={camera_id} ìŠ¤ìº” ì¤‘ ì—ëŸ¬: {e}")
                continue
        
        return available_cameras
    
    def _get_camera_device_name(self, camera_id: int) -> str:
        """v4l2-ctlì„ ì‚¬ìš©í•˜ì—¬ ì¹´ë©”ë¼ ë””ë°”ì´ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°"""
        try:
            import subprocess
            device_path = f"/dev/video{camera_id}"
            
            # v4l2-ctlë¡œ ë””ë°”ì´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            result = subprocess.run(
                ['v4l2-ctl', '--device', device_path, '--info'],
                capture_output=True, text=True, timeout=3
            )
            
            if result.returncode == 0:
                # Card ì´ë¦„ ì¶”ì¶œ (ì‹¤ì œ ì¹´ë©”ë¼ ì´ë¦„)
                for line in result.stdout.split('\n'):
                    if 'Card type' in line:
                        card_name = line.split(':', 1)[1].strip()
                        return card_name
                    elif 'Device name' in line:
                        device_name = line.split(':', 1)[1].strip()
                        return device_name
            
            return f"Unknown (ID={camera_id})"
            
        except Exception as e:
            self.logger.debug(f"ì¹´ë©”ë¼ ë””ë°”ì´ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (ID={camera_id}): {e}")
            return f"Unknown (ID={camera_id})"
    
    def _select_appropriate_camera(self, available_cameras: list) -> dict:
        """ë””ë°”ì´ìŠ¤ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ì¹´ë©”ë¼ ì„ íƒ"""
        if not available_cameras:
            return None
        
        # ì „ë°© USB ì›¹ìº ì¸ ê²½ìš° (ì˜¤ì§ HCA ì¹´ë©”ë¼ì™€ ABKO ì¹´ë©”ë¼ë§Œ)
        if "USB" in self.camera_name:
            self.logger.info("ğŸ¯ ì „ë°© USB ì›¹ìº  ì„ íƒ ë¡œì§ ì‹œì‘ (HCA/ABKOë§Œ)")
            
            # 1ìˆœìœ„: HCAM01N ì°¾ê¸°
            for camera in available_cameras:
                device_name = camera['device_name'].lower()
                if 'hcam01n' in device_name:
                    self.logger.info(f"âœ… HCAM01N ì „ë°©ì¹´ë©”ë¼ ì„ íƒ: ID={camera['id']}, device='{camera['device_name']}'")
                    return camera
            
            # 2ìˆœìœ„: ABKO ë“± í—ˆìš©ëœ ì™¸ë¶€ USB ì›¹ìº ë§Œ ì°¾ê¸°
            for camera in available_cameras:
                device_name = camera['device_name'].lower()
                # í—ˆìš©ëœ ì „ë°© ì¹´ë©”ë¼ë§Œ (HD Webcam ì™„ì „ ì œì™¸)
                allowed_keywords = ['abko apc930', 'abko ap', 'apc930', 'abko', 'c920', 'c922', 'c930', 'logitech']
                
                # ë””ë²„ê·¸: ê° ì¹´ë©”ë¼ í™•ì¸
                self.logger.info(f"ğŸ” ì „ë°© ì¹´ë©”ë¼ ê²€ì‚¬: {device_name}")
                
                # HD Webcam ì™„ì „ ì œì™¸ (ì •í™•í•œ ë§¤ì¹­)
                if device_name.startswith('hd webcam') or device_name == 'hd webcam: hd webcam':
                    self.logger.info(f"âŒ HD Webcam ì œì™¸ë¨: {device_name}")
                    continue
                
                if any(keyword in device_name for keyword in allowed_keywords):
                    self.logger.info(f"ğŸ“¹ í—ˆìš©ëœ ì™¸ë¶€ USB ì›¹ìº  ì„ íƒ: ID={camera['id']}, device='{camera['device_name']}'")
                    return camera
            
            # ì „ë°©ìš© ì¹´ë©”ë¼ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
            self.logger.error("âŒ ì „ë°©ìš© ì¹´ë©”ë¼(HCA/ABKO)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            raise RuntimeError("ì „ë°©ìš© ì¹´ë©”ë¼(HCA ë˜ëŠ” ABKO)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # í›„ë°© ë‚´ì¥ ì¹´ë©”ë¼ì¸ ê²½ìš° (HD Webcam ë¬´ì¡°ê±´ ì„ íƒ)
        elif "Built-in" in self.camera_name:
            self.logger.info("ğŸ¯ í›„ë°© ë‚´ì¥ ì¹´ë©”ë¼ ì„ íƒ ë¡œì§ ì‹œì‘ (HD Webcam ë¬´ì¡°ê±´)")
            
            # 1ìˆœìœ„: ì •í™•í•œ HD Webcam ë¬´ì¡°ê±´ ì°¾ê¸°
            for camera in available_cameras:
                device_name = camera['device_name'].lower()
                if 'hd webcam: hd webcam' in device_name:
                    self.logger.info(f"âœ… ì •í™•í•œ HD Webcam í›„ë°©ì¹´ë©”ë¼ ì„ íƒ: ID={camera['id']}, device='{camera['device_name']}'")
                    return camera
            
            # HD Webcamì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°œìƒ
            self.logger.error("âŒ HD Webcamì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! í›„ë°© ì¹´ë©”ë¼ëŠ” ë°˜ë“œì‹œ HD Webcamì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            raise RuntimeError("í›„ë°© ì¹´ë©”ë¼ìš© HD Webcamì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ì„ íƒ
        return available_cameras[0]
    
    def _get_optimal_resolution(self, camera_id: int) -> tuple:
        """ì¹´ë©”ë¼ë³„ ìµœì  í•´ìƒë„ ë°˜í™˜"""
        try:
            # HCAM01N (ID 0)ì€ 800x600 ì§€ì›
            if camera_id == 0:
                # ë””ë°”ì´ìŠ¤ ì´ë¦„ìœ¼ë¡œ í•œë²ˆ ë” í™•ì¸
                device_name = self._get_camera_device_name(camera_id).lower()
                if 'hcam01n' in device_name:
                    self.logger.info(f"ğŸ“ HCAM01N ê³ í•´ìƒë„ ì„¤ì •: 800x600")
                    return (800, 600)
            
            # ê¸°ë³¸ í•´ìƒë„ 640x480
            self.logger.info(f"ğŸ“ ê¸°ë³¸ í•´ìƒë„ ì„¤ì •: 640x480 (camera_id={camera_id})")
            return (640, 480)
            
        except Exception as e:
            self.logger.warning(f"í•´ìƒë„ ì„¤ì • ì˜¤ë¥˜: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return (640, 480)
    
    def _try_camera_id(self, camera_id: int) -> bool:
        """íŠ¹ì • camera_idë¡œ ì›¹ìº  ì´ˆê¸°í™” ì‹œë„"""
        try:
            self.logger.info(f"{self.camera_name} camera_id={camera_id} ì‹œë„ ì¤‘...")
            
            cap = cv2.VideoCapture(camera_id)
            if not cap.isOpened():
                self.logger.debug(f"camera_id={camera_id} ì—´ê¸° ì‹¤íŒ¨")
                cap.release()
                return False
            
            # ì¹´ë©”ë¼ë³„ ìµœì  í•´ìƒë„ ì„¤ì •
            width, height = self._get_optimal_resolution(camera_id)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            
            # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì½ê¸°
            ret, frame = cap.read()
            if not ret or frame is None:
                self.logger.debug(f"camera_id={camera_id} í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                cap.release()
                return False
            
            # ì„±ê³µ!
            self.cap = cap
            self.actual_camera_id = camera_id
            self.is_running = True
            actual_height, actual_width = frame.shape[:2]
            
            # ì¹´ë©”ë¼ ë°±ì—”ë“œ ì •ë³´ í™•ì¸
            backend = cap.getBackendName()
            
            # ì„¤ì •ëœ í•´ìƒë„ì™€ ì‹¤ì œ í•´ìƒë„ ë¹„êµ
            if actual_width == width and actual_height == height:
                self.logger.info(f"âœ… {self.camera_name} ì´ˆê¸°í™” ì„±ê³µ: camera_id={camera_id}, {actual_width}x{actual_height}, backend={backend}")
            else:
                self.logger.warning(f"âš ï¸ {self.camera_name} í•´ìƒë„ ë¶ˆì¼ì¹˜: ìš”ì²­({width}x{height}) â†’ ì‹¤ì œ({actual_width}x{actual_height}), camera_id={camera_id}, backend={backend}")
            
            return True
            
        except Exception as e:
            self.logger.debug(f"camera_id={camera_id} ì‹œë„ ì¤‘ ì—ëŸ¬: {e}")
            return False
    
    def get_frames(self) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """ì›¹ìº ì—ì„œ í”„ë ˆì„ íšë“ (depthëŠ” None ë°˜í™˜)"""
        if not self.is_running or self.cap is None:
            raise RuntimeError("ì›¹ìº ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            ret, color_image = self.cap.read()
            if not ret:
                self.logger.warning("ì›¹ìº  í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                return None, None
            
            # í˜„ì¬ í”„ë ˆì„ ì €ì¥
            with self.frame_lock:
                self.current_color = color_image.copy()
            
            # depthëŠ” ì—†ìœ¼ë¯€ë¡œ None ë°˜í™˜
            return None, color_image
            
        except Exception as e:
            self.logger.error(f"ì›¹ìº  í”„ë ˆì„ íšë“ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ì›¹ìº  í”„ë ˆì„ íšë“ ì‹¤íŒ¨: {e}")
    
    def cleanup(self):
        """ì›¹ìº  ì •ë¦¬"""
        self.is_running = False
        
        try:
            if self.cap:
                self.cap.release()
                self.cap = None
                
            self.logger.info(f"{self.camera_name} ì •ë¦¬ ì™„ë£Œ (camera_id={self.actual_camera_id})")
            
        except Exception as e:
            self.logger.warning(f"ì›¹ìº  ì •ë¦¬ ì¤‘ ì—ëŸ¬: {e}")

class MultiCameraManager:
    """ë©€í‹° ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ê´€ë¦¬ í´ë˜ìŠ¤ (ìë™ ì›¹ìº  íƒì§€ ì§€ì›)"""
    
    def __init__(self, logger):
        self.logger = logger
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ camera_id ì½ê¸° (ì„ íƒì‚¬í•­)
        import os
        front_cam_id_env = os.getenv('FRONT_CAMERA_ID')
        rear_cam_id_env = os.getenv('REAR_CAMERA_ID')
        
        front_preferred_id = int(front_cam_id_env) if front_cam_id_env else None
        rear_preferred_id = int(rear_cam_id_env) if rear_cam_id_env else None
        
        # ì „ë°© ì¹´ë©”ë¼ë“¤ - ê³ ì • ì„¤ì •: ëìŠ¤ + USB ì›¹ìº 
        self.front_webcam = WebCamCamera(
            logger, 
            camera_id=front_preferred_id,  # í™˜ê²½ë³€ìˆ˜ ìš°ì„  ë˜ëŠ” None
            camera_ids_to_try=[0, 1, 2, 3],  # ë””ë°”ì´ìŠ¤ ì´ë¦„ìœ¼ë¡œ êµ¬ë¶„
            camera_name="Front USB Webcam"
        )
        self.front_depth = OpenNI2Camera(logger)  # ëìŠ¤ ì¹´ë©”ë¼
        
        # í›„ë°© ì¹´ë©”ë¼ - ê³ ì • ì„¤ì •: ë…¸íŠ¸ë¶ ë‚´ì¥ìº 
        self.rear_webcam = WebCamCamera(
            logger, 
            camera_id=rear_preferred_id,  # í™˜ê²½ë³€ìˆ˜ ìš°ì„  ë˜ëŠ” None
            camera_ids_to_try=[0, 1, 2, 3],  # ëª¨ë“  ID ì‹œë„í•˜ë˜ ë°±ì—”ë“œë¡œ ë‚´ì¥ìº  ì„ íƒ
            camera_name="Rear Built-in Camera"
        )
        
        # ì´ˆê¸°í™” ìƒíƒœ
        self.front_webcam_initialized = False
        self.front_depth_initialized = False
        self.rear_webcam_initialized = False
        
    def initialize_all_cameras(self):
        """ëª¨ë“  ì¹´ë©”ë¼ ë…ë¦½ì  ì´ˆê¸°í™” (ë ˆê±°ì‹œ ë©”ì„œë“œ - ëª¨ë“œ ê¸°ë°˜ ì´ˆê¸°í™”ë¡œ ëŒ€ì²´ë¨)"""
        self.logger.info("ğŸ“Œ ë ˆê±°ì‹œ ì „ì²´ ì¹´ë©”ë¼ ì´ˆê¸°í™” - í˜„ì¬ëŠ” ëª¨ë“œ ê¸°ë°˜ ë™ì  ì´ˆê¸°í™” ì‚¬ìš©")
        return True  # ëŒ€ê¸°ëª¨ë“œëŠ” í•­ìƒ ì§€ì›í•˜ë¯€ë¡œ True
    
    def _initialize_front_cameras(self):
        """ì „ë°© ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.logger.info("ğŸ”§ ì „ë°© ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        front_success = False
        
        # ì „ë°© ì›¹ìº  ì´ˆê¸°í™”
        try:
            if self.front_webcam.initialize():
                self.front_webcam_initialized = True
                self.logger.info("âœ… ì „ë°© ì›¹ìº  ì´ˆê¸°í™” ì„±ê³µ")
                front_success = True
            else:
                self.logger.warning("âš ï¸ ì „ë°© ì›¹ìº  ì´ˆê¸°í™” ì‹¤íŒ¨")
        except Exception as e:
            self.logger.warning(f"ì „ë°© ì›¹ìº  ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬: {e}")
        
        # ì „ë°© ëìŠ¤ ì¹´ë©”ë¼ ì´ˆê¸°í™”
        try:
            if self.front_depth.initialize():
                self.front_depth_initialized = True
                self.logger.info("âœ… ì „ë°© ëìŠ¤ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì„±ê³µ")
                front_success = True
            else:
                self.logger.warning("âš ï¸ ì „ë°© ëìŠ¤ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨")
        except Exception as e:
            self.logger.warning(f"ì „ë°© ëìŠ¤ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬: {e}")
            
        return front_success
    
    def _initialize_rear_camera(self):
        """í›„ë°© ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.logger.info("ğŸ”§ í›„ë°© ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        
        # í›„ë°© ì›¹ìº  ì´ˆê¸°í™”
        try:
            if self.rear_webcam.initialize():
                self.rear_webcam_initialized = True
                self.logger.info("âœ… í›„ë°© ì›¹ìº  ì´ˆê¸°í™” ì„±ê³µ")
                return True
            else:
                self.logger.warning("âš ï¸ í›„ë°© ì›¹ìº  ì´ˆê¸°í™” ì‹¤íŒ¨")
                return False
        except Exception as e:
            self.logger.warning(f"í›„ë°© ì›¹ìº  ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬: {e}")
            return False
    
    def get_camera_for_mode(self, mode_id):
        """ëª¨ë“œì— ë”°ë¥¸ ì¹´ë©”ë¼ ì„ íƒ (ëª¨ë“  ëª¨ë“œì—ì„œ ì¹´ë©”ë¼ í™œì„±í™”)"""
        if mode_id in [0, 1, 2]:  # í›„ë°© ê´€ë ¨ ëª¨ë“œë“¤
            if self.rear_webcam_initialized:
                if mode_id == 0:
                    return self.rear_webcam, None, "Rear Webcam (Standby)"
                else:  # ë“±ë¡ëª¨ë“œ(1), ì¶”ì ëª¨ë“œ(2)
                    return self.rear_webcam, None, "Rear Webcam"
            else:
                self.logger.warning(f"í›„ë°© ì›¹ìº ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ëª¨ë“œ {mode_id} ì‚¬ìš© ë¶ˆê°€")
                return None, None, "None"
                
        elif mode_id in [3, 4, 5, 6]:  # ì „ë°© ê´€ë ¨ ëª¨ë“œë“¤
            # ëª¨ë“  ì „ë°© ëª¨ë“œì—ì„œ ì›¹ìº  + ëìŠ¤ ì¹´ë©”ë¼ ì œê³µ (ëª¨ë¸ ì ìš©ì€ ë³„ë„)
            if self.front_webcam_initialized and self.front_depth_initialized:
                if mode_id == 3:
                    return self.front_webcam, self.front_depth, "Front Webcam + Depth (Elevator Out)"
                elif mode_id == 4:
                    return self.front_webcam, self.front_depth, "Front Webcam + Depth (Elevator In)"
                elif mode_id == 5:
                    return self.front_webcam, self.front_depth, "Front Webcam + Depth"
                else:  # mode_id == 6
                    return self.front_webcam, self.front_depth, "Front Webcam + Depth (Standby)"
            elif self.front_webcam_initialized:
                self.logger.warning("ëìŠ¤ ì¹´ë©”ë¼ ì—†ì´ ì›¹ìº ë§Œ ì‚¬ìš©")
                if mode_id == 3:
                    return self.front_webcam, None, "Front Webcam Only (Elevator Out)"
                elif mode_id == 4:
                    return self.front_webcam, None, "Front Webcam Only (Elevator In)"
                elif mode_id == 5:
                    return self.front_webcam, None, "Front Webcam Only"
                else:  # mode_id == 6
                    return self.front_webcam, None, "Front Webcam Only (Standby)"
            elif self.front_depth_initialized:
                # ëìŠ¤ ì¹´ë©”ë¼ë§Œ ìˆëŠ” ê²½ìš° - ë‹¨ë…ìœ¼ë¡œë„ ì‚¬ìš© ê°€ëŠ¥
                self.logger.info("ì›¹ìº  ì—†ì´ ëìŠ¤ ì¹´ë©”ë¼ë§Œ ì‚¬ìš©")
                if mode_id == 3:
                    return self.front_depth, None, "Front Depth Only (Elevator Out)"
                elif mode_id == 4:
                    return self.front_depth, None, "Front Depth Only (Elevator In)"
                elif mode_id == 5:
                    return self.front_depth, None, "Front Depth Only"
                else:  # mode_id == 6
                    return self.front_depth, None, "Front Depth Only (Standby)"
            else:
                self.logger.warning("ì „ë°© ì¹´ë©”ë¼ë“¤ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return None, None, "None"
        else:
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ë“±
            return None, None, "Simulation Mode"
    
    def cleanup_all_cameras(self):
        """ëª¨ë“  ì¹´ë©”ë¼ ì •ë¦¬"""
        self.logger.info("ëª¨ë“  ì¹´ë©”ë¼ ì •ë¦¬ ì‹œì‘...")
        
        try:
            self.front_webcam.cleanup()
        except Exception as e:
            self.logger.warning(f"ì „ë°© ì›¹ìº  ì •ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
            
        try:
            self.front_depth.cleanup()
        except Exception as e:
            self.logger.warning(f"ì „ë°© ëìŠ¤ ì •ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
            
        try:
            self.rear_webcam.cleanup()
        except Exception as e:
            self.logger.warning(f"í›„ë°© ì›¹ìº  ì •ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
        
        self.logger.info("ëª¨ë“  ì¹´ë©”ë¼ ì •ë¦¬ ì™„ë£Œ!")
    
    def get_required_cameras_for_mode(self, mode_id):
        """ëª¨ë“œë³„ í•„ìš”í•œ ì¹´ë©”ë¼ ëª©ë¡ ë°˜í™˜"""
        camera_requirements = {
            # í›„ë°© ê´€ë ¨ ëª¨ë“œ - ëª¨ë‘ í›„ë°© ì›¹ìº  ì‚¬ìš©
            0: ['rear_webcam'],           # í›„ë°© ëŒ€ê¸°: í›„ë°© ì›¹ìº  (í•­ìƒ ì¼œë†“ê¸°)
            1: ['rear_webcam'],           # ë“±ë¡ ëª¨ë“œ: í›„ë°© ì›¹ìº ë§Œ
            2: ['rear_webcam'],           # ì¶”ì  ëª¨ë“œ: í›„ë°© ì›¹ìº ë§Œ
            
            # ì „ë°© ê´€ë ¨ ëª¨ë“œ - ëª¨ë‘ ì „ë°© ì›¹ìº  + ëìŠ¤ ì‚¬ìš© (ì¹´ë©”ë¼ëŠ” í•­ìƒ ì¼œë‘ê³  ëª¨ë¸ë§Œ ì„ íƒì  ì ìš©)
            3: ['front_webcam', 'front_depth'],  # ì—˜ë¦¬ë² ì´í„° ì™¸ë¶€: ì „ë°© ì›¹ìº  + ëìŠ¤
            4: ['front_webcam', 'front_depth'],  # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€: ì „ë°© ì›¹ìº  + ëìŠ¤
            5: ['front_webcam', 'front_depth'],  # ì¼ë°˜ ì£¼í–‰: ì „ë°© ì›¹ìº  + ëìŠ¤
            6: ['front_webcam', 'front_depth'],  # ì „ë°© ëŒ€ê¸°: ì „ë°© ì›¹ìº  + ëìŠ¤ (í•­ìƒ ì¼œë†“ê¸°)
            
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë“¤ (ì¹´ë©”ë¼ ë¶ˆí•„ìš”)
            100: [], 101: [], 102: [], 103: [], 104: []
        }
        
        return camera_requirements.get(mode_id, [])
    
    def initialize_cameras_for_mode(self, mode_id):
        """ëª¨ë“œì— í•„ìš”í•œ ì¹´ë©”ë¼ë§Œ ì´ˆê¸°í™” (GPU ë¦¬ì†ŒìŠ¤ ì ˆì•½)"""
        required_cameras = self.get_required_cameras_for_mode(mode_id)
        
        self.logger.info(f"ğŸ¯ ëª¨ë“œ {mode_id}ì— í•„ìš”í•œ ì¹´ë©”ë¼: {required_cameras}")
        
        # ì „ë°©/í›„ë°© ì¹´ë©”ë¼ëŠ” ë…ë¦½ì ìœ¼ë¡œ ìœ ì§€ - ê¸°ì¡´ ì¹´ë©”ë¼ ì •ë¦¬í•˜ì§€ ì•ŠìŒ
        
        # í•„ìš”í•œ ì¹´ë©”ë¼ë§Œ ì´ˆê¸°í™”
        success = True
        initialized_cameras = []
        
        if 'rear_webcam' in required_cameras:
            if not self.rear_webcam_initialized:
                if self._initialize_rear_camera():
                    initialized_cameras.append('í›„ë°© ì›¹ìº ')
                else:
                    success = False
                    
        if 'front_webcam' in required_cameras:
            if not self.front_webcam_initialized:
                if self._initialize_front_webcam():
                    initialized_cameras.append('ì „ë°© ì›¹ìº ')
                else:
                    success = False
                    
        if 'front_depth' in required_cameras:
            if not self.front_depth_initialized:
                if self._initialize_front_depth():
                    initialized_cameras.append('ì „ë°© ëìŠ¤')
                else:
                    success = False
        
        # ê²°ê³¼ ë¡œê·¸
        if required_cameras:
            if initialized_cameras:
                self.logger.info(f"âœ… ëª¨ë“œ {mode_id} ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ: {', '.join(initialized_cameras)}")
            else:
                self.logger.info(f"ğŸ”„ ëª¨ë“œ {mode_id}: ì¹´ë©”ë¼ ì´ë¯¸ ì´ˆê¸°í™”ë¨")
        else:
            self.logger.info(f"ğŸŸ¡ ëª¨ë“œ {mode_id}: ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ - ì¹´ë©”ë¼ ë¶ˆí•„ìš”")
            
        return success or len(required_cameras) == 0
    
    def _initialize_front_webcam(self):
        """ì „ë°© ì›¹ìº ë§Œ ì´ˆê¸°í™”"""
        try:
            if self.front_webcam.initialize():
                self.front_webcam_initialized = True
                self.logger.info("âœ… ì „ë°© ì›¹ìº  ì´ˆê¸°í™” ì„±ê³µ")
                return True
            else:
                self.logger.warning("âš ï¸ ì „ë°© ì›¹ìº  ì´ˆê¸°í™” ì‹¤íŒ¨")
                return False
        except Exception as e:
            self.logger.warning(f"ì „ë°© ì›¹ìº  ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬: {e}")
            return False
    
    def _initialize_front_depth(self):
        """ì „ë°© ëìŠ¤ ì¹´ë©”ë¼ë§Œ ì´ˆê¸°í™”"""
        try:
            if self.front_depth.initialize():
                self.front_depth_initialized = True
                self.logger.info("âœ… ì „ë°© ëìŠ¤ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì„±ê³µ")
                return True
            else:
                self.logger.warning("âš ï¸ ì „ë°© ëìŠ¤ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨")
                return False
        except Exception as e:
            self.logger.warning(f"ì „ë°© ëìŠ¤ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬: {e}")
            return False

class ButtonPressedCNN:
    """ë²„íŠ¼ ëˆŒë¦¼ ìƒíƒœ ê°ì§€ CNN í´ë˜ìŠ¤"""
    
    def __init__(self, logger):
        self.logger = logger
        self.model_path = None
        self.model = None
        self.device = None
        self._initialize_model()
    
    def _initialize_model(self):
        """ë²„íŠ¼ ëˆŒë¦¼ ê°ì§€ CNN ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            import torch
            import torch.nn as nn
            import torch.nn.functional as F
            
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            
            # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
            model_path = self._find_pressed_model()
            if not model_path:
                self.logger.warning("âš ï¸ ë²„íŠ¼ ëˆŒë¦¼ ê°ì§€ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            # BalancedButtonCNN ì•„í‚¤í…ì²˜ ì •ì˜ (ì‹¤ì œ ì €ì¥ëœ ëª¨ë¸ê³¼ ì¼ì¹˜)
            class PressedButtonCNN(nn.Module):
                def __init__(self, num_classes=2):
                    super(PressedButtonCNN, self).__init__()
                    
                    # ê· í˜•ì¡íŒ íŠ¹ì§• ì¶”ì¶œ - ì‹¤ì œ ëª¨ë¸ êµ¬ì¡°ì™€ ì¼ì¹˜
                    self.features = nn.Sequential(
                        # Block 1: ì ë‹¹í•œ ì‹œì‘
                        nn.Conv2d(3, 24, kernel_size=3, padding=1),
                        nn.BatchNorm2d(24),
                        nn.ReLU(inplace=True),
                        nn.MaxPool2d(kernel_size=2, stride=2),
                        nn.Dropout(0.2),
                        
                        # Block 2: ì¤‘ê°„ í™•ì¥
                        nn.Conv2d(24, 48, kernel_size=3, padding=1),
                        nn.BatchNorm2d(48),
                        nn.ReLU(inplace=True),
                        nn.MaxPool2d(kernel_size=2, stride=2),
                        nn.Dropout(0.3),
                        
                        # Block 3: ì¶©ë¶„í•œ íŠ¹ì§•
                        nn.Conv2d(48, 96, kernel_size=3, padding=1),
                        nn.BatchNorm2d(96),
                        nn.ReLU(inplace=True),
                        nn.AdaptiveAvgPool2d((4, 4)),  # ì ë‹¹í•œ ì¶œë ¥
                        nn.Dropout(0.3),
                    )
                    
                    # ê· í˜•ì¡íŒ ë¶„ë¥˜ê¸°
                    self.classifier = nn.Sequential(
                        nn.Flatten(),
                        nn.Linear(96 * 4 * 4, 192),
                        nn.ReLU(inplace=True),
                        nn.Dropout(0.5),
                        nn.Linear(192, num_classes)
                    )
                
                def forward(self, x):
                    x = self.features(x)
                    x = self.classifier(x)
                    return x
            
            # ëª¨ë¸ ë¡œë“œ
            self.model = PressedButtonCNN(num_classes=2)
            self.model.load_state_dict(torch.load(model_path, map_location=self.device))
            self.model.to(self.device)
            self.model.eval()
            
            self.logger.info("âœ… ë²„íŠ¼ ëˆŒë¦¼ ê°ì§€ CNN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ë²„íŠ¼ ëˆŒë¦¼ CNN ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _find_pressed_model(self):
        """ë²„íŠ¼ ëˆŒë¦¼ ê°ì§€ ëª¨ë¸ íŒŒì¼ ì°¾ê¸°"""
        import os
        
        # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ ì°¾ê¸°
        current_dir = os.path.dirname(os.path.abspath(__file__))
        
        possible_paths = [
            # ìŠ¤í¬ë¦½íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
            os.path.join(current_dir, "..", "training", "button_pressed_cnn", "best_roomie_button_model_32px_with_metadata.pth"),
            # ì ˆëŒ€ ê²½ë¡œë“¤
            os.path.join(os.path.expanduser("~"), "project_ws", "Roomie", "ros2_ws", "src", "roomie_vs", "training", "button_pressed_cnn", "best_roomie_button_model_32px_with_metadata.pth"),
            os.path.join(os.getcwd(), "src", "roomie_vs", "training", "button_pressed_cnn", "best_roomie_button_model_32px_with_metadata.pth"),
            "src/roomie_vs/training/button_pressed_cnn/best_roomie_button_model_32px_with_metadata.pth",
            "training/button_pressed_cnn/best_roomie_button_model_32px_with_metadata.pth",
            "roomie_vs/training/button_pressed_cnn/best_roomie_button_model_32px_with_metadata.pth",
            "../training/button_pressed_cnn/best_roomie_button_model_32px_with_metadata.pth"
        ]
        
        for path in possible_paths:
            abs_path = os.path.abspath(path)
            if os.path.exists(abs_path):
                self.logger.info(f"ğŸ“‚ ë²„íŠ¼ ëˆŒë¦¼ ëª¨ë¸ ë°œê²¬: {abs_path}")
                return abs_path
        
        # ë””ë²„ê¹…ì„ ìœ„í•´ ëª¨ë“  ê²½ë¡œ ì¶œë ¥
        self.logger.debug("ğŸ” ë²„íŠ¼ ëˆŒë¦¼ ëª¨ë¸ ê²€ìƒ‰ ê²½ë¡œë“¤:")
        for path in possible_paths:
            abs_path = os.path.abspath(path)
            self.logger.debug(f"   - {abs_path} (ì¡´ì¬: {os.path.exists(abs_path)})")
        
        return None
    
    def classify_pressed(self, color_image: np.ndarray, bbox: tuple) -> dict:
        """ë²„íŠ¼ ROIì—ì„œ ëˆŒë¦¼ ìƒíƒœ ë¶„ë¥˜"""
        if self.model is None:
            return {'is_pressed': False, 'confidence': 0.0, 'method': 'no_model'}
            
        try:
            import torch
            
            # 1. ROI ì¶”ì¶œ
            x1, y1, x2, y2 = bbox
            roi = color_image[y1:y2, x1:x2]
            
            if roi.size == 0:
                return {'is_pressed': False, 'confidence': 0.0, 'method': 'empty_roi'}
            
            # 2. 32x32ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            roi_resized = cv2.resize(roi, (32, 32))
            
            # 3. ImageNet ì •ê·œí™”
            roi_normalized = self._preprocess_image(roi_resized)
            
            # 4. CNN ì¶”ë¡ 
            with torch.no_grad():
                roi_tensor = torch.from_numpy(roi_normalized).float().unsqueeze(0).to(self.device)
                outputs = self.model(roi_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                
                # 0: pressed, 1: unpressed
                pressed_prob = float(probabilities[0][0])
                unpressed_prob = float(probabilities[0][1])
                
                is_pressed = pressed_prob > unpressed_prob
                confidence = max(pressed_prob, unpressed_prob)
                
                return {
                    'is_pressed': is_pressed,
                    'confidence': confidence,
                    'pressed_prob': pressed_prob,
                    'unpressed_prob': unpressed_prob,
                    'method': 'cnn_only'
                }
                
        except Exception as e:
            self.logger.error(f"CNN ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return {'is_pressed': False, 'confidence': 0.0, 'method': 'error'}
    
    def _preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """ImageNet í‘œì¤€ ì „ì²˜ë¦¬"""
        # BGR â†’ RGB ë³€í™˜
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # 0-1 ì •ê·œí™”
        image_normalized = image_rgb.astype(np.float32) / 255.0
        
        # ImageNet ì •ê·œí™” (float32ë¡œ ëª…ì‹œì  ë³€í™˜)
        mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
        std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
        
        image_normalized = (image_normalized - mean) / std
        
        # CHW ìˆœì„œë¡œ ë³€ê²½
        image_chw = np.transpose(image_normalized, (2, 0, 1))
        
        return image_chw


class CNNButtonClassifier:
    """CNN ê¸°ë°˜ ë²„íŠ¼ ë¶„ë¥˜ í´ë˜ìŠ¤"""
    
    def __init__(self, logger):
        self.logger = logger
        self.model = None
        self.transform = None
        self.torch_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') if TORCH_AVAILABLE else None
        self.class_names = []
        self.button_id_mapping = {}
        
        if TORCH_AVAILABLE:
            # ëª¨ë¸ ë¡œë“œ
            self._load_cnn_model()
        else:
            self.logger.warning("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ CNN ë²„íŠ¼ ë¶„ë¥˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    def _load_cnn_model(self):
        """CNN ëª¨ë¸ê³¼ ì„¤ì • ë¡œë“œ"""
        try:
            # ëª¨ë¸ ê²½ë¡œ ì°¾ê¸° (ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ê²½ë¡œì™€ ì†ŒìŠ¤ ê²½ë¡œ ëª¨ë‘ ì‹œë„)
            current_dir = os.path.dirname(os.path.abspath(__file__))
            
            # 1. ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ê²½ë¡œ ì‹œë„
            from ament_index_python.packages import get_package_share_directory
            try:
                share_dir = get_package_share_directory('roomie_vs')
                model_dir = os.path.join(share_dir, 'training', 'button_cnn')
            except Exception:
                # 2. ì†ŒìŠ¤ ê²½ë¡œ ì‹œë„ (ê°œë°œ ì¤‘)
                model_dir = os.path.join(current_dir, '..', 'training', 'button_cnn')
            
            model_path = os.path.join(model_dir, 'best_smart_balanced_model_32px_with_metadata.pth')
            config_path = os.path.join(model_dir, 'best_smart_balanced_model_32px_with_metadata_config.yaml')
            
            if not os.path.exists(model_path):
                # ì†ŒìŠ¤ ê²½ë¡œë„ ì‹œë„
                source_model_dir = os.path.join(current_dir, '..', 'training', 'button_cnn')
                model_path = os.path.join(source_model_dir, 'best_smart_balanced_model_32px_with_metadata.pth')
                config_path = os.path.join(source_model_dir, 'best_smart_balanced_model_32px_with_metadata_config.yaml')
                
                if not os.path.exists(model_path):
                    self.logger.warning(f"âš ï¸ CNN ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                    return False
                
            if not os.path.exists(config_path):
                self.logger.warning(f"âš ï¸ CNN ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
                return False
            
            # ì„¤ì • íŒŒì¼ ë¡œë“œ
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
            
            self.class_names = config['dataset_info']['class_names']
            
            # í´ë˜ìŠ¤ëª…ì„ ë²„íŠ¼ IDë¡œ ë§¤í•‘
            self._create_button_mapping()
            
            # ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„± ë° state_dict ë¡œë“œ
            self.model = BalancedButtonCNN(num_classes=len(self.class_names))
            
            # state_dict ì§ì ‘ ë¡œë“œ (ì°¸ê³  ì½”ë“œ ë°©ì‹)
            self.model.load_state_dict(torch.load(model_path, map_location=self.torch_device))
            
            self.model.to(self.torch_device)
            self.model.eval()
            
            # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ì„¤ì • íŒŒì¼ ê¸°ë°˜)
            self.transform = transforms.Compose([
                transforms.Resize((32, 32)),
                transforms.ToTensor(),
                transforms.Normalize(
                    mean=config['preprocessing']['normalize_mean'],
                    std=config['preprocessing']['normalize_std']
                )
            ])
            
            self.logger.info(f"âœ… CNN ë²„íŠ¼ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {len(self.class_names)}ê°œ í´ë˜ìŠ¤")
            self.logger.info(f"ğŸ“‹ ì§€ì› ë²„íŠ¼: {self.class_names}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ CNN ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def _create_button_mapping(self):
        """í´ë˜ìŠ¤ëª…ì„ ë²„íŠ¼ IDë¡œ ë§¤í•‘"""
        self.button_id_mapping = {
            'btn_1': 1, 'btn_2': 2, 'btn_3': 3, 'btn_4': 4,
            'btn_5': 5, 'btn_6': 6, 'btn_7': 7, 'btn_8': 8,
            'btn_9': 9, 'btn_10': 10, 'btn_11': 11, 'btn_12': 12,
            'btn_b1': 13, 'btn_b2': 14,
            'btn_open': 102, 'btn_close': 103,
            'btn_upward': 101, 'btn_downward': 100
        }
    
    def classify_button(self, color_image: np.ndarray, button_bbox: tuple) -> dict:
        """ê°œë³„ ë²„íŠ¼ ì´ë¯¸ì§€ë¥¼ CNNìœ¼ë¡œ ë¶„ë¥˜"""
        if self.model is None or not TORCH_AVAILABLE:
            return None
            
        try:
            # ë²„íŠ¼ ì˜ì—­ í¬ë¡­
            x1, y1, x2, y2 = button_bbox
            button_crop = color_image[y1:y2, x1:x2]
            
            if button_crop.size == 0:
                return None
            
            # OpenCV â†’ PIL ë³€í™˜
            button_crop_rgb = cv2.cvtColor(button_crop, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(button_crop_rgb)
            
            # ì „ì²˜ë¦¬
            input_tensor = self.transform(pil_image).unsqueeze(0).to(self.torch_device)
            
            # ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                predicted_class = torch.argmax(probabilities, dim=1).item()
                confidence = probabilities[0][predicted_class].item()
            
            # ê²°ê³¼ ë§¤í•‘
            class_name = self.class_names[predicted_class]
            button_id = self.button_id_mapping.get(class_name, 'unknown')
            
            # ë²„íŠ¼ íƒ€ì… ë¶„ë¥˜
            if button_id in [102, 103]:  # ì—´ê¸°/ë‹«ê¸°
                floor_type = 'control'
            elif button_id in [13, 14]:  # B1/B2
                floor_type = 'basement'
            elif button_id in [100, 101]:  # ìƒí–‰/í•˜í–‰
                floor_type = 'direction'
            else:  # ì¸µìˆ˜ ë²„íŠ¼
                floor_type = 'floor'
            
            return {
                'button_id': button_id,
                'confidence': confidence,
                'class_name': class_name,
                'floor_type': floor_type,
                'recognition_method': 'cnn_classification'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ CNN ë²„íŠ¼ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return None


class MultiModelDetector:
    """ë‹¤ì¤‘ YOLO ëª¨ë¸ì„ ì§€ì›í•˜ëŠ” íƒì§€ í´ë˜ìŠ¤"""
    
    def __init__(self, logger):
        self.logger = logger
        self.models = {}
        self.current_model_name = None
        self.current_model = None
        self.button_pressed_cnn = None  # ë‚˜ì¤‘ì— ì„¤ì •ë¨
        
        # ğŸ“¦ ë°•ìŠ¤ ì•ˆì •í™”ë¥¼ ìœ„í•œ ë³€ìˆ˜ë“¤
        self.previous_objects = []  # ì´ì „ í”„ë ˆì„ ê°ì²´ë“¤
        self.object_tracking_threshold = 0.5  # IoU ì„ê³„ê°’ (ê²¹ì¹¨ íŒì •)
        self.stability_frames = 3  # ì•ˆì •í™”ë¥¼ ìœ„í•œ ìµœì†Œ í”„ë ˆì„ ìˆ˜
        self.object_history = {}  # ê°ì²´ë³„ íˆìŠ¤í† ë¦¬ {id: [frame_data, ...]}
        
    def set_button_pressed_cnn(self, button_pressed_cnn):
        """ë²„íŠ¼ ëˆŒë¦¼ ê°ì§€ CNN ì„¤ì •"""
        self.button_pressed_cnn = button_pressed_cnn
        
        # ëª¨ë¸ë³„ í´ë˜ìŠ¤ ì •ì˜ (ì‹¤ì œ ëª¨ë¸ ìˆœì„œì— ë§ê²Œ ìˆ˜ì •)
        self.model_classes = {
            'normal': ['chair', 'door', 'person'],  # ì‹¤ì œ ìˆœì„œ: 0=chair, 1=door, 2=person
            'elevator': ['button', 'direction_light', 'display', 'door']  # ì—˜ë¦¬ë² ì´í„°ìš©: ë²„íŠ¼, ë°©í–¥ë“±, ë””ìŠ¤í”Œë ˆì´, ë¬¸
        }
        
        # ëª¨ë¸ë³„ ID ë§¤í•‘ (ì‹¤ì œ ìˆœì„œì— ë§ê²Œ ìˆ˜ì •)
        self.model_id_maps = {
            'normal': {
                'chair': 'CHAIR',  # 0: chair
                'door': 'DOOR',    # 1: door
                'person': 'PERSON' # 2: person
            },
            'elevator': {
                'button': 'BUTTON',
                'direction_light': 'DIRECTION_LIGHT',
                'display': 'DISPLAY',
                'door': 'DOOR'
            }
        }
        

        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_models()
        
    def _initialize_models(self):
        """ëª¨ë“  YOLO ëª¨ë¸ ì´ˆê¸°í™”"""
        self.logger.info("ë‹¤ì¤‘ YOLO ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")
        
        try:
            from ultralytics import YOLO
            
            # 1. ì¼ë°˜ ì£¼í–‰ìš© ëª¨ë¸ (training/normal/best.pt)
            normal_model_path = self._find_model_in_subdir('normal', 'best.pt')
            if normal_model_path:
                try:
                    self.models['normal'] = YOLO(normal_model_path)
                    # ğŸš€ GPU ì„¤ì • ì¶”ê°€
                    self.models['normal'].to('cuda')
                    # ì‹¤ì œ ëª¨ë¸ í´ë˜ìŠ¤ í™•ì¸
                    if hasattr(self.models['normal'], 'names'):
                        actual_classes = list(self.models['normal'].names.values())
                        self.logger.info(f"âœ… ì¼ë°˜ ì£¼í–‰ ëª¨ë¸ ë¡œë”© ì„±ê³µ (GPU): {normal_model_path}")
                        self.logger.info(f"ğŸ“‹ ì‹¤ì œ í´ë˜ìŠ¤: {actual_classes}")
                    else:
                        self.logger.info(f"âœ… ì¼ë°˜ ì£¼í–‰ ëª¨ë¸ ë¡œë”© ì„±ê³µ (GPU): {normal_model_path}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì¼ë°˜ ì£¼í–‰ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            else:
                # ì¼ë°˜ ì£¼í–‰ìš© ëª¨ë¸ì´ ì—†ìœ¼ë©´ COCO ì‚¬ì „í›ˆë ¨ ëª¨ë¸ ì‚¬ìš©
                try:
                    self.models['normal'] = YOLO('yolov8n.pt')
                    # ğŸš€ GPU ì„¤ì • ì¶”ê°€
                    self.models['normal'].to('cuda')
                    # COCO ëª¨ë¸ í´ë˜ìŠ¤ í™•ì¸
                    if hasattr(self.models['normal'], 'names'):
                        actual_classes = list(self.models['normal'].names.values())
                        self.logger.info("âœ… ì¼ë°˜ ì£¼í–‰ìš©ìœ¼ë¡œ COCO ì‚¬ì „í›ˆë ¨ ëª¨ë¸(yolov8n.pt) ì‚¬ìš© (GPU)")
                        self.logger.info(f"ğŸ“‹ COCO í´ë˜ìŠ¤ (ì „ì²´ {len(actual_classes)}ê°œ): person, chair ë“±ë§Œ í•„í„°ë§ ì‚¬ìš©")
                    else:
                        self.logger.info("âœ… ì¼ë°˜ ì£¼í–‰ìš©ìœ¼ë¡œ COCO ì‚¬ì „í›ˆë ¨ ëª¨ë¸(yolov8n.pt) ì‚¬ìš© (GPU)")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ COCO ëª¨ë¸ë„ ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 2. ì—˜ë¦¬ë² ì´í„°ìš© ëª¨ë¸ (best_v2.pt ìš°ì„ , best_v1.pt, best.pt ìˆœì„œ)
            elevator_model_path = self._find_elevator_model()
            if elevator_model_path:
                try:
                    self.models['elevator'] = YOLO(elevator_model_path)
                    # ğŸš€ GPU ì„¤ì • ì¶”ê°€
                    self.models['elevator'].to('cuda')
                    # ì‹¤ì œ ëª¨ë¸ í´ë˜ìŠ¤ í™•ì¸
                    if hasattr(self.models['elevator'], 'names'):
                        actual_classes = list(self.models['elevator'].names.values())
                        self.logger.info(f"âœ… ì—˜ë¦¬ë² ì´í„° ëª¨ë¸ ë¡œë”© ì„±ê³µ (GPU): {elevator_model_path}")
                        self.logger.info(f"ğŸ“‹ ì‹¤ì œ í´ë˜ìŠ¤: {actual_classes}")
                    else:
                        self.logger.info(f"âœ… ì—˜ë¦¬ë² ì´í„° ëª¨ë¸ ë¡œë”© ì„±ê³µ (GPU): {elevator_model_path}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì—˜ë¦¬ë² ì´í„° ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            else:
                self.logger.warning("âš ï¸ ì—˜ë¦¬ë² ì´í„°ìš© ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ì´ˆê¸°í™” ê²°ê³¼
            loaded_models = list(self.models.keys())
            self.logger.info(f"ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {loaded_models} ({len(loaded_models)}/2ê°œ)")
            
            # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
            if 'elevator' in self.models:
                self.current_model_name = 'elevator'
                self.current_model = self.models['elevator']
            elif 'normal' in self.models:
                self.current_model_name = 'normal'
                self.current_model = self.models['normal']
            
            return len(self.models) > 0
                
        except ImportError:
            self.logger.error("ultralytics íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install ultralytics")
            raise ImportError("ultralytics íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”")
        except Exception as e:
            self.logger.error(f"ë‹¤ì¤‘ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _find_model(self, model_filename):
        """ëª¨ë¸ íŒŒì¼ ì°¾ê¸°"""
        script_dir = os.path.dirname(os.path.abspath(__file__))
        
        possible_dirs = [
            os.path.join(script_dir, "..", "training"),
            os.path.join(script_dir, "..", "models"),
            os.path.join(os.path.expanduser("~"), "project_ws", "Roomie", "ros2_ws", "src", "roomie_vs", "training"),
            os.path.join(os.path.expanduser("~"), "project_ws", "Roomie", "ros2_ws", "src", "roomie_vs", "models"),
            os.path.join(os.getcwd(), "ros2_ws", "src", "roomie_vs", "training"),
            os.path.join(os.getcwd(), "ros2_ws", "src", "roomie_vs", "models"),
            "ros2_ws/src/roomie_vs/training",
            "ros2_ws/src/roomie_vs/models"
        ]
        
        for search_dir in possible_dirs:
            if os.path.exists(search_dir):
                model_path = os.path.join(search_dir, model_filename)
                if os.path.exists(model_path):
                    self.logger.debug(f"ëª¨ë¸ ë°œê²¬: {model_path}")
                    return model_path
        
        self.logger.debug(f"ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_filename}")
        return None
    
    def _find_model_in_subdir(self, subdir, model_filename):
        """training í´ë”ì˜ ì„œë¸Œë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ íŒŒì¼ ì°¾ê¸°"""
        script_dir = os.path.dirname(os.path.abspath(__file__))
        
        possible_dirs = [
            os.path.join(script_dir, "..", "training"),
            os.path.join(os.path.expanduser("~"), "project_ws", "Roomie", "ros2_ws", "src", "roomie_vs", "training"),
            os.path.join(os.getcwd(), "ros2_ws", "src", "roomie_vs", "training"),
            "ros2_ws/src/roomie_vs/training"
        ]
        
        for search_dir in possible_dirs:
            if os.path.exists(search_dir):
                model_path = os.path.join(search_dir, subdir, model_filename)
                if os.path.exists(model_path):
                    self.logger.debug(f"ëª¨ë¸ ë°œê²¬: {model_path}")
                    return model_path
        
        self.logger.debug(f"ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {subdir}/{model_filename}")
        return None
    
    def _find_elevator_model(self):
        """ì—˜ë¦¬ë² ì´í„° ëª¨ë¸ ì°¾ê¸° (best_v2.pt ìš°ì„ )"""
        script_dir = os.path.dirname(os.path.abspath(__file__))
        
        possible_dirs = [
            os.path.join(script_dir, "..", "training"),
            os.path.join(os.path.expanduser("~"), "project_ws", "Roomie", "ros2_ws", "src", "roomie_vs", "training"),
            os.path.join(os.getcwd(), "ros2_ws", "src", "roomie_vs", "training"),
            "ros2_ws/src/roomie_vs/training"
        ]
        
        for search_dir in possible_dirs:
            if os.path.exists(search_dir):
                elevator_dir = os.path.join(search_dir, "elevator")
                if os.path.exists(elevator_dir):
                    # 1ìˆœìœ„: best_v2.pt (ìµœì‹  ë²„ì „)
                    best_v2_path = os.path.join(elevator_dir, "best_v2.pt")
                    if os.path.exists(best_v2_path):
                        self.logger.info(f"âœ… ì—˜ë¦¬ë² ì´í„° ëª¨ë¸ ë°œê²¬ (v2): {best_v2_path}")
                        return best_v2_path
                    
                    # 2ìˆœìœ„: best_v1.pt (ì´ì „ ë²„ì „)
                    best_v1_path = os.path.join(elevator_dir, "best_v1.pt")
                    if os.path.exists(best_v1_path):
                        self.logger.info(f"âœ… ì—˜ë¦¬ë² ì´í„° ëª¨ë¸ ë°œê²¬ (v1): {best_v1_path}")
                        return best_v1_path
                    
                    # 3ìˆœìœ„: best.pt (ê¸°ë³¸)
                    best_path = os.path.join(elevator_dir, "best.pt")
                    if os.path.exists(best_path):
                        self.logger.info(f"âœ… ì—˜ë¦¬ë² ì´í„° ëª¨ë¸ ë°œê²¬ (ê¸°ë³¸): {best_path}")
                        return best_path
        
        self.logger.warning("âš ï¸ ì—˜ë¦¬ë² ì´í„°ìš© ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (best_v2.pt, best_v1.pt, best.pt)")
        return None
    
    def set_model_for_mode(self, mode_id):
        """ëª¨ë“œì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ"""
        try:
            if mode_id == 5:  # ì¼ë°˜ ì£¼í–‰ ëª¨ë“œ
                if 'normal' in self.models:
                    old_model = self.current_model_name
                    self.current_model_name = 'normal'
                    self.current_model = self.models['normal']
                    if old_model != 'normal':
                        self.logger.info(f"ğŸ¤– ëª¨ë¸ ë³€ê²½: {old_model} â†’ normal (ì¼ë°˜ ì£¼í–‰ìš©)")
                    return True
                else:
                    self.logger.warning("ì¼ë°˜ ì£¼í–‰ìš© ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
                    return False
                    
            elif mode_id in [3, 4]:  # ì—˜ë¦¬ë² ì´í„° ëª¨ë“œ
                if 'elevator' in self.models:
                    old_model = self.current_model_name
                    self.current_model_name = 'elevator'
                    self.current_model = self.models['elevator']
                    if old_model != 'elevator':
                        self.logger.info(f"ğŸ¤– ëª¨ë¸ ë³€ê²½: {old_model} â†’ elevator (ì—˜ë¦¬ë² ì´í„°ìš©)")
                    return True
                else:
                    self.logger.warning("ì—˜ë¦¬ë² ì´í„°ìš© ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
                    return False
            else:
                # ë‹¤ë¥¸ ëª¨ë“œëŠ” ëª¨ë¸ ì‚¬ìš© ì•ˆí•¨
                if self.current_model_name:
                    self.logger.info(f"ğŸ¤– ëª¨ë¸ ë¹„í™œì„±í™” (ëª¨ë“œ {mode_id})")
                    self.current_model_name = None
                    self.current_model = None
                return True
                
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ì„ íƒ ì¤‘ ì—ëŸ¬: {e}")
            return False
    
    def detect_objects(self, color_image: np.ndarray, depth_image: np.ndarray, conf_threshold: float = 0.7, mode_id: int = 0) -> List[dict]:
        """í˜„ì¬ ì„ íƒëœ ëª¨ë¸ë¡œ ê°ì²´ íƒì§€ (ëª¨ë“œë³„ ë²„íŠ¼ ì¸ì‹ í¬í•¨)"""
        if color_image is None or self.current_model is None:
            return []
            
        try:
            objects = self._detect_with_current_model(color_image, depth_image, conf_threshold)
            return objects
        except Exception as e:
            self.logger.error(f"ê°ì²´ íƒì§€ ì¤‘ ì—ëŸ¬: {e}")
            return []
    
    def _detect_with_current_model(self, color_image: np.ndarray, depth_image: np.ndarray, conf_threshold: float = 0.7) -> List[dict]:
        """í˜„ì¬ ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°ì²´ íƒì§€"""
        try:
            results = self.current_model.predict(
                color_image, 
                conf=conf_threshold,
                device='cuda',  # ğŸš€ GPU ì‚¬ìš©
                verbose=False
            )
            
            objects = []
            if results and len(results) > 0:
                result = results[0]
                
                if result.boxes is not None and len(result.boxes) > 0:
                    boxes = result.boxes.xyxy.cpu().numpy()
                    confs = result.boxes.conf.cpu().numpy()
                    classes = result.boxes.cls.cpu().numpy()
                    
                    # ì‹¤ì œ ëª¨ë¸ì˜ í´ë˜ìŠ¤ ì´ë¦„ ì‚¬ìš© (ëª¨ë¸ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°)
                    if hasattr(self.current_model, 'names'):
                        # YOLO ëª¨ë¸ì´ ê°€ì§„ ì‹¤ì œ í´ë˜ìŠ¤ ì´ë¦„ë“¤
                        actual_class_names = list(self.current_model.names.values())
                        self.logger.debug(f"ì‹¤ì œ ëª¨ë¸ í´ë˜ìŠ¤: {actual_class_names}")
                        current_class_names = actual_class_names
                    else:
                        # ë°±ì—…: ìˆ˜ë™ ì •ì˜ëœ í´ë˜ìŠ¤ ì´ë¦„
                        current_class_names = self.model_classes.get(self.current_model_name, [])
                        self.logger.warning(f"ëª¨ë¸ì—ì„œ í´ë˜ìŠ¤ ì´ë¦„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ìˆ˜ë™ ì •ì˜ ì‚¬ìš©: {current_class_names}")
                    
                    # ID ë§¤í•‘ë„ ì‹¤ì œ í´ë˜ìŠ¤ ì´ë¦„ì— ë§ê²Œ ë™ì  ìƒì„±
                    if hasattr(self.current_model, 'names'):
                        current_id_map = {name: name.upper() for name in current_class_names}
                    else:
                        current_id_map = self.model_id_maps.get(self.current_model_name, {})
                    
                    for box, conf, cls in zip(boxes, confs, classes):
                        x1, y1, x2, y2 = box.astype(int)
                        center_x = int((x1 + x2) / 2)
                        center_y = int((y1 + y2) / 2)
                        width = x2 - x1
                        height = y2 - y1
                        radius = int(max(width, height) / 2)
                        
                        # í´ë˜ìŠ¤ ì •ë³´
                        class_id = int(cls)
                        
                        # COCO ëª¨ë¸ì˜ ê²½ìš° í´ë˜ìŠ¤ ë§¤í•‘
                        if self.current_model_name == 'normal' and 'normal' not in self.models:
                            # COCO í´ë˜ìŠ¤ ì´ë¦„ë“¤
                            coco_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 
                                         'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 
                                         'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 
                                         'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 
                                         'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 
                                         'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 
                                         'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 
                                         'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 
                                         'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 
                                         'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 
                                         'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 
                                         'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 
                                         'scissors', 'teddy bear', 'hair drier', 'toothbrush']
                            
                            if class_id < len(coco_names):
                                class_name = coco_names[class_id]
                                # ê´€ì‹¬ ìˆëŠ” ê°ì²´ë§Œ í•„í„°ë§
                                if class_name not in ['person', 'chair']:
                                    continue  # ì‚¬ëŒê³¼ ì˜ìë§Œ íƒì§€
                            else:
                                class_name = f"unknown_{class_id}"
                        else:
                            # ì»¤ìŠ¤í…€ ëª¨ë¸ì˜ ê²½ìš°
                            if class_id < len(current_class_names):
                                class_name = current_class_names[class_id]
                            else:
                                class_name = f"unknown_{class_id}"
                        
                        # Depth ì •ë³´
                        depth_value = depth_image[center_y, center_x] if depth_image is not None else 1000
                        
                        # ê°ì²´ë³„ íŠ¹ë³„ ì²˜ë¦¬
                        is_pressed = False
                        pressed_confidence = 0.0
                        pressed_method = 'none'
                        object_id = current_id_map.get(class_name, class_name.upper())
                        
                        if class_name == 'button':
                            # CNN ê¸°ë°˜ ë²„íŠ¼ ëˆŒë¦¼ ê°ì§€
                            pressed_result = self._check_button_pressed_cnn(color_image, (x1, y1, x2, y2))
                            is_pressed = pressed_result['is_pressed']
                            pressed_confidence = pressed_result['confidence']
                            pressed_method = pressed_result['method']
                            # pressed_probê³¼ unpressed_prob ê°’ë„ ì €ì¥
                            pressed_prob = pressed_result.get('pressed_prob', 0.0)
                            unpressed_prob = pressed_result.get('unpressed_prob', 0.0)
                        
                        objects.append({
                            'center': (center_x, center_y),
                            'radius': radius,
                            'depth_mm': int(depth_value),
                            'is_pressed': is_pressed,
                            'pressed_confidence': pressed_confidence,
                            'pressed_method': pressed_method,
                            'pressed_prob': pressed_prob if class_name == 'button' else 0.0,
                            'unpressed_prob': unpressed_prob if class_name == 'button' else 0.0,
                            'class_name': class_name,
                            'class_id': class_id,
                            'object_id': object_id,
                            'confidence': float(conf),
                            'bbox': (x1, y1, x2, y2),
                            'is_button': class_name == 'button',
                            'model_name': self.current_model_name
                        })
            
            # ğŸ“¦ ë°•ìŠ¤ ì•ˆì •í™” ì ìš©
            stabilized_objects = self._apply_box_stabilization(objects)
            
            self.logger.debug(f"{self.current_model_name} ëª¨ë¸ë¡œ {len(objects)}ê°œ ê°ì²´ íƒì§€ â†’ {len(stabilized_objects)}ê°œ ì•ˆì •í™”")
            return stabilized_objects
            
        except Exception as e:
            self.logger.error(f"{self.current_model_name} ëª¨ë¸ íƒì§€ ì—ëŸ¬: {e}")
            return []
    
    def _check_button_pressed_cnn(self, color_image: np.ndarray, bbox: tuple) -> dict:
        """CNN ê¸°ë°˜ ë²„íŠ¼ ëˆŒë¦¼ ìƒíƒœ í™•ì¸"""
        if self.button_pressed_cnn is None:
            return {'is_pressed': False, 'confidence': 0.0, 'method': 'no_cnn'}
        
        return self.button_pressed_cnn.classify_pressed(color_image, bbox)
    
    def _apply_box_stabilization(self, objects: List[dict]) -> List[dict]:
        """ë°•ìŠ¤ ê²¹ì¹¨ ì•ˆì •í™” ì ìš©"""
        if not objects:
            return objects
        
        # 1. NMS (Non-Maximum Suppression) ì ìš©
        nms_objects = self._apply_nms(objects)
        
        # 2. ê°ì²´ ì¶”ì  ë° ì•ˆì •í™”
        tracked_objects = self._apply_object_tracking(nms_objects)
        
        # 3. ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§
        filtered_objects = self._apply_confidence_filtering(tracked_objects)
        
        return filtered_objects
    
    def _apply_nms(self, objects: List[dict], iou_threshold: float = 0.5) -> List[dict]:
        """Non-Maximum Suppressionì„ ì ìš©í•˜ì—¬ ê²¹ì¹˜ëŠ” ë°•ìŠ¤ ì œê±°"""
        if len(objects) <= 1:
            return objects
        
        # í´ë˜ìŠ¤ë³„ë¡œ NMS ì ìš©
        class_groups = {}
        for obj in objects:
            class_name = obj['class_name']
            if class_name not in class_groups:
                class_groups[class_name] = []
            class_groups[class_name].append(obj)
        
        nms_objects = []
        for class_name, class_objects in class_groups.items():
            if len(class_objects) <= 1:
                nms_objects.extend(class_objects)
                continue
            
            # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            class_objects.sort(key=lambda x: x['confidence'], reverse=True)
            
            keep_objects = []
            while class_objects:
                # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ê°ì²´ ì„ íƒ
                current = class_objects.pop(0)
                keep_objects.append(current)
                
                # ë‚˜ë¨¸ì§€ ê°ì²´ë“¤ê³¼ IoU ê³„ì‚°í•˜ì—¬ ê²¹ì¹˜ëŠ” ê²ƒë“¤ ì œê±°
                remaining = []
                for obj in class_objects:
                    iou = self._calculate_iou(current['bbox'], obj['bbox'])
                    if iou < iou_threshold:
                        remaining.append(obj)
                class_objects = remaining
            
            nms_objects.extend(keep_objects)
        
        return nms_objects
    
    def _calculate_iou(self, box1: tuple, box2: tuple) -> float:
        """ë‘ ë°•ìŠ¤ ê°„ì˜ IoU (Intersection over Union) ê³„ì‚°"""
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        
        # êµì§‘í•© ì˜ì—­ ê³„ì‚°
        x1_inter = max(x1_1, x1_2)
        y1_inter = max(y1_1, y1_2)
        x2_inter = min(x2_1, x2_2)
        y2_inter = min(y2_1, y2_2)
        
        if x2_inter <= x1_inter or y2_inter <= y1_inter:
            return 0.0
        
        inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)
        
        # í•©ì§‘í•© ì˜ì—­ ê³„ì‚°
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union_area = area1 + area2 - inter_area
        
        return inter_area / union_area if union_area > 0 else 0.0
    
    def _apply_object_tracking(self, objects: List[dict]) -> List[dict]:
        """ê°ì²´ ì¶”ì ì„ í†µí•œ ì•ˆì •í™”"""
        if not hasattr(self, 'previous_objects'):
            self.previous_objects = objects
            return objects
        
        tracked_objects = []
        import time
        current_time = time.time()
        
        for obj in objects:
            # ì´ì „ í”„ë ˆì„ ê°ì²´ë“¤ê³¼ ë§¤ì¹­
            best_match = None
            best_iou = 0.0
            
            for prev_obj in self.previous_objects:
                if prev_obj['class_name'] == obj['class_name']:
                    iou = self._calculate_iou(obj['bbox'], prev_obj['bbox'])
                    if iou > best_iou and iou > self.object_tracking_threshold:
                        best_iou = iou
                        best_match = prev_obj
            
            if best_match:
                # ê¸°ì¡´ ê°ì²´ì™€ ë§¤ì¹­ë¨ - ìœ„ì¹˜ ìŠ¤ë¬´ë”© ì ìš©
                obj['center'] = self._smooth_position(obj['center'], best_match['center'], 0.7)
                obj['bbox'] = self._smooth_bbox(obj['bbox'], best_match['bbox'], 0.7)
                obj['tracking_id'] = best_match.get('tracking_id', f"obj_{len(tracked_objects)}")
                obj['stable_frames'] = best_match.get('stable_frames', 0) + 1
            else:
                # ìƒˆë¡œìš´ ê°ì²´
                obj['tracking_id'] = f"obj_{current_time}_{len(tracked_objects)}"
                obj['stable_frames'] = 1
            
            tracked_objects.append(obj)
        
        self.previous_objects = tracked_objects.copy()
        return tracked_objects
    
    def _smooth_position(self, current_pos: tuple, prev_pos: tuple, alpha: float = 0.7) -> tuple:
        """ìœ„ì¹˜ ìŠ¤ë¬´ë”© (ì§€ìˆ˜ ì´ë™ í‰ê· )"""
        curr_x, curr_y = current_pos
        prev_x, prev_y = prev_pos
        
        smooth_x = int(alpha * curr_x + (1 - alpha) * prev_x)
        smooth_y = int(alpha * curr_y + (1 - alpha) * prev_y)
        
        return (smooth_x, smooth_y)
    
    def _smooth_bbox(self, current_bbox: tuple, prev_bbox: tuple, alpha: float = 0.7) -> tuple:
        """ë°”ìš´ë”©ë°•ìŠ¤ ìŠ¤ë¬´ë”©"""
        curr_x1, curr_y1, curr_x2, curr_y2 = current_bbox
        prev_x1, prev_y1, prev_x2, prev_y2 = prev_bbox
        
        smooth_x1 = int(alpha * curr_x1 + (1 - alpha) * prev_x1)
        smooth_y1 = int(alpha * curr_y1 + (1 - alpha) * prev_y1)
        smooth_x2 = int(alpha * curr_x2 + (1 - alpha) * prev_x2)
        smooth_y2 = int(alpha * curr_y2 + (1 - alpha) * prev_y2)
        
        return (smooth_x1, smooth_y1, smooth_x2, smooth_y2)
    
    def _apply_confidence_filtering(self, objects: List[dict]) -> List[dict]:
        """ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§ ë° ì•ˆì •ì„± ì²´í¬"""
        filtered_objects = []
        
        for obj in objects:
            # ê¸°ë³¸ ì‹ ë¢°ë„ í•„í„°ë§
            if obj['confidence'] < 0.3:  # ë§¤ìš° ë‚®ì€ ì‹ ë¢°ë„ ì œê±°
                continue
            
            # ì•ˆì •ì„± ì²´í¬ (ìƒˆë¡œìš´ ê°ì²´ëŠ” ë†’ì€ ì‹ ë¢°ë„ ìš”êµ¬)
            stable_frames = obj.get('stable_frames', 1)
            min_confidence = 0.7 if stable_frames < self.stability_frames else 0.5
            
            if obj['confidence'] >= min_confidence:
                filtered_objects.append(obj)
        
        return filtered_objects

    
    def get_current_model_info(self):
        """í˜„ì¬ ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            'model_name': self.current_model_name,
            'available_models': list(self.models.keys()),
            'class_names': self.model_classes.get(self.current_model_name, []),
            'is_active': self.current_model is not None
        }

# YOLOButtonDetector í´ë˜ìŠ¤ ì œê±°ë¨ - MultiModelDetectorê°€ ì‹¤ì œë¡œ ì‚¬ìš©ë¨

class VSNode(Node):
    """OpenNI2 ê¸°ë°˜ Vision Service ROS2 ë…¸ë“œ"""
    
    def __init__(self):
        super().__init__('vs_node')
        
        # ë©€í‹° ì¹´ë©”ë¼ ë§¤ë‹ˆì €ì™€ ë‹¤ì¤‘ ëª¨ë¸ íƒì§€ê¸° ì´ˆê¸°í™”
        self.camera_manager = MultiCameraManager(self.get_logger())
        self.model_detector = MultiModelDetector(self.get_logger())
        
        # ë²„íŠ¼ ëˆŒë¦¼ ê°ì§€ CNN ì´ˆê¸°í™”
        self.button_pressed_cnn = ButtonPressedCNN(self.get_logger())
        
        # CNNì„ MultiModelDetectorì— ì—°ê²°
        self.model_detector.set_button_pressed_cnn(self.button_pressed_cnn)
        
        # CNN ë²„íŠ¼ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        self.cnn_classifier = CNNButtonClassifier(self.get_logger())
        
        # ğŸš§ ì¥ì• ë¬¼ ê°ì§€ê¸° ì´ˆê¸°í™”
        self.obstacle_detector = ObstacleDetector(self.get_logger())
        
        # ğŸ“¹ UDP ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë¨¸ ì´ˆê¸°í™” (í›„ë°© ì¹´ë©”ë¼ â†’ RGUI)
        self.udp_streamer = UDPVideoStreamer(
            target_ip=os.environ.get('VS_UDP_TARGET_IP', '127.0.0.1'),
            target_port=int(os.environ.get('VS_UDP_TARGET_PORT', os.environ.get('RGUI_UDP_PORT', 5005))),
            max_fps=int(os.environ.get('VS_UDP_MAX_FPS', 15)),
            quality=int(os.environ.get('VS_UDP_QUALITY', 70)),
            logger=self.get_logger()
        )
        self.get_logger().info(f"ğŸ“¹ UDP ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë¨¸ ì´ˆê¸°í™” ì™„ë£Œ ({self.udp_streamer.addr[0]}:{self.udp_streamer.addr[1]})")
        
        # ğŸ”¥ ìµœì í™”ëœ DisplayOCR ì´ˆê¸°í™” (EasyOCRë§Œ ì‚¬ìš©, GPU ë¦¬ì†ŒìŠ¤ ì ˆì•½)
        self.display_ocr = DisplayOCR(self.get_logger())
        # EasyOCR test_all_models_on_roiì™€ ë™ì¼í•œ ë‹¨ìˆœ í¬ë¡­ ë°©ì‹ ì‚¬ìš©
        self.display_ocr.update_config(debug_mode=True, use_simple_crop=True)
        
        # OCR ì£¼ê¸° ì¡°ì ˆ ì„¤ì • (ë¦¬ì†ŒìŠ¤ ì ˆì•½)
        self.ocr_counter = 0
        self.ocr_skip_frames = 5  # 5í”„ë ˆì„ë§ˆë‹¤ í•œ ë²ˆì”© OCR ìˆ˜í–‰ (ê¸°ì¡´ë³´ë‹¤ ëŠë¦¬ê²Œ)
        self.last_ocr_objects = []  # ë§ˆì§€ë§‰ OCR ê²°ê³¼ ìºì‹±
        
        # ğŸšª ìœ ë¦¬ ë¬¸ ìƒíƒœ ì´ë²¤íŠ¸ ê¸°ë°˜ ë°œí–‰ì„ ìœ„í•œ ë³€ìˆ˜
        self.last_glass_door_opened = None  # ì´ì „ ìœ ë¦¬ ë¬¸ ìƒíƒœ (None: ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ)
        
        # ğŸš§ ì¥ì• ë¬¼ ê°ì§€ 1ì´ˆ ì¢…í•© í‰ê°€ë¥¼ ìœ„í•œ ë³€ìˆ˜ë“¤
        self.obstacle_detection_history = {}  # {class_name: [detection_count, total_frames]}
        self.last_obstacle_publish_time = None  # ë§ˆì§€ë§‰ ì¥ì• ë¬¼ ë°œí–‰ ì‹œê°„
        self.obstacle_publish_interval = 1.0  # ì¥ì• ë¬¼ ë°œí–‰ ê°„ê²© (1ì´ˆ)
        self.obstacle_detection_threshold = 0.6  # 60% ì´ìƒ ê°ì§€ë˜ì–´ì•¼ ì¥ì• ë¬¼ë¡œ ì¸ì •
        
        # ğŸ® GPU ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™”
        try:
            from .gpu_monitor import GPUResourceMonitor
            # GPU ë©”ëª¨ë¦¬ ì œí•œ: RTX 2060 6GB ì¤‘ 4GBë§Œ ì‚¬ìš© í—ˆìš©
            self.gpu_monitor = GPUResourceMonitor(
                self.get_logger(), 
                max_memory_mb=4096,  # 4GB ì œí•œ
                check_interval=3.0   # 3ì´ˆë§ˆë‹¤ ì²´í¬
            )
            
            # GPU ë©”ëª¨ë¦¬ ì´ˆê³¼ ì‹œ ëŒ€ì‘ ë°©ë²• ì„¤ì •
            self.gpu_monitor.set_memory_exceeded_callback(self._on_gpu_memory_exceeded)
            self.gpu_monitor.set_gpu_error_callback(self._on_gpu_error)
            
            # GPU ëª¨ë‹ˆí„°ë§ ì‹œì‘
            if self.gpu_monitor.start_monitoring():
                self.get_logger().info("ğŸ® GPU ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ í™œì„±í™”ë¨")
            else:
                self.get_logger().warning("âš ï¸ GPU ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨")
                
        except Exception as e:
            self.get_logger().warning(f"âš ï¸ GPU ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.gpu_monitor = None
        
        # í˜„ì¬ ì„ íƒëœ ì¹´ë©”ë¼ë“¤ (ëª¨ë“œë³„ë¡œ ë³€ê²½ë¨)
        self.current_camera = None
        self.current_depth_camera = None
        self.current_camera_name = "None"
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜µì…˜
        self.flip_horizontal = False  # ê¸°ë³¸ ì¢Œìš°ë°˜ì „ ë„ê¸°
        self.confidence_threshold = 0.7
        
        # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì„¤ì • (GUI ì—†ì´ ë™ì‘)
        self.headless_mode = os.environ.get('ROOMIE_HEADLESS', 'false').lower() in ['true', '1', 'yes']
        if self.headless_mode:
            self.get_logger().info("ğŸ–¥ï¸ í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ í™œì„±í™”: GUI ì—†ì´ ë™ì‘í•©ë‹ˆë‹¤")
        
        # ArUco ë§ˆì»¤ ê°ì§€ ì„¤ì •
        try:
            # OpenCV ë²„ì „ í™•ì¸
            opencv_version = cv2.__version__
            self.get_logger().info(f"OpenCV ë²„ì „: {opencv_version}")
            self.get_logger().info(f"OpenCV íŒŒì¼ ìœ„ì¹˜: {cv2.__file__}")
            self.get_logger().info("ğŸ” ArUco ì´ˆê¸°í™” ì‹œì‘...")
            
            # ArUco ê¸°ë³¸ ì„¤ì • (ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸)
            self.get_logger().info("ğŸ” ArUco ê¸°ë³¸ ì‚¬ì „ ë¡œë”© ì‹œë„...")
            self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_ARUCO_ORIGINAL)
            self.aruco_dict_name = "DICT_ARUCO_ORIGINAL"
            self.get_logger().info("âœ… ArUco ì‚¬ì „ ë¡œë”© ì„±ê³µ")
            
            self.get_logger().info("ğŸ” ArUco íŒŒë¼ë¯¸í„° ì„¤ì •...")
            # OpenCV 4.7+ ì‹  API ìš°ì„  ì‚¬ìš©, ê°€ëŠ¥ ì‹œ DetectorParameters ë° ArucoDetector ìƒì„±
            try:
                self.aruco_params = cv2.aruco.DetectorParameters()
                if hasattr(cv2.aruco, 'ArucoDetector'):
                    self.aruco_detector = cv2.aruco.ArucoDetector(self.aruco_dict, self.aruco_params)
                    self.aruco_api_version = "new"
                    self.get_logger().info("âœ… ArUcoDetector ì´ˆê¸°í™” ì™„ë£Œ (ì‹  API)")
                else:
                    # í´ë°±: ë ˆê±°ì‹œ APIë§Œ ìˆëŠ” ê²½ìš° í”Œë˜ê·¸ë¡œ í™œì„±í™”
                    self.aruco_detector = True
                    self.aruco_api_version = "legacy"
                    self.get_logger().info("âœ… ArUco ê°ì§€ ì‹œìŠ¤í…œ í™œì„±í™” (ë ˆê±°ì‹œ API)")
            except Exception:
                # ìµœì¢… í´ë°±: íŒŒë¼ë¯¸í„°ë¥¼ Noneìœ¼ë¡œ ë‘ê³  ë ˆê±°ì‹œë¡œë§Œ ì‹œë„
                self.aruco_params = None
                self.aruco_detector = True if self.aruco_dict is not None else False
                self.aruco_api_version = "legacy" if self.aruco_detector else "error"
                self.get_logger().info("âœ… ArUco íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ (ê¸°ë³¸ê°’/ë ˆê±°ì‹œ)")
            
        except Exception as e:
            self.get_logger().warning(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
            self.aruco_dict = None
            self.aruco_params = None
            self.aruco_detector = None
            self.aruco_api_version = "error"
        
        # ë§ˆì§€ë§‰ìœ¼ë¡œ ê°ì§€ëœ ìœ„ì¹˜ ì €ì¥
        self.last_detected_location_id = 0  # ê¸°ë³¸ê°’: LOB_WAITING
        self.last_detection_time = None
        self.unknown_aruco_id = None  # ì•Œ ìˆ˜ ì—†ëŠ” ArUco ë§ˆì»¤ ID ì €ì¥
        
        # ğŸš¦ ì—˜ë¦¬ë² ì´í„° ë°©í–¥ ìºì‹œ
        self.last_elevator_direction = 0  # 0: ìƒí–‰, 1: í•˜í–‰
        self.last_direction_detection_time = None
        
        # ğŸ”¥ ê°œì„ ëœ Direction Light ì¶”ì  (ê°œë³„ ìœ„ì¹˜ ê¸°ë°˜)
        self.previous_direction_lights = []  # ì´ì „ í”„ë ˆì„ì˜ direction light ê°ì²´ë“¤ (ìœ„ì¹˜+ë°ê¸°)
        self.direction_light_history = []    # ìµœê·¼ 5í”„ë ˆì„ì˜ ê°œìˆ˜ íˆìŠ¤í† ë¦¬
        self.brightness_threshold = 180      # ë°ê¸° ì„ê³„ê°’ (0-255, ì¡°ê¸ˆ ë‚®ì¶¤)
        
        # ğŸ¯ ë°©í–¥ë“± ìœ„ì¹˜ ê¸°ì–µ ì‹œìŠ¤í…œ (ê°„í—ì  ê°ì§€ ë³´ê°•)
        self.remembered_direction_positions = {
            'upper': None,  # ê¸°ì–µëœ ìœ„ìª½ ë°©í–¥ë“± ìœ„ì¹˜ 
            'lower': None   # ê¸°ì–µëœ ì•„ë˜ìª½ ë°©í–¥ë“± ìœ„ì¹˜
        }
        self.last_position_update = None  # ë§ˆì§€ë§‰ ìœ„ì¹˜ ì—…ë°ì´íŠ¸ ì‹œê°„
        
        # ğŸ¯ ë°ê¸° ë³€í™” ê¸°ë°˜ ê¹œë¹¡ì„ ê°ì§€ ì‹œìŠ¤í…œ
        self.brightness_history = {
            'upper': [],  # ìœ„ìª½ ë°©í–¥ë“± ë°ê¸° íˆìŠ¤í† ë¦¬ (ìµœê·¼ 10í”„ë ˆì„)
            'lower': []   # ì•„ë˜ìª½ ë°©í–¥ë“± ë°ê¸° íˆìŠ¤í† ë¦¬
        }
        self.blink_detection_enabled = True
        self.brightness_change_threshold_for_blink = 20  # ê¹œë¹¡ì„ ê°ì§€ìš© ë°ê¸° ë³€í™” ì„ê³„ê°’ (ë” ë¯¼ê°í•˜ê²Œ)
        self.history_size = 10  # íˆìŠ¤í† ë¦¬ ì €ì¥ í”„ë ˆì„ ìˆ˜
        self.last_blink_detected = False  # ë§ˆì§€ë§‰ ë°©í–¥ ê°ì§€ì—ì„œ ê¹œë¹¡ì„ì´ ê°ì§€ë˜ì—ˆëŠ”ì§€
        self.brightness_change_threshold = 50  # ë°ê¸° ë³€í™” ê°ì§€ ì„ê³„ê°’ (ì•ˆì •ì„± ìš°ì„ )
        self.position_tolerance = 50         # ê°™ì€ ë°©í–¥ë“±ìœ¼ë¡œ ì¸ì‹í•  ìœ„ì¹˜ í—ˆìš© ì˜¤ì°¨ (í”½ì…€)
        
        # ğŸ¯ ë§ˆì§€ë§‰ ê°ì§€ëœ ê°ì²´ë“¤ ì €ì¥ (Lí‚¤ ê°•ì œ í•™ìŠµìš©)
        self.last_detected_objects = []
        
        # ArUco ë§ˆì»¤ IDì™€ location_id ì§ì ‘ ë§¤í•‘ (interface ë¬¸ì„œ ê¸°ì¤€)
        self.aruco_to_location = {
            0: 0,     # LOB_WAITING
            1: 1,     # LOB_CALL  
            2: 2,     # RES_PICKUP
            3: 3,     # RES_CALL
            4: 4,     # SUP_PICKUP
            5: 5,     # ELE_1
            6: 6,     # ELE_2
            101: 101, # ROOM_101
            102: 102, # ROOM_102
            201: 201, # ROOM_201
            202: 202, # ROOM_202
        }
        
        # VS ëª¨ë“œ ìƒíƒœ ê´€ë¦¬ - ì „ë°©/í›„ë°© ë…ë¦½ì ìœ¼ë¡œ ê´€ë¦¬
        self.current_front_mode_id = 6  # ì „ë°© ëŒ€ê¸°ëª¨ë“œë¡œ ì‹œì‘
        self.current_rear_mode_id = 0   # í›„ë°© ëŒ€ê¸°ëª¨ë“œë¡œ ì‹œì‘
        self.mode_names = {
            0: "Standby Mode (Rear)",
            1: "Registration Mode (Rear)", 
            2: "Tracking Mode (Rear)",
            3: "Elevator External Mode (Front)",
            4: "Elevator Internal Mode (Front)",
            5: "Normal Mode (Front)",
            6: "Standby Mode (Front)",
            100: "Delivery Simulation Mode",
            101: "Call Simulation Mode",
            102: "Guide Simulation Mode",
            103: "Return Simulation Mode",
            104: "Elevator Simulation Mode"
        }
        
        # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë³„ ì‹œë‚˜ë¦¬ì˜¤ ì¹´ìš´í„°
        self.simulation_counters = {
            100: 0,  # ë°°ì†¡ ì‹œë®¬ë ˆì´ì…˜
            101: 0,  # í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
            102: 0,  # ê¸¸ì•ˆë‚´ ì‹œë®¬ë ˆì´ì…˜
            103: 0,  # ë³µê·€ ì‹œë®¬ë ˆì´ì…˜
            104: 0   # ì—˜ë¦¬ë² ì´í„° ì‹œë®¬ë ˆì´ì…˜
        }
        
        # ëª¨ë“  ì¹´ë©”ë¼ í™œì„±í™” (ëŒ€ê¸°ëª¨ë“œì—ì„œë„ GUI ì œê³µ)
        self.camera_initialized = True
        self.get_logger().info("ğŸš€ ëª¨ë“  ì¹´ë©”ë¼ í™œì„±í™” ì´ˆê¸°í™” ì‹œì‘")
        self.get_logger().info("ğŸ“Œ ëŒ€ê¸°ëª¨ë“œì—ì„œë„ ì¹´ë©”ë¼ì™€ GUIê°€ í•­ìƒ í™œì„±í™”ë©ë‹ˆë‹¤")
        self.get_logger().info("ğŸ’¡ ì‹¤ì‹œê°„ ì˜ìƒ í™•ì¸ ê°€ëŠ¥ - ë¦¬ì†ŒìŠ¤ ì†Œëª¨ ì¦ê°€")
            
        # ì „ë°©/í›„ë°© ì¹´ë©”ë¼ ëª¨ë‘ í™œì„±í™”
        self.update_front_camera()  # ì „ë°© ì¹´ë©”ë¼ ì´ˆê¸°í™” (ëŒ€ê¸°ëª¨ë“œ 6ë²ˆ)
        self.update_rear_camera()   # í›„ë°© ì¹´ë©”ë¼ ì´ˆê¸°í™” (ëŒ€ê¸°ëª¨ë“œ 0ë²ˆ)
        
        # ROS2 ì„œë¹„ìŠ¤ë“¤ (/vs/command/*)
        self.get_logger().info("VS ì„œë¹„ìŠ¤ ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        
        self.set_mode_service = self.create_service(
            SetVSMode,
            '/vs/command/set_vs_mode',
            self.set_vs_mode_callback
        )
        

        
        self.button_status_service = self.create_service(
            ButtonStatus, 
            '/vs/command/button_status', 
            self.button_status_callback
        )
        
        self.elevator_status_service = self.create_service(
            ElevatorStatus,
            '/vs/command/elevator_status',
            self.elevator_status_callback
        )
        
        self.door_status_service = self.create_service(
            DoorStatus,
            '/vs/command/door_status',
            self.door_status_callback
        )
        

        
        self.location_service = self.create_service(
            Location,
            '/vs/command/location',
            self.location_callback
        )
        
        # ğŸ‘¤ ì¶”ì  ê´€ë ¨ ì•¡ì…˜ ë° ì„œë¹„ìŠ¤ ì¶”ê°€
        self.enroll_action_server = ActionServer(
            self,
            Enroll,
            '/vs/action/enroll',
            self.enroll_action_callback
        )
        
        self.stop_tracking_service = self.create_service(
            Trigger,
            '/vs/command/stop_tracking',
            self.stop_tracking_callback
        )
        
        # ROS2 í† í”½ í¼ë¸”ë¦¬ì…”ë“¤ (QoS í”„ë¡œíŒŒì¼ ëª…ì‹œì  ì„¤ì •)
        from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy
        
        # QoS í”„ë¡œíŒŒì¼ ì„¤ì • (íˆìŠ¤í† ë¦¬ í¬ê¸° ì¦ê°€)
        qos_profile = QoSProfile(
            history=HistoryPolicy.KEEP_LAST,
            depth=50,  # íˆìŠ¤í† ë¦¬ í¬ê¸°ë¥¼ 50ìœ¼ë¡œ ì¦ê°€
            reliability=ReliabilityPolicy.RELIABLE
        )
        

        
        # ğŸš§ ì¥ì• ë¬¼ í† í”½ í¼ë¸”ë¦¬ì…” ì¶”ê°€
        self.obstacle_pub = self.create_publisher(
            Obstacle,
            '/vs/obstacle',
            qos_profile
        )
        
        # ğŸšª ìœ ë¦¬ ë¬¸ ìƒíƒœ í† í”½ í¼ë¸”ë¦¬ì…” ì¶”ê°€
        self.glass_door_pub = self.create_publisher(
            GlassDoorStatus,
            '/vs/glass_door_status',
            qos_profile
        )
        
        self.get_logger().info("ëª¨ë“  VS ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
        self.get_logger().info("êµ¬í˜„ëœ ì„œë¹„ìŠ¤ 7ê°œ: set_vs_mode, button_status, elevator_status, door_status, location, stop_tracking, enroll(action)")
        self.get_logger().info("êµ¬í˜„ëœ í† í”½ 3ê°œ: obstacle, glass_door_status, tracking")
        self.get_logger().info("ArUco ë§ˆì»¤ ê¸°ë°˜ ìœ„ì¹˜ ê°ì§€ ì‹œìŠ¤í…œ í™œì„±í™”")
        self.get_logger().info("ğŸ¯ GPU ë¦¬ì†ŒìŠ¤ ì ˆì•½í˜• ë™ì  ì¹´ë©”ë¼ VS Node ì´ˆê¸°í™” ì™„ë£Œ!")
        self.get_logger().info(f"ğŸš€ ì‹œì‘ ëª¨ë“œ: ì „ë°© {self.mode_names[self.current_front_mode_id]} (ID: {self.current_front_mode_id}), í›„ë°© {self.mode_names[self.current_rear_mode_id]} (ID: {self.current_rear_mode_id})")
        
        # ëª¨ë“œë³„ ì¹´ë©”ë¼ ìš”êµ¬ì‚¬í•­ ìš”ì•½ ì¶œë ¥
        self.get_logger().info("=" * 60)
        self.get_logger().info("ğŸ“‹ ëª¨ë“œë³„ ì¹´ë©”ë¼ ì‚¬ìš© ê³„íš (í•­ìƒ í™œì„±í™”)")
        self.get_logger().info("=" * 60)
        self.get_logger().info("í›„ë°© ê´€ë ¨: 0(ëŒ€ê¸°) â†’ í›„ë°©ì›¹ìº , 1(ë“±ë¡) â†’ í›„ë°©ì›¹ìº , 2(ì¶”ì ) â†’ í›„ë°©ì›¹ìº ")
        self.get_logger().info("ì „ë°© ê´€ë ¨: 3(ì—˜ì™¸ë¶€) â†’ ì „ë°©ì›¹ìº +ëìŠ¤, 4(ì—˜ë‚´ë¶€) â†’ ì „ë°©ì›¹ìº +ëìŠ¤, 5(ì¼ë°˜) â†’ ì „ë°©ì›¹ìº +ëìŠ¤, 6(ëŒ€ê¸°) â†’ ì „ë°©ì›¹ìº +ëìŠ¤")
        self.get_logger().info("ğŸ’¡ ëª¨ë“  ëª¨ë“œì—ì„œ ì¹´ë©”ë¼ì™€ GUIê°€ í™œì„±í™”ë˜ì–´ ì‹¤ì‹œê°„ ì˜ìƒ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        self.get_logger().info("=" * 60)
        
        # ğŸ‘¤ ì‚¬ëŒ ì¶”ì  ëª¨ë“ˆ ì´ˆê¸°í™” (ë§ˆì§€ë§‰ì— ì¶”ê°€)
        try:
            # MultiModelDetectorì—ì„œ YOLOv8n ëª¨ë¸ ì°¸ì¡°
            yolo_model = None
            if hasattr(self.model_detector, 'model_normal') and self.model_detector.model_normal:
                yolo_model = self.model_detector.model_normal
            elif hasattr(self.model_detector, 'fallback_model') and self.model_detector.fallback_model:
                yolo_model = self.model_detector.fallback_model
            
            self.person_tracker = PersonTracker(self, yolo_model)
            self.get_logger().info("ğŸ‘¤ PersonTracker ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.get_logger().error(f"ğŸ‘¤ PersonTracker ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.person_tracker = None
    
    def update_camera_for_current_mode(self):
        """ì „ë°©/í›„ë°© ì¹´ë©”ë¼ ë…ë¦½ì  ì—…ë°ì´íŠ¸ (í˜¸í™˜ì„± ìœ ì§€)"""
        try:
            # ì „ë°©ê³¼ í›„ë°© ì¹´ë©”ë¼ë¥¼ ê°ê° ì´ˆê¸°í™” (ë…ë¦½ì  ê´€ë¦¬)
            self.update_front_camera()
            self.update_rear_camera()
                
        except Exception as e:
            self.get_logger().error(f"ì¹´ë©”ë¼ ì—…ë°ì´íŠ¸ ì—ëŸ¬: {e}")
            self.current_camera = None
            self.current_depth_camera = None
            self.current_camera_name = "Error"
    
    def detect_and_update_location(self, input_image: np.ndarray = None) -> int:
        """ArUco ë§ˆì»¤ë¥¼ ê°ì§€í•˜ì—¬ ìœ„ì¹˜ ì—…ë°ì´íŠ¸ ë° í˜„ì¬ ìœ„ì¹˜ ë°˜í™˜"""
        if not self.aruco_detector or self.aruco_dict is None:
            self.get_logger().debug("ArUco ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return self.last_detected_location_id
        
        try:
            # ì…ë ¥ ì´ë¯¸ì§€ê°€ ì œê³µë˜ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í˜„ì¬ ì¹´ë©”ë¼ í”„ë ˆì„ ì‚¬ìš©
            if input_image is not None:
                current_color = input_image
            else:
                # í˜„ì¬ ì¹´ë©”ë¼ í”„ë ˆì„ íšë“
                if self.current_camera is None:
                    self.get_logger().debug("í˜„ì¬ ì¹´ë©”ë¼ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                    return self.last_detected_location_id
                
                with self.current_camera.frame_lock:
                    current_color = self.current_camera.current_color
            
            if current_color is None:
                self.get_logger().debug("ì¹´ë©”ë¼ í”„ë ˆì„ì´ ì—†ìŒ")
                return self.last_detected_location_id
            
            # ì¢Œìš°ë°˜ì „ì€ ì´ë¯¸ ì ìš©ë˜ì—ˆë‹¤ê³  ê°€ì • (mainì—ì„œ ì²˜ë¦¬)
            processed_image = current_color.copy()
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
            
            # ë ˆê±°ì‹œ/ì‹  API ëŒ€ì‘í•˜ì—¬ ArUco ë§ˆì»¤ ê°ì§€
            corners = ids = rejected = None
            try:
                if hasattr(cv2.aruco, 'ArucoDetector') and isinstance(self.aruco_detector, cv2.aruco.ArucoDetector):
                    corners, ids, rejected = self.aruco_detector.detectMarkers(gray)
                elif hasattr(cv2.aruco, 'detectMarkers'):
                    corners, ids, rejected = cv2.aruco.detectMarkers(
                        gray,
                        self.aruco_dict,
                        parameters=self.aruco_params if self.aruco_params is not None else None
                    )
                else:
                    self.get_logger().error("ArUco ê°ì§€ APIë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ArucoDetector/legacy detectMarkers ëª¨ë‘ ì—†ìŒ)")
                    return self.last_detected_location_id
            except Exception as e:
                self.get_logger().error(f"ArUco ê°ì§€ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                return self.last_detected_location_id
            
            # ì¡°ìš©í•œ ìë™ ê°ì§€ (ë¡œê·¸ ìµœì†Œí™”)
            
            if ids is not None and len(ids) > 0:
                # ì²« ë²ˆì§¸ ê°ì§€ëœ ë§ˆì»¤ ì‚¬ìš©
                detected_id = int(ids[0][0])
                
                # ë§¤í•‘ëœ location_id í™•ì¸
                if detected_id in self.aruco_to_location:
                    new_location_id = self.aruco_to_location[detected_id]
                    
                    # ìƒˆë¡œìš´ ìœ„ì¹˜ê°€ ì´ì „ê³¼ ë‹¤ë¥´ë©´ ì—…ë°ì´íŠ¸
                    if new_location_id != self.last_detected_location_id:
                        old_location = self.last_detected_location_id
                        self.last_detected_location_id = new_location_id
                        self.last_detection_time = self.get_clock().now()
                        
                        location_names = {
                            0: "LOB_WAITING", 1: "LOB_CALL", 2: "RES_PICKUP", 3: "RES_CALL",
                            4: "SUP_PICKUP", 5: "ELE_1", 6: "ELE_2", 101: "ROOM_101",
                            102: "ROOM_102", 201: "ROOM_201", 202: "ROOM_202"
                        }
                        old_name = location_names.get(old_location, f"UNKNOWN({old_location})")
                        new_name = location_names.get(new_location_id, f"UNKNOWN({new_location_id})")
                        
                        self.get_logger().info(f"ğŸ¯ ìœ„ì¹˜ ë³€ê²½: {old_name} â†’ {new_name} (ArUco ë§ˆì»¤ {detected_id})")
                    else:
                        # ê°™ì€ ìœ„ì¹˜ ì¬í™•ì¸ (ì¡°ìš©í•˜ê²Œ)
                        self.last_detection_time = self.get_clock().now()
                    
                    return self.last_detected_location_id
                else:
                    # ì•Œ ìˆ˜ ì—†ëŠ” ë§ˆì»¤ëŠ” ì¡°ìš©íˆ ì²˜ë¦¬ (ë¡œê·¸ ìµœì†Œí™”)
                    # GUIì— ë§ˆì»¤ IDë¥¼ ì˜¤ë²„ë ˆì´ë¡œ í‘œì‹œ
                    self.unknown_aruco_id = detected_id
                    return self.last_detected_location_id
            else:
                # ë§ˆì»¤ê°€ ê°ì§€ë˜ì§€ ì•ŠìŒ - ë§ˆì§€ë§‰ ìœ„ì¹˜ ìœ ì§€
                return self.last_detected_location_id
                
        except Exception as e:
            self.get_logger().error(f"âŒ ArUco ë§ˆì»¤ ê°ì§€ ì—ëŸ¬: {e}")
            import traceback
            self.get_logger().error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            return self.last_detected_location_id
    
    def test_aruco_detection(self):
        """ArUco ê°ì§€ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ('A' í‚¤ìš©) - ëª¨ë“  ArUco ì‚¬ì „ ì‹œë„"""
        try:
            # í˜„ì¬ ì¹´ë©”ë¼ í”„ë ˆì„ íšë“
            if self.current_camera is None:
                self.get_logger().warning("âš ï¸ í˜„ì¬ ì¹´ë©”ë¼ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return
            
            with self.current_camera.frame_lock:
                current_color = self.current_camera.current_color
            
            if current_color is None:
                self.get_logger().warning("âš ï¸ ì¹´ë©”ë¼ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤")
                return
            
            # ì¢Œìš°ë°˜ì „ ì ìš©
            processed_image = current_color.copy()
            if self.flip_horizontal:
                processed_image = cv2.flip(processed_image, 1)
                self.get_logger().info("ğŸ”„ ì¢Œìš°ë°˜ì „ ì ìš©ë¨")
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
            self.get_logger().info(f"ğŸ“Š ì´ë¯¸ì§€ í¬ê¸°: {gray.shape}, íƒ€ì…: {gray.dtype}")
            
            # ëª¨ë“  ì£¼ìš” ArUco ì‚¬ì „ ì‹œë„
            aruco_dicts_to_test = [
                (cv2.aruco.DICT_4X4_50, "DICT_4X4_50"),
                (cv2.aruco.DICT_4X4_100, "DICT_4X4_100"),
                (cv2.aruco.DICT_4X4_250, "DICT_4X4_250"),
                (cv2.aruco.DICT_4X4_1000, "DICT_4X4_1000"),
                (cv2.aruco.DICT_5X5_50, "DICT_5X5_50"),
                (cv2.aruco.DICT_5X5_100, "DICT_5X5_100"),
                (cv2.aruco.DICT_5X5_250, "DICT_5X5_250"),
                (cv2.aruco.DICT_5X5_1000, "DICT_5X5_1000"),
                (cv2.aruco.DICT_6X6_50, "DICT_6X6_50"),
                (cv2.aruco.DICT_6X6_100, "DICT_6X6_100"),
                (cv2.aruco.DICT_6X6_250, "DICT_6X6_250"),
                (cv2.aruco.DICT_6X6_1000, "DICT_6X6_1000"),
                (cv2.aruco.DICT_7X7_50, "DICT_7X7_50"),
                (cv2.aruco.DICT_7X7_100, "DICT_7X7_100"),
                (cv2.aruco.DICT_7X7_250, "DICT_7X7_250"),
                (cv2.aruco.DICT_7X7_1000, "DICT_7X7_1000"),
                (cv2.aruco.DICT_ARUCO_ORIGINAL, "DICT_ARUCO_ORIGINAL"),
            ]
            
            self.get_logger().info(f"ğŸ” ëª¨ë“  ArUco ì‚¬ì „ í…ŒìŠ¤íŠ¸ ì‹œì‘ ({len(aruco_dicts_to_test)}ê°œ)")
            
            detected_in_dicts = []
            
            for dict_id, dict_name in aruco_dicts_to_test:
                try:
                    # í…ŒìŠ¤íŠ¸ìš© ArUco ì‚¬ì „ ìƒì„± (íŒŒë¼ë¯¸í„°ëŠ” ê¸°ë³¸ê°’)
                    test_dict = cv2.aruco.getPredefinedDictionary(dict_id)
                    
                    # ArUco ë§ˆì»¤ ê°ì§€ (ì‹  API ìš°ì„ , ë ˆê±°ì‹œ í´ë°±)
                    try:
                        if hasattr(cv2.aruco, 'ArucoDetector'):
                            test_detector = cv2.aruco.ArucoDetector(test_dict, cv2.aruco.DetectorParameters())
                            corners, ids, rejected = test_detector.detectMarkers(gray)
                        elif hasattr(cv2.aruco, 'detectMarkers'):
                            corners, ids, rejected = cv2.aruco.detectMarkers(
                                gray,
                                test_dict,
                                parameters=None
                            )
                        else:
                            corners, ids, rejected = None, None, None
                    except Exception as e:
                        self.get_logger().warning(f"{dict_name} ê°ì§€ ì‹¤íŒ¨: {e}")
                        corners, ids, rejected = None, None, None
                    
                    detected_count = len(ids) if ids is not None else 0
                    rejected_count = len(rejected) if rejected is not None else 0
                    
                    if detected_count > 0:
                        self.get_logger().info(f"ğŸ¯ {dict_name}: {detected_count}ê°œ ë§ˆì»¤ ê°ì§€!")
                        
                        # ê°ì§€ëœ ë§ˆì»¤ IDë“¤ ì¶œë ¥
                        marker_ids = [int(id[0]) for id in ids]
                        self.get_logger().info(f"   ê°ì§€ëœ ë§ˆì»¤ ID: {marker_ids}")
                        
                        # 1ë²ˆ ë§ˆì»¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                        if 1 in marker_ids:
                            self.get_logger().info(f"   âœ… 1ë²ˆ ë§ˆì»¤ ë°œê²¬! {dict_name}ì„ ì‚¬ìš©í•˜ì„¸ìš”!")
                            detected_in_dicts.append((dict_name, marker_ids))
                        else:
                            detected_in_dicts.append((dict_name, marker_ids))
                    else:
                        if rejected_count > 0:
                            self.get_logger().debug(f"   {dict_name}: 0ê°œ ê°ì§€, {rejected_count}ê°œ ê±°ë¶€ë¨")
                        
                except Exception as e:
                    self.get_logger().debug(f"   {dict_name}: í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - {e}")
            
            # ê²°ê³¼ ìš”ì•½
            self.get_logger().info("ğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
            if detected_in_dicts:
                self.get_logger().info(f"âœ… ë§ˆì»¤ê°€ ê°ì§€ëœ ì‚¬ì „ë“¤ ({len(detected_in_dicts)}ê°œ):")
                for dict_name, marker_ids in detected_in_dicts:
                    self.get_logger().info(f"   {dict_name}: ë§ˆì»¤ ID {marker_ids}")
                    if 1 in marker_ids:
                        self.get_logger().info(f"   ğŸ‘† {dict_name}ì—ì„œ 1ë²ˆ ë§ˆì»¤ ë°œê²¬! ì´ ì‚¬ì „ì„ ì‚¬ìš©í•˜ì„¸ìš”!")
            else:
                self.get_logger().warning("âŒ ì–´ë–¤ ArUco ì‚¬ì „ì—ì„œë„ ë§ˆì»¤ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
                self.get_logger().info("ğŸ’¡ í™•ì¸ì‚¬í•­:")
                self.get_logger().info("   1. ë§ˆì»¤ê°€ í™”ë©´ì— ì„ ëª…í•˜ê²Œ ë³´ì´ëŠ”ê°€?")
                self.get_logger().info("   2. ì¡°ëª…ì´ ì¶©ë¶„í•œê°€?")
                self.get_logger().info("   3. ë§ˆì»¤ê°€ í‰í‰í•˜ê³  ì™œê³¡ë˜ì§€ ì•Šì•˜ëŠ”ê°€?")
                self.get_logger().info("   4. ë§ˆì»¤ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ í¬ì§€ ì•Šì€ê°€?")
                
        except Exception as e:
            self.get_logger().error(f"âŒ ArUco í…ŒìŠ¤íŠ¸ ì—ëŸ¬: {e}")
            import traceback
            self.get_logger().error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
    
    def _add_aruco_visualization(self, image: np.ndarray):
        """ArUco ë§ˆì»¤ ê°ì§€ ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— í‘œì‹œ (ì´ë¯¸ ê°ì§€ëœ ì •ë³´ ì‚¬ìš©)"""
        if not self.aruco_detector or self.aruco_dict is None:
            return
        
        try:
            # ì´ë¯¸ ê°ì§€ëœ ìœ„ì¹˜ ì •ë³´ í‘œì‹œ (ë³„ë„ ê°ì§€í•˜ì§€ ì•ŠìŒ)
            if self.last_detected_location_id is not None:
                location_names = {
                    0: "LOB_WAITING", 1: "LOB_CALL", 2: "RES_PICKUP", 3: "RES_CALL",
                    4: "SUP_PICKUP", 5: "ELE_1", 6: "ELE_2", 101: "ROOM_101",
                    102: "ROOM_102", 201: "ROOM_201", 202: "ROOM_202"
                }
                location_name = location_names.get(self.last_detected_location_id, f"ID_{self.last_detected_location_id}")
                
                # ê°ì§€ëœ ìœ„ì¹˜ ì •ë³´ í‘œì‹œ (ë” ì•„ë˜ìª½ìœ¼ë¡œ ì´ë™)
                cv2.putText(image, f"ArUco Status: Active", (10, 240), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                cv2.putText(image, f"Location: {location_name}", (10, 265), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                
                # ë§ˆì§€ë§‰ ê°ì§€ ì‹œê°„ í‘œì‹œ (ì„ íƒì )
                if self.last_detection_time is not None:
                    import time
                    current_time = self.get_clock().now()
                    time_diff = (current_time - self.last_detection_time).nanoseconds / 1e9
                    cv2.putText(image, f"Last detected: {time_diff:.1f}s ago", (10, 290), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 255), 2)
            else:
                # ì•„ì§ ê°ì§€ëœ ë§ˆì»¤ê°€ ì—†ìŒ
                cv2.putText(image, f"ArUco Status: Waiting", (10, 240), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 2)
            
            # ì•Œ ìˆ˜ ì—†ëŠ” ArUco ë§ˆì»¤ ID í‘œì‹œ (GUI ì˜¤ë²„ë ˆì´)
            if self.unknown_aruco_id is not None:
                cv2.putText(image, f"Unknown ArUco: {self.unknown_aruco_id}", (10, 315), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                cv2.putText(image, f"Supported: {list(self.aruco_to_location.keys())}", (10, 340), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 2)
                
        except Exception as e:
            pass
    
    def button_status_callback(self, request, response):
        """ë²„íŠ¼ ìƒíƒœ ìš”ì²­ ì²˜ë¦¬ - ë‹¨ì¼ ë²„íŠ¼ ê°ì§€"""
        try:
            self.get_logger().info(f"ë²„íŠ¼ ìƒíƒœ ìš”ì²­: robot_id={request.robot_id}, button_id={request.button_id}")
            
            response.robot_id = request.robot_id
            response.button_id = request.button_id
            
            # í˜„ì¬ í”„ë ˆì„ íšë“
            if self.current_camera is None:
                self.get_logger().warning("í˜„ì¬ ì¹´ë©”ë¼ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                response.success = False
                response.x = 0.0
                response.y = 0.0
                response.size = 0.0
                response.is_pressed = False
                response.timestamp = self.get_clock().now().to_msg()
                return response
                
            try:
                with self.current_camera.frame_lock:
                    # WebCamCameraì—ëŠ” current_depthê°€ ì—†ìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼
                    current_depth = getattr(self.current_camera, 'current_depth', None)
                    current_color = self.current_camera.current_color
                
                # ì´ë¯¸ì§€ ì¢Œìš°ë°˜ì „
                if self.flip_horizontal:
                    if current_color is not None:
                        current_color = cv2.flip(current_color, 1)
                    if current_depth is not None:
                        current_depth = cv2.flip(current_depth, 1)
                
                if current_color is None:
                    self.get_logger().warning("ì¹´ë©”ë¼ í”„ë ˆì„ì´ ì—†ìŒ")
                    response.success = False
                    response.x = 0.0
                    response.y = 0.0
                    response.size = 0.0
                    response.is_pressed = False
                    response.timestamp = self.get_clock().now().to_msg()
                    return response
                
                # ì´ë¯¸ì§€ í¬ê¸° ì •ë³´
                img_height, img_width = current_color.shape[:2]
                
                # ì„¤ì •ëœ ëª©í‘œ í•´ìƒë„ ì •ë³´ (ì •ê·œí™”ìš©)
                if hasattr(self.current_camera, 'actual_camera_id') and self.current_camera.actual_camera_id is not None:
                    target_width, target_height = self.current_camera._get_optimal_resolution(self.current_camera.actual_camera_id)
                    self.get_logger().info(f"ğŸ” í•´ìƒë„ ì •ë³´: ì‹¤ì œ={img_width}x{img_height}, ëª©í‘œ={target_width}x{target_height}")
                else:
                    target_width, target_height = img_width, img_height
                    self.get_logger().info(f"ğŸ” í•´ìƒë„ ì •ë³´: ì‹¤ì œ=ëª©í‘œ={img_width}x{img_height}")
                
                # ë‹¤ì¤‘ ëª¨ë¸ë¡œ ê°ì²´ íƒì§€ (í˜„ì¬ ëª¨ë“œ ì „ë‹¬)
                self.get_logger().info(f"ğŸ¯ íƒì§€ ì„¤ì •: mode_id={self.current_front_mode_id}, confidence={self.confidence_threshold}")
                detected_objects = self.model_detector.detect_objects(current_color, current_depth, self.confidence_threshold, self.current_front_mode_id)
                
                # ë””ë²„ê¹…: ë‹¨ê³„ë³„ ë²„íŠ¼ íƒì§€ í™•ì¸
                raw_buttons = [obj for obj in detected_objects if obj.get('class_name') == 'button']
                self.get_logger().info(f"ğŸ” 1ë‹¨ê³„ YOLO íƒì§€: ë²„íŠ¼ {len(raw_buttons)}ê°œ")
                
                # ê°ì²´ì— OCR ê²°ê³¼ ì¶”ê°€ (display ê°ì²´ë§Œ)
                enhanced_objects = self._enhance_objects_with_ocr(current_color, detected_objects)
                
                enhanced_buttons = [obj for obj in enhanced_objects if obj.get('class_name') == 'button']
                self.get_logger().info(f"ğŸ” 2ë‹¨ê³„ OCR ì²˜ë¦¬ í›„: ë²„íŠ¼ {len(enhanced_buttons)}ê°œ")
                
                # ë²„íŠ¼ì€ CNNìœ¼ë¡œ ì§ì ‘ ì²˜ë¦¬, displayëŠ” OCR ì²˜ë¦¬ëœ ìƒíƒœ ìœ ì§€
                processed_objects = self._apply_enhanced_button_recognition(enhanced_objects, current_color, self.current_front_mode_id)
                
                # ë””ë²„ê¹…: ì²˜ë¦¬ëœ ë²„íŠ¼ ê°ì²´ë“¤ í™•ì¸
                all_button_objects = [obj for obj in processed_objects if obj.get('class_name') == 'button']
                for i, btn_obj in enumerate(all_button_objects):
                    button_id = btn_obj.get('button_id', 'None')
                    method = btn_obj.get('recognition_method', 'None')
                    confidence = btn_obj.get('confidence', 0)
                    self.get_logger().info(f"ğŸ” ì²˜ë¦¬ëœ ë²„íŠ¼ {i+1}: ID={button_id}, method={method}, conf={confidence:.3f}")
                
                # ë²„íŠ¼ í•„í„°ë§ ë¡œì§: button_id=0ì´ë©´ ëª¨ë“  íƒì§€ëœ ë²„íŠ¼, ì•„ë‹ˆë©´ IDê°€ í• ë‹¹ëœ ë²„íŠ¼ë§Œ
                total_button_objects = [obj for obj in processed_objects if obj.get('class_name') == 'button']
                
                if request.button_id == 0:
                    # button_id=0: í˜„ì¬ ìœ ì¼í•˜ê²Œ ê°ì§€ë˜ëŠ” ë²„íŠ¼ (ID í• ë‹¹ ì—¬ë¶€ ë¬´ê´€)
                    detected_buttons = total_button_objects
                else:
                    # íŠ¹ì • button_id ìš”ì²­: button_idê°€ í• ë‹¹ëœ ë²„íŠ¼ë“¤ë§Œ
                    detected_buttons = [
                        obj for obj in processed_objects 
                        if obj.get('class_name') == 'button' and 
                        obj.get('button_id') not in [None, 'unmapped', -1, 'None']
                    ]
                
                # ë²„íŠ¼ ê°œìˆ˜ì— ë”°ë¥¸ ì²˜ë¦¬
                if len(detected_buttons) == 0:
                    # íƒì§€ëœ ë²„íŠ¼ì´ ì—†ìŒ
                    if request.button_id == 0:
                        self.get_logger().info(f"íƒì§€ëœ ë²„íŠ¼ ì—†ìŒ: ì´ 0ê°œ")
                    else:
                        recognized_count = len([obj for obj in total_button_objects if obj.get('button_id') not in [None, 'unmapped', -1, 'None']])
                        self.get_logger().info(f"ì¸ì‹ëœ ë²„íŠ¼ ì—†ìŒ: íƒì§€ {len(total_button_objects)}ê°œ, ì¸ì‹ ì„±ê³µ {recognized_count}ê°œ")
                    response.success = False
                    response.x = 0.0
                    response.y = 0.0
                    response.size = 0.0
                    response.is_pressed = False
                    response.timestamp = self.get_clock().now().to_msg()
                    
                elif len(detected_buttons) == 1:
                    # ì •í™•íˆ 1ê°œì˜ ë²„íŠ¼ì´ ê°ì§€ë¨
                    btn = detected_buttons[0]
                    center = btn['center']
                    bbox = btn['bbox']
                    
                    # ì¢Œí‘œë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™” (ì„¤ì •ëœ ëª©í‘œ í•´ìƒë„ ê¸°ì¤€)
                    x_norm = float(center[0] / target_width)
                    y_norm = float(center[1] / target_height)
                    
                    # ë²„íŠ¼ í¬ê¸°ë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™” (ì„¤ì •ëœ ëª©í‘œ í•´ìƒë„ ê¸°ì¤€)
                    bbox_width = bbox[2] - bbox[0]
                    bbox_height = bbox[3] - bbox[1]
                    bbox_area = bbox_width * bbox_height
                    target_area = target_width * target_height
                    size_norm = float(bbox_area / target_area)
                    
                    # ë””ë²„ê·¸: í¬ê¸° ê³„ì‚° ìƒì„¸ ì •ë³´
                    img_area = img_width * img_height
                    size_norm_actual = float(bbox_area / img_area)
                    self.get_logger().info(f"ğŸ” í¬ê¸° ê³„ì‚°: bbox={bbox_width}x{bbox_height}(ë©´ì :{bbox_area})")
                    self.get_logger().info(f"ğŸ” ë©´ì  ë¹„êµ: ì‹¤ì œì´ë¯¸ì§€={img_area}, target={target_area}")
                    self.get_logger().info(f"ğŸ” ì •ê·œí™”: targetê¸°ì¤€={size_norm:.4f}, ì‹¤ì œê¸°ì¤€={size_norm_actual:.4f}")
                    
                    response.success = True
                    response.x = x_norm
                    response.y = y_norm
                    response.size = size_norm
                    response.is_pressed = bool(btn.get('is_pressed', False))
                    response.timestamp = self.get_clock().now().to_msg()
                    
                    confidence = btn.get('confidence', 1.0)
                    button_id = btn.get('button_id', 'unknown')
                    recognition_method = btn.get('recognition_method', 'unknown')
                    pressed_confidence = btn.get('pressed_confidence', 0.0)
                    pressed_method = btn.get('pressed_method', 'none')
                    self.get_logger().info(f"ë²„íŠ¼ ì¸ì‹ ì„±ê³µ: ID={button_id} ({recognition_method}), "
                                         f"x={x_norm:.3f}, y={y_norm:.3f}, size={size_norm:.3f}, "
                                         f"pressed={btn.get('is_pressed', False)} ({pressed_method}:{pressed_confidence:.3f}), conf={confidence:.2f}")
                    
                    # button_id ë§¤ì¹­ ê²€ì¦
                    if request.button_id != 0:
                        # 0ì´ ì•„ë‹Œ ê²½ìš°: íŠ¹ì • ë²„íŠ¼ ìš”ì²­ â†’ ID ë§¤ì¹­ í•„ìˆ˜
                        detected_button_id = btn.get('button_id', -1)
                        
                        if detected_button_id == -1:
                            # OCRë¡œ button_idë¥¼ ê°ì§€í•˜ì§€ ëª»í•¨
                            self.get_logger().warning(f"ìš”ì²­ëœ button_id({request.button_id})ì— ëŒ€í•œ OCR ë§¤ì¹­ ì‹¤íŒ¨")
                            response.success = False
                            response.x = 0.0
                            response.y = 0.0
                            response.size = 0.0
                            response.is_pressed = False
                            response.timestamp = self.get_clock().now().to_msg()
                            return response
                            
                        elif detected_button_id != request.button_id:
                            # ìš”ì²­ëœ IDì™€ ë‹¤ë¥¸ ë²„íŠ¼ì´ ê°ì§€ë¨
                            self.get_logger().warning(f"âŒ ID ë¶ˆì¼ì¹˜: ìš”ì²­({request.button_id}) â‰  ê°ì§€({detected_button_id})")
                            response.success = False
                            response.x = 0.0
                            response.y = 0.0
                            response.size = 0.0
                            response.is_pressed = False
                            response.timestamp = self.get_clock().now().to_msg()
                            return response
                        else:
                            # ID ë§¤ì¹­ ì„±ê³µ
                            self.get_logger().info(f"âœ… ID ë§¤ì¹­ ì„±ê³µ: button_id={detected_button_id}")
                    else:
                        # button_id=0ì¸ ê²½ìš°: í˜„ì¬ ìœ ì¼í•˜ê²Œ ê°ì§€ë˜ëŠ” ë²„íŠ¼ (ID ë§¤ì¹­ ë¶ˆí•„ìš”)
                        self.get_logger().info("ğŸ“ ìœ ì¼ ë²„íŠ¼ ê°ì§€ ëª¨ë“œ (ID ë§¤ì¹­ ìƒëµ)")
                else:
                    # 2ê°œ ì´ìƒì˜ ë²„íŠ¼ì´ ê°ì§€ë¨
                    button_ids = [obj.get('button_id', 'unknown') for obj in detected_buttons]
                    if request.button_id == 0:
                        self.get_logger().info(f"ë‹¤ì¤‘ ë²„íŠ¼ íƒì§€: ì´ {len(detected_buttons)}ê°œ (IDs: {button_ids})")
                    else:
                        recognized_count = len([obj for obj in total_button_objects if obj.get('button_id') not in [None, 'unmapped', -1, 'None']])
                        self.get_logger().info(f"ë‹¤ì¤‘ ë²„íŠ¼ ì¸ì‹: íƒì§€ {len(total_button_objects)}ê°œ, ì¸ì‹ ì„±ê³µ {recognized_count}ê°œ (IDs: {button_ids})")
                    
                    if request.button_id == 0:
                        # button_id=0: ìœ ì¼í•œ ë²„íŠ¼ë§Œ í—ˆìš© â†’ success=false
                        self.get_logger().warning("button_id=0 ìš”ì²­ì´ì§€ë§Œ ìœ ì¼í•œ ë²„íŠ¼ì´ ì•„ë‹˜ - success=false")
                        response.success = False
                        response.x = 0.0
                        response.y = 0.0
                        response.size = 0.0
                        response.is_pressed = False
                        response.timestamp = self.get_clock().now().to_msg()
                    else:
                        # íŠ¹ì • button_id ìš”ì²­ ì‹œ ë‹¤ì¤‘ ê°ì§€ëœ ë²„íŠ¼ë“¤ ì¤‘ í•´ë‹¹ ID ì°¾ê¸°
                        target_button = next((btn for btn in detected_buttons if btn.get('button_id') == request.button_id), None)
                        
                        if target_button is None:
                            # ìš”ì²­í•œ ë²„íŠ¼ì´ ì—†ìŒ
                            self.get_logger().warning(f"ìš”ì²­í•œ button_id={request.button_id}ê°€ ê°ì§€ë˜ì§€ ì•ŠìŒ")
                            response.success = False
                            response.x = 0.0
                            response.y = 0.0
                            response.size = 0.0
                            response.is_pressed = False
                            response.timestamp = self.get_clock().now().to_msg()
                        else:
                            # ìš”ì²­í•œ ë²„íŠ¼ì„ ì°¾ìŒ â†’ ì„±ê³µ
                            btn = target_button
                            center = btn['center']
                            bbox = btn['bbox']
                            
                            # ì¢Œí‘œë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™” (ì„¤ì •ëœ ëª©í‘œ í•´ìƒë„ ê¸°ì¤€)
                            x_norm = float(center[0] / target_width)
                            y_norm = float(center[1] / target_height)
                            
                            # ë²„íŠ¼ í¬ê¸°ë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™” (ì„¤ì •ëœ ëª©í‘œ í•´ìƒë„ ê¸°ì¤€)
                            bbox_width = bbox[2] - bbox[0]
                            bbox_height = bbox[3] - bbox[1]
                            bbox_area = bbox_width * bbox_height
                            target_area = target_width * target_height
                            size_norm = float(bbox_area / target_area)
                            
                            # ë””ë²„ê·¸: í¬ê¸° ê³„ì‚° ìƒì„¸ ì •ë³´ (ë‹¤ì¤‘ ë²„íŠ¼)
                            img_area = img_width * img_height
                            size_norm_actual = float(bbox_area / img_area)
                            self.get_logger().info(f"ğŸ” í¬ê¸° ê³„ì‚°(ë‹¤ì¤‘): bbox={bbox_width}x{bbox_height}(ë©´ì :{bbox_area})")
                            self.get_logger().info(f"ğŸ” ë©´ì  ë¹„êµ(ë‹¤ì¤‘): ì‹¤ì œì´ë¯¸ì§€={img_area}, target={target_area}")
                            self.get_logger().info(f"ğŸ” ì •ê·œí™”(ë‹¤ì¤‘): targetê¸°ì¤€={size_norm:.4f}, ì‹¤ì œê¸°ì¤€={size_norm_actual:.4f}")
                            
                            response.success = True
                            response.x = x_norm
                            response.y = y_norm
                            response.size = size_norm
                            response.is_pressed = bool(btn.get('is_pressed', False))
                            response.timestamp = self.get_clock().now().to_msg()
                            
                            confidence = btn.get('confidence', 1.0)
                            self.get_logger().info(f"íŠ¹ì • ë²„íŠ¼ íƒì§€ ì„±ê³µ: button_id={request.button_id}, "
                                                 f"x={x_norm:.3f}, y={y_norm:.3f}, size={size_norm:.3f}, "
                                                 f"pressed={btn.get('is_pressed', False)}, conf={confidence:.2f}")
                    
            except Exception as detection_error:
                self.get_logger().error(f"ë²„íŠ¼ íƒì§€ ì¤‘ ì—ëŸ¬: {detection_error}")
                response.success = False
                response.x = 0.0
                response.y = 0.0
                response.size = 0.0
                response.is_pressed = False
                response.timestamp = self.get_clock().now().to_msg()
                
        except Exception as e:
            self.get_logger().error(f"ë²„íŠ¼ ìƒíƒœ ì„œë¹„ìŠ¤ ì—ëŸ¬: {e}")
            response.robot_id = request.robot_id
            response.button_id = request.button_id
            response.success = False
            response.x = 0.0
            response.y = 0.0
            response.size = 0.0
            response.is_pressed = False
            response.timestamp = self.get_clock().now().to_msg()
        
        return response
    
    # í† í”½ í¼ë¸”ë¦¬ì‹œ ë©”ì†Œë“œë“¤
    

    
    def detect_and_publish_obstacles(self, objects, depth_camera, mode_id):
        """ëìŠ¤ ì¹´ë©”ë¼ ê¸°ë°˜ ì¥ì• ë¬¼ ê°ì§€ ë° ë°œí–‰ (ë³´ìˆ˜ì  ìœ ì§€ + ê°„ë‹¨ íŠ¸ë˜í‚¹)"""
        if mode_id != 5:  # ì¼ë°˜ ì£¼í–‰ ëª¨ë“œê°€ ì•„ë‹ˆë©´ ìŠ¤í‚µ
            return
        
        # ëìŠ¤ ì¹´ë©”ë¼ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if depth_camera is None or not hasattr(depth_camera, 'pixel_to_3d'):
            return
        
        try:
            current_time = self.get_clock().now()
            
            # í˜„ì¬ í”„ë ˆì„ì—ì„œ ê°ì§€ëœ ì¥ì• ë¬¼ë“¤ ìˆ˜ì§‘
            current_obstacles = self.obstacle_detector.detect_obstacles_from_objects(
                objects, depth_camera
            )
            
            # ë‚´ë¶€ íŠ¸ë˜í‚¹ ìƒíƒœ ì´ˆê¸°í™”
            if not hasattr(self, 'obstacle_tracks'):
                self.obstacle_tracks = {}  # tracking_id(or pseudo id) -> track dict
            if not hasattr(self, 'next_obstacle_track_id'):
                self.next_obstacle_track_id = 0
            
            # ë§¤ì¹­ì„ ìœ„í•œ í—¬í¼ (ì¢Œí‘œ ê·¼ì ‘ ê¸°ë°˜)
            def match_track(obs, tracks, pos_tol=0.08):
                tid = obs.get('tracking_id')
                if tid is not None and tid in tracks:
                    return tid
                best_id = None
                best_dist = 1e9
                for track_id, tr in tracks.items():
                    if tr.get('class_name') != obs.get('class_name'):
                        continue
                    dx = (tr['x'] - obs['x'])
                    dy = (tr['y'] - obs['y'])
                    dist = (dx*dx + dy*dy) ** 0.5
                    if dist < best_dist and dist <= pos_tol:
                        best_dist = dist
                        best_id = track_id
                return best_id
            
            # ê¸°ì¡´ íŠ¸ë™ ì—…ë°ì´íŠ¸ í”Œë˜ê·¸ ì´ˆê¸°í™”
            for tr in getattr(self, 'obstacle_tracks', {}).values():
                tr['updated'] = False
            
            # í˜„ì¬ ì¥ì• ë¬¼ë“¤ì„ íŠ¸ë™ì— ë§¤ì¹­/ì—…ë°ì´íŠ¸ ë° ì¦‰ì‹œ ë°œí–‰
            for obs in current_obstacles:
                obs.setdefault('x', obs.get('normalized_x', 0.0))
                obs.setdefault('y', obs.get('normalized_y', 0.0))
                
                track_id = match_track(obs, self.obstacle_tracks)
                if track_id is None:
                    track_id = f"trk_{self.next_obstacle_track_id}"
                    self.next_obstacle_track_id += 1
                    self.obstacle_tracks[track_id] = {
                        'class_name': obs['class_name'],
                        'dynamic': obs['dynamic'],
                        'x': obs['x'],
                        'y': obs['y'],
                        'depth': obs['depth'],
                        'last_seen': current_time,
                        'missing_frames': 0,
                        'started': True
                    }
                else:
                    tr = self.obstacle_tracks[track_id]
                    tr['x'] = obs['x']
                    tr['y'] = obs['y']
                    tr['depth'] = obs['depth']
                    tr['last_seen'] = current_time
                    tr['missing_frames'] = 0
                    tr['dynamic'] = obs['dynamic']
                    tr['class_name'] = obs['class_name']
                    tr['updated'] = True
                    tr.setdefault('started', True)
                
                obstacle_msg = Obstacle()
                obstacle_msg.robot_id = obs['robot_id']
                obstacle_msg.dynamic = obs['dynamic']
                obstacle_msg.x = obs['x']
                obstacle_msg.y = obs['y']
                obstacle_msg.depth = obs['depth']
                self.obstacle_pub.publish(obstacle_msg)
            
            # ëˆ„ë½ëœ íŠ¸ë™ ë³´ìˆ˜ì  ìœ ì§€/ì¢…ë£Œ
            HOLD_FRAMES = 5  # ì ê¹ ëŠê¸¸ ë•Œ ìœ ì§€í•  í”„ë ˆì„ ìˆ˜
            to_delete = []
            for track_id, tr in self.obstacle_tracks.items():
                if tr.get('updated'):
                    continue
                tr['missing_frames'] = tr.get('missing_frames', 0) + 1
                if tr['missing_frames'] <= HOLD_FRAMES:
                    obstacle_msg = Obstacle()
                    obstacle_msg.robot_id = 0
                    obstacle_msg.dynamic = tr['dynamic']
                    obstacle_msg.x = tr['x']
                    obstacle_msg.y = tr['y']
                    obstacle_msg.depth = tr['depth']
                    self.obstacle_pub.publish(obstacle_msg)
                else:
                    to_delete.append(track_id)
            for tid in to_delete:
                del self.obstacle_tracks[tid]
            
            self.last_obstacle_publish_time = current_time
            
        except Exception as e:
            self.get_logger().error(f"âŒ ì¥ì• ë¬¼ ê°ì§€ ë° ë°œí–‰ ì‹¤íŒ¨: {e}")
    

    
    def set_vs_mode_callback(self, request, response):
        """VS ëª¨ë“œ ì„¤ì • ì²˜ë¦¬ - ì „ë°©/í›„ë°© ë…ë¦½ì  ê´€ë¦¬"""
        try:
            self.get_logger().info(f"VS ëª¨ë“œ ì„¤ì • ìš”ì²­: robot_id={request.robot_id}, mode_id={request.mode_id}")
            
            if request.mode_id not in self.mode_names:
                self.get_logger().error(f"ì˜ëª»ëœ ëª¨ë“œ ID: {request.mode_id}")
                response.robot_id = request.robot_id
                response.success = False
                return response
            
            # ì „ë°©/í›„ë°© ëª¨ë“œ êµ¬ë¶„
            is_front_mode = request.mode_id in [3, 4, 5, 6]
            is_rear_mode = request.mode_id in [0, 1, 2]
            
            if is_front_mode:
                old_mode_id = self.current_front_mode_id
                old_mode = self.mode_names.get(old_mode_id, "Unknown")
                new_mode = self.mode_names[request.mode_id]
                
                self.current_front_mode_id = request.mode_id
                self.get_logger().info(f"ì „ë°© ëª¨ë“œ ë³€ê²½: {old_mode} â†’ {new_mode}")
                
                # ì „ë°© ì¹´ë©”ë¼ë§Œ ì—…ë°ì´íŠ¸
                self.update_front_camera()
                
            elif is_rear_mode:
                old_mode_id = self.current_rear_mode_id
                old_mode = self.mode_names.get(old_mode_id, "Unknown")
                new_mode = self.mode_names[request.mode_id]
                
                self.current_rear_mode_id = request.mode_id
                self.get_logger().info(f"í›„ë°© ëª¨ë“œ ë³€ê²½: {old_mode} â†’ {new_mode}")
                
                # í›„ë°© ì¹´ë©”ë¼ë§Œ ì—…ë°ì´íŠ¸
                self.update_rear_camera()
                
                # ğŸ‘¤ PersonTracker ëª¨ë“œ ì—°ë™ (í›„ë°© ëª¨ë“œ ë³€ê²½ì‹œ)
                if hasattr(self, 'person_tracker') and self.person_tracker:
                    self.person_tracker.set_mode(request.mode_id)
            
            response.robot_id = request.robot_id
            response.success = True
            
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì´ˆê¸°í™” (ì „ë°©/í›„ë°© êµ¬ë¶„ ì—†ì´ ì²˜ë¦¬)
            if request.mode_id in self.simulation_counters:
                self.simulation_counters[request.mode_id] = 0
                
        except Exception as e:
            self.get_logger().error(f"VS ëª¨ë“œ ì„¤ì • ì—ëŸ¬: {e}")
            response.robot_id = request.robot_id
            response.success = False
        
        return response
    
    def get_active_mode_id(self):
        """í˜„ì¬ í™œì„± ëª¨ë“œ ID ë°˜í™˜ (ì „ë°© ìš°ì„ , ëŒ€ê¸°ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš°)"""
        # ì „ë°©ì´ ëŒ€ê¸°ëª¨ë“œê°€ ì•„ë‹ˆë©´ ì „ë°© ëª¨ë“œ ë°˜í™˜
        if self.current_front_mode_id != 6:
            return self.current_front_mode_id
        # í›„ë°©ì´ ëŒ€ê¸°ëª¨ë“œê°€ ì•„ë‹ˆë©´ í›„ë°© ëª¨ë“œ ë°˜í™˜  
        if self.current_rear_mode_id != 0:
            return self.current_rear_mode_id
        # ë‘˜ ë‹¤ ëŒ€ê¸°ëª¨ë“œë©´ ì „ë°© ëª¨ë“œ ë°˜í™˜
        return self.current_front_mode_id
    
    def get_active_mode_name(self):
        """í˜„ì¬ í™œì„± ëª¨ë“œ ì´ë¦„ ë°˜í™˜"""
        mode_id = self.get_active_mode_id()
        return self.mode_names.get(mode_id, f"ID_{mode_id}")
    
    def get_active_cameras(self):
        """í˜„ì¬ í™œì„±í™”ëœ ì¹´ë©”ë¼ë“¤ì„ ë°˜í™˜ (ì „ë°©/í›„ë°© ëª¨ë‘ í¬í•¨)"""
        active_cameras = []
        
        # ì „ë°© ì¹´ë©”ë¼ ì²´í¬ - ì›¹ìº ê³¼ ëìŠ¤ë¥¼ ë¶„ë¦¬í•´ì„œ ì²˜ë¦¬
        if self.current_front_mode_id in [3, 4, 5, 6]:
            # ì›¹ìº ì´ ì‹¤ì œë¡œ ìˆê³  ëìŠ¤ì™€ ë‹¤ë¥¸ ê²½ìš°ë§Œ ì›¹ìº  ì°½ ì¶”ê°€
            front_webcam = getattr(self.camera_manager, 'front_webcam', None)
            front_depth = getattr(self.camera_manager, 'front_depth', None)
            
            # ì›¹ìº ì´ ì´ˆê¸°í™”ë˜ì–´ ìˆìœ¼ë©´ ì›¹ìº  ì°½ ì¶”ê°€
            if front_webcam and getattr(self.camera_manager, 'front_webcam_initialized', False):
                if self.current_front_mode_id == 3:
                    webcam_name = 'Front USB Webcam (Elevator Out)'
                elif self.current_front_mode_id == 4:
                    webcam_name = 'Front USB Webcam (Elevator In)'
                elif self.current_front_mode_id == 5:
                    webcam_name = 'Front USB Webcam (ArUco)'
                else:  # mode_id == 6
                    webcam_name = 'Front USB Webcam (Standby)'
                    
                active_cameras.append({
                    'camera': front_webcam,
                    'depth_camera': None,
                    'name': webcam_name,
                    'mode_id': self.current_front_mode_id,
                    'type': 'front_webcam'
                })
            
            # ëìŠ¤ ì¹´ë©”ë¼ê°€ ì´ˆê¸°í™”ë˜ì–´ ìˆìœ¼ë©´ ëìŠ¤ ì°½ ì¶”ê°€
            if front_depth and getattr(self.camera_manager, 'front_depth_initialized', False):
                if self.current_front_mode_id == 3:
                    depth_name = 'Front Depth Camera (Elevator Out)'
                elif self.current_front_mode_id == 4:
                    depth_name = 'Front Depth Camera (Elevator In)'
                elif self.current_front_mode_id == 5:
                    depth_name = 'Front Depth Camera (YOLO)'
                else:  # mode_id == 6
                    depth_name = 'Front Depth Camera (Standby)'
                    
                active_cameras.append({
                    'camera': front_depth,
                    'depth_camera': front_depth,
                    'name': depth_name,
                    'mode_id': self.current_front_mode_id,
                    'type': 'front_depth'
                })
        elif hasattr(self, 'current_camera') and self.current_camera is not None:
            # ë‹¤ë¥¸ ì „ë°© ëª¨ë“œë“¤ì€ ê¸°ì¡´ ë°©ì‹ (í˜¹ì‹œ ìˆë‹¤ë©´)
            active_cameras.append({
                'camera': self.current_camera,
                'depth_camera': getattr(self, 'current_depth_camera', None),
                'name': getattr(self, 'current_camera_name', 'Front Camera'),
                'mode_id': self.current_front_mode_id,
                'type': 'front'
            })
        
        # í›„ë°© ì¹´ë©”ë¼ ì²´í¬
        if hasattr(self, 'current_rear_camera') and self.current_rear_camera is not None:
            active_cameras.append({
                'camera': self.current_rear_camera,
                'depth_camera': None,  # í›„ë°©ì€ ëìŠ¤ ì¹´ë©”ë¼ ì—†ìŒ
                'name': getattr(self, 'current_rear_camera_name', 'Rear Camera'),
                'mode_id': self.current_rear_mode_id,
                'type': 'rear'
            })
        
        return active_cameras
    
    def update_front_camera(self):
        """ì „ë°© ì¹´ë©”ë¼ì™€ ëª¨ë¸ ì—…ë°ì´íŠ¸"""
        try:
            mode_name = self.mode_names.get(self.current_front_mode_id, f"ID_{self.current_front_mode_id}")
            old_camera_name = getattr(self, 'current_front_camera_name', "No Camera")
            
            # ì „ë°© ì¹´ë©”ë¼ ì´ˆê¸°í™”
            self.camera_manager.initialize_cameras_for_mode(self.current_front_mode_id)
            
            # ì „ë°© ì¹´ë©”ë¼ ì—…ë°ì´íŠ¸
            camera, depth_camera, camera_name = self.camera_manager.get_camera_for_mode(self.current_front_mode_id)
            
            self.current_camera = camera  # ë©”ì¸ ì¹´ë©”ë¼ (í˜¸í™˜ì„±)
            self.current_depth_camera = depth_camera
            self.current_camera_name = camera_name
            
            # ì „ë°© ëª¨ë¸ ì—…ë°ì´íŠ¸
            self.model_detector.set_model_for_mode(self.current_front_mode_id)
            model_info = self.model_detector.get_current_model_info()
            
            # ê²°ê³¼ ë¡œê·¸
            if camera:
                self.get_logger().info(f"ğŸ“· ì „ë°© ì¹´ë©”ë¼: {old_camera_name} â†’ {camera_name} (ëª¨ë“œ: {mode_name})")
            else:
                self.get_logger().warning(f"âš ï¸ ì „ë°© ëª¨ë“œ {mode_name}ìš© ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            if model_info['is_active']:
                current_classes = ', '.join(model_info['class_names'][:3])
                if len(model_info['class_names']) > 3:
                    current_classes += "..."
                self.get_logger().info(f"ï¿½ï¿½ ì „ë°© ëª¨ë¸: {model_info['model_name']} (í´ë˜ìŠ¤: {current_classes})")
            else:
                self.get_logger().info(f"ğŸ¤– ì „ë°© ëª¨ë¸ ë¹„í™œì„±í™”")
                
        except Exception as e:
            self.get_logger().error(f"ì „ë°© ì¹´ë©”ë¼ ì—…ë°ì´íŠ¸ ì—ëŸ¬: {e}")
    
    def update_rear_camera(self):
        """í›„ë°© ì¹´ë©”ë¼ ì—…ë°ì´íŠ¸ (í›„ë°©ì€ ëª¨ë¸ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)"""
        try:
            mode_name = self.mode_names.get(self.current_rear_mode_id, f"ID_{self.current_rear_mode_id}")
            old_camera_name = getattr(self, 'current_rear_camera_name', "No Camera")
            
            # í›„ë°© ì¹´ë©”ë¼ ì´ˆê¸°í™”
            self.camera_manager.initialize_cameras_for_mode(self.current_rear_mode_id)
            
            # í›„ë°© ì¹´ë©”ë¼ ì§ì ‘ í™•ì¸ ë° ì„¤ì • (ëª¨ë“  ëª¨ë“œì—ì„œ ì¹´ë©”ë¼ ì‚¬ìš©)
            if self.camera_manager.rear_webcam_initialized:
                self.current_rear_camera = self.camera_manager.rear_webcam
                if self.current_rear_mode_id == 0:  # í›„ë°© ëŒ€ê¸°ëª¨ë“œ
                    self.current_rear_camera_name = "Rear Webcam (Standby)"
                else:  # ë“±ë¡ ëª¨ë“œ(1), ì¶”ì  ëª¨ë“œ(2)
                    self.current_rear_camera_name = "Rear Webcam"
                
                self.get_logger().info(f"ğŸ“· í›„ë°© ì¹´ë©”ë¼: {old_camera_name} â†’ {self.current_rear_camera_name} (ëª¨ë“œ: {mode_name})")
                
                # ğŸ“¹ í›„ë°© ì¹´ë©”ë¼ê°€ í™œì„±í™”ë˜ë©´ UDP ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
                self._start_rear_camera_streaming()
                
            else:
                self.current_rear_camera = None
                self.current_rear_camera_name = "None"
                self.get_logger().warning(f"âš ï¸ í›„ë°© ëª¨ë“œ {mode_name}ìš© ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                # ğŸ“¹ í›„ë°© ì¹´ë©”ë¼ê°€ ë¹„í™œì„±í™”ë˜ë©´ UDP ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€
                self._stop_rear_camera_streaming()
                
        except Exception as e:
            self.get_logger().error(f"í›„ë°© ì¹´ë©”ë¼ ì—…ë°ì´íŠ¸ ì—ëŸ¬: {e}")
    

    
    def elevator_status_callback(self, request, response):
        """ì—˜ë¦¬ë² ì´í„° ìœ„ì¹˜ ë° ë°©í–¥ ê°ì§€ ì²˜ë¦¬ - display ê°ì²´ OCR ê¸°ë°˜"""
        try:
            self.get_logger().info(f"ì—˜ë¦¬ë² ì´í„° ìƒíƒœ ê°ì§€ ìš”ì²­: robot_id={request.robot_id}")
            
            # í˜„ì¬ í™œì„± ì¹´ë©”ë¼ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            current_color = None
            current_depth = None
            
            # ì „ë©´ ì¹´ë©”ë¼ ì‚¬ìš© (ì—˜ë¦¬ë² ì´í„° ë””ìŠ¤í”Œë ˆì´ ê°ì§€ì— ì í•©)
            if self.current_camera:
                depth_frame, color_frame = self.current_camera.get_frames()
                if color_frame is not None:
                    current_color = color_frame
                    current_depth = depth_frame
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            detected_floor = 1  # ê¸°ë³¸ 1ì¸µ
            detected_direction = 0  # ê¸°ë³¸ ìƒí–‰
            success = True  # ë¬´ì¡°ê±´ ì„±ê³µ ë°˜í™˜
            
            if current_color is not None:
                # ê°ì²´ ê°ì§€ ìˆ˜í–‰
                detected_objects = self.model_detector.detect_objects(
                    current_color, 
                    current_depth, 
                    self.confidence_threshold, 
                    self.current_front_mode_id
                )
                
                # ê°ì²´ì— OCR ê²°ê³¼ ì¶”ê°€ (display ê°ì²´ë§Œ)
                enhanced_objects = self._enhance_objects_with_ocr(current_color, detected_objects)
                
                # 'display' ê°ì²´ì—ì„œ ì¸µìˆ˜ ì •ë³´ ì¶”ì¶œ
                display_objects = [obj for obj in enhanced_objects if obj.get('class_name') == 'display']
                
                if display_objects:
                    for display_obj in display_objects:
                        floor_number = display_obj.get('floor_number')
                        floor_text = display_obj.get('ocr_text', '')
                        ocr_success = display_obj.get('ocr_success', False)
                        
                        if floor_number is not None:
                            detected_floor = floor_number
                            success = True
                            self.get_logger().debug(f"ğŸ¢ ì—˜ë¦¬ë² ì´í„° ì¸µìˆ˜ ì¸ì‹: '{floor_text}' -> {detected_floor}ì¸µ (ì‹ ë¢°ë„: {display_obj.get('confidence', 0):.2f})")
                            break  # ì²« ë²ˆì§¸ ì„±ê³µí•œ ê²°ê³¼ ì‚¬ìš©
                        elif ocr_success:
                            self.get_logger().warn(f"ì¸µìˆ˜ íŒŒì‹± ì‹¤íŒ¨: '{floor_text}'")
                        else:
                            self.get_logger().debug(f"ë””ìŠ¤í”Œë ˆì´ ê°ì§€ë¨ (OCR ì‹¤íŒ¨)")
                else:
                    self.get_logger().debug("display ê°ì²´ê°€ ê°ì§€ë˜ì§€ ì•ŠìŒ")
            else:
                self.get_logger().warn("ì¹´ë©”ë¼ì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ")
            
            # direction_light ê°ì²´ë¡œ ë°©í–¥ ê°ì§€ - ì—˜ë¦¬ë² ì´í„° ì™¸ë¶€ì—ì„œë§Œ ìˆ˜í–‰
            if self.current_front_mode_id != 4:  # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ
                if current_color is not None and 'enhanced_objects' in locals():
                    direction_objects = [obj for obj in enhanced_objects if obj.get('class_name') == 'direction_light']
                    if direction_objects:
                        # ğŸš¦ ë°©í–¥ë“± ì‹¤ì‹œê°„ ê°ì§€ ì‹œë„
                        detected_direction = self._detect_direction_by_lights(current_color, direction_objects)
                        
                        # ğŸ¯ ë°©í–¥ ì—…ë°ì´íŠ¸ (ê¹œë¹¡ì„ ê°ì§€ ì‹œ í•­ìƒ ì—…ë°ì´íŠ¸)
                        if detected_direction != -1:
                            if (detected_direction != self.last_elevator_direction or self.last_blink_detected):
                                # ë°©í–¥ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ê¹œë¹¡ì„ì´ ê°ì§€ëœ ê²½ìš° ì—…ë°ì´íŠ¸
                                self.last_elevator_direction = detected_direction
                                self.last_direction_detection_time = self.get_clock().now()
                                blink_info = " (ê¹œë¹¡ì„ ê°ì§€)" if self.last_blink_detected else ""
                                self.get_logger().info(f"ğŸ¯ ë°©í–¥ë“± ê¸°ë°˜ ë°©í–¥ ì—…ë°ì´íŠ¸: {len(direction_objects)}ê°œ â†’ {'ìƒí–‰' if detected_direction == 0 else 'í•˜í–‰'}{blink_info}")
                                
                                # ğŸ”„ ê¹œë¹¡ì„ ì²˜ë¦¬ ì™„ë£Œ í›„ í”Œë˜ê·¸ ì´ˆê¸°í™” (ë‹¤ìŒ ê¹œë¹¡ì„ ê°ì§€ë¥¼ ìœ„í•´)
                                if self.last_blink_detected:
                                    self.last_blink_detected = False
                                    self.get_logger().info("ğŸ”„ ê¹œë¹¡ì„ ê°ì§€ í”Œë˜ê·¸ ì´ˆê¸°í™” ì™„ë£Œ")
                            else:
                                # ë°©í–¥ ë³€í™” ì—†ìŒ (ê¹œë¹¡ì„ë„ ì—†ìŒ)
                                detected_direction = self.last_elevator_direction
                    else:
                        # ë°©í–¥ë“±ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ìºì‹œëœ ë°©í–¥ ì‚¬ìš©
                        detected_direction = self.last_elevator_direction
                        self.get_logger().debug(f"ë°©í–¥ë“± ë¯¸ê°ì§€ â†’ ìºì‹œëœ ë°©í–¥ ì‚¬ìš©: {'ìƒí–‰' if detected_direction == 0 else 'í•˜í–‰'}")
                else:
                    # ì´ë¯¸ì§€ë‚˜ ê°ì²´ê°€ ì—†ìœ¼ë©´ ìºì‹œëœ ë°©í–¥ ì‚¬ìš©
                    detected_direction = self.last_elevator_direction
                    self.get_logger().debug(f"ì´ë¯¸ì§€/ê°ì²´ ì—†ìŒ â†’ ìºì‹œëœ ë°©í–¥ ì‚¬ìš©: {'ìƒí–‰' if detected_direction == 0 else 'í•˜í–‰'}")
            else:
                # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€ ëª¨ë“œì—ì„œëŠ” ë°©í–¥ë“±ì´ ì—†ìœ¼ë¯€ë¡œ ìºì‹œëœ ë°©í–¥ ì‚¬ìš©
                detected_direction = self.last_elevator_direction
                self.get_logger().debug(f"ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€ ëª¨ë“œ â†’ ìºì‹œëœ ë°©í–¥ ì‚¬ìš©: {'ìƒí–‰' if detected_direction == 0 else 'í•˜í–‰'}")
            
            # ì‘ë‹µ ì„¤ì •
            response.robot_id = request.robot_id
            response.success = success
            response.direction = detected_direction
            response.position = detected_floor
            
            direction_str = "ìƒí–‰" if detected_direction == 0 else "í•˜í–‰"
            status_str = "OCR ì„±ê³µ" if success else "OCR ì‹¤íŒ¨ (ê¸°ë³¸ê°’ ì‚¬ìš©)"
            self.get_logger().info(f"ì—˜ë¦¬ë² ì´í„° ìƒíƒœ: {direction_str}, {detected_floor}ì¸µ ({status_str})")
                
        except Exception as e:
            self.get_logger().error(f"ì—˜ë¦¬ë² ì´í„° ìƒíƒœ ê°ì§€ ì—ëŸ¬: {e}")
            response.robot_id = request.robot_id
            response.success = True  # ë¬´ì¡°ê±´ ì„±ê³µ ë°˜í™˜
            response.direction = 0
            response.position = 1
        
        return response
    
    def _enhance_objects_with_ocr(self, color_image: np.ndarray, objects: List[dict]) -> List[dict]:
        """ê°ì²´ ëª©ë¡ì—ì„œ display ê°ì²´ë“¤ì— ëŒ€í•´ OCR ìˆ˜í–‰í•˜ê³  direction_light ê°ì²´ë“¤ì— ëŒ€í•´ ìƒ‰ìƒ ë¶„ì„ ìˆ˜í–‰"""
        enhanced_objects = []
        
        # ë°©í–¥ë“± ìœ„ì¹˜ ë¶„ì„ì„ ìœ„í•´ ë¨¼ì € direction_light ê°ì²´ë“¤ì„ ì°¾ì•„ì„œ ì •ë ¬
        direction_lights = [obj for obj in objects if obj.get('class_name') == 'direction_light']
        sorted_direction_lights = sorted(direction_lights, key=lambda x: x['center'][1]) if len(direction_lights) >= 2 else []
        
        for obj in objects:
            enhanced_obj = obj.copy()
            
            # display ê°ì²´ì— ëŒ€í•´ì„œë§Œ OCR ìˆ˜í–‰
            if obj.get('class_name') == 'display':
                try:
                    bbox = obj.get('bbox')
                    if bbox:
                        # ğŸ”¥ ìµœì í™”ëœ EasyOCR ì‚¬ìš© (ë‹¨ìˆœ í¬ë¡­ + EasyOCRë§Œ)
                        ocr_result = self.display_ocr.recognize_from_display_bbox_stable(color_image, bbox)
                        floor_text = ocr_result.get('text', '?')
                        confidence = ocr_result.get('confidence', 0.0)
                        digit_bbox = ocr_result.get('digit_bbox', None)
                        floor_number = None
                        
                        if floor_text and floor_text.strip() and floor_text != "?":
                            floor_number = self._parse_floor_number(floor_text.strip())
                        
                        # OCR ê²°ê³¼ë¥¼ ê°ì²´ì— ì €ì¥
                        enhanced_obj['ocr_text'] = floor_text if floor_text else ""
                        enhanced_obj['floor_number'] = floor_number
                        enhanced_obj['ocr_success'] = bool(floor_text and floor_text.strip() and floor_text != "?")
                        enhanced_obj['ocr_confidence'] = confidence  # ì‹ ë¢°ë„ ì¶”ê°€
                        enhanced_obj['digit_bbox'] = digit_bbox  # ğŸ¯ ìˆ«ì ì˜ì—­ ë°”ìš´ë”©ë°•ìŠ¤ ì¶”ê°€
                        
                except Exception as e:
                    self.get_logger().error(f"DisplayOCR ì—ëŸ¬: {e}")
                    enhanced_obj['ocr_text'] = ""
                    enhanced_obj['floor_number'] = None
                    enhanced_obj['ocr_success'] = False
                    enhanced_obj['ocr_confidence'] = 0.0
                    enhanced_obj['digit_bbox'] = None
            
            # ğŸš¦ direction_light ê°ì²´ì— ëŒ€í•´ ìƒ‰ìƒ ë¶„ì„ ë° ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
            elif obj.get('class_name') == 'direction_light':
                try:
                    # ìƒ‰ìƒ ë¶„ì„
                    detected_color = self._analyze_light_color(color_image, obj)
                    brightness = self._get_light_brightness(color_image, obj)
                    
                    # ìœ„ì¹˜ ë¶„ì„ (ìœ„ìª½/ì•„ë˜ìª½ êµ¬ë¶„)
                    light_position = 'unknown'
                    if len(sorted_direction_lights) >= 2:
                        current_obj_y = obj['center'][1]
                        if current_obj_y == sorted_direction_lights[0]['center'][1]:
                            light_position = 'upper'
                        elif current_obj_y == sorted_direction_lights[-1]['center'][1]:
                            light_position = 'lower'
                        else:
                            light_position = 'middle'
                    
                    # ìƒ‰ìƒ ë° ìœ„ì¹˜ ì •ë³´ë¥¼ ê°ì²´ì— ì €ì¥
                    enhanced_obj['light_color'] = detected_color
                    enhanced_obj['light_brightness'] = brightness
                    enhanced_obj['light_position'] = light_position
                    
                    # ë””ë²„ê·¸ ë¡œê·¸
                    self.get_logger().debug(f"ğŸš¦ ë°©í–¥ë“± ë¶„ì„: ìœ„ì¹˜={light_position}, ìƒ‰ìƒ={detected_color}, ë°ê¸°={brightness:.1f}")
                    
                except Exception as e:
                    self.get_logger().error(f"ë°©í–¥ë“± ìƒ‰ìƒ ë¶„ì„ ì—ëŸ¬: {e}")
                    enhanced_obj['light_color'] = 'UNKNOWN'
                    enhanced_obj['light_brightness'] = 0.0
                    enhanced_obj['light_position'] = 'unknown'
            
            enhanced_objects.append(enhanced_obj)
        
        return enhanced_objects
    
    def _parse_floor_number(self, floor_text: str) -> Optional[int]:
        """OCR í…ìŠ¤íŠ¸ì—ì„œ ì¸µìˆ˜ ì¶”ì¶œ"""
        try:
            # ê³µë°± ì œê±°
            text = floor_text.strip().upper()
            
            if not text:
                return None
            
            # ì§€í•˜ì¸µ ì²˜ë¦¬ (B1, B2 ë“±)
            if text.startswith('B'):
                basement_str = text[1:]
                if basement_str.isdigit():
                    return -int(basement_str)  # ì§€í•˜ëŠ” ìŒìˆ˜ë¡œ
            
            # ì¼ë°˜ ì¸µìˆ˜ (ìˆ«ìë§Œ ì¶”ì¶œ)
            # "12F", "3ì¸µ", "05" ë“±ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
            numbers = ''.join(c for c in text if c.isdigit())
            
            if numbers:
                floor_num = int(numbers)
                # í•©ë¦¬ì ì¸ ë²”ìœ„ ì²´í¬ (ì§€ìƒ 1~50ì¸µ)
                if 1 <= floor_num <= 50:
                    return floor_num
                elif floor_num == 0:
                    return 1  # 0ì€ 1ì¸µìœ¼ë¡œ ê°„ì£¼
            
            # íŠ¹ìˆ˜ ê²½ìš° ì²˜ë¦¬
            if text in ['G', 'GF', 'L']:  # Ground Floor, Lobby
                return 1
            
            # ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ì¸µìˆ˜ ì²˜ë¦¬
            if numbers:
                floor_num = int(numbers)
                if floor_num > 50:
                    return 50
            
            self.get_logger().debug(f"ì¸µìˆ˜ íŒŒì‹± ì‹¤íŒ¨: '{floor_text}' -> '{text}'")
            return None
            
        except Exception as e:
            self.get_logger().error(f"ì¸µìˆ˜ íŒŒì‹± ì—ëŸ¬: {e}")
            return None
    
    def door_status_callback(self, request, response):
        """ë¬¸ ì—´ë¦¼ ê°ì§€ ì²˜ë¦¬ - ê°ì²´ ê°ì§€ ê¸°ë°˜"""
        try:
            self.get_logger().info(f"ë¬¸ ìƒíƒœ ê°ì§€ ìš”ì²­: robot_id={request.robot_id}")
            
            # í˜„ì¬ í™œì„± ì¹´ë©”ë¼ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            current_color = None
            current_depth = None
            
            # ì „ë©´ ì¹´ë©”ë¼ ì‚¬ìš© (ë¬¸ ê°ì§€ì— ì í•©)
            if self.current_camera:
                depth_frame, color_frame = self.current_camera.get_frames()
                if color_frame is not None:
                    current_color = color_frame
                    current_depth = depth_frame
            
            # ì¹´ë©”ë¼ì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš° ì„ì‹œë¡œ ì„±ê³µ ë°˜í™˜
            if current_color is None:
                self.get_logger().warn("ì¹´ë©”ë¼ì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ - ë¬¸ ìƒíƒœ ê°ì§€ ì‹¤íŒ¨")
                response.robot_id = request.robot_id
                response.success = True  # ë¬´ì¡°ê±´ ì„±ê³µ ë°˜í™˜
                response.door_opened = False  # ì„ì‹œ ì¡°ì¹˜: ì¹´ë©”ë¼ ì‹¤íŒ¨ ì‹œì—ë„ True
                return response
            
            # ê°ì²´ ê°ì§€ ìˆ˜í–‰
            detected_objects = self.model_detector.detect_objects(
                current_color, 
                current_depth, 
                self.confidence_threshold, 
                self.current_front_mode_id
            )
            
            # door ê°ì²´ê°€ ê°ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸
            door_detected = False
            door_count = 0
            
            for obj in detected_objects:
                if obj['class_name'] == 'door':
                    door_detected = True
                    door_count += 1
                    self.get_logger().info(f"ë¬¸ ê°ì²´ ê°ì§€ë¨: ì‹ ë¢°ë„={obj['confidence']:.2f}, ìœ„ì¹˜=({obj['center'][0]}, {obj['center'][1]})")
            
            # ë¬¸ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ì—´ë¦¼, ê°ì§€ë˜ë©´ ë‹«í˜ìœ¼ë¡œ íŒë‹¨
            response.robot_id = request.robot_id
            response.success = True
            response.door_opened = not door_detected  # ğŸ”¥ ë¡œì§ ìˆ˜ì •: ë¬¸ì´ ì•ˆ ë³´ì´ë©´ ì—´ë¦° ê²ƒ
            
            door_str = "ì—´ë¦¼" if not door_detected else "ë‹«í˜"
            self.get_logger().info(f"ë¬¸ ìƒíƒœ: {door_str} (ê°ì§€ëœ ë¬¸ ê°ì²´ ìˆ˜: {door_count})")
                
        except Exception as e:
            self.get_logger().error(f"ë¬¸ ìƒíƒœ ê°ì§€ ì—ëŸ¬: {e}")
            response.robot_id = request.robot_id
            response.success = True  # ë¬´ì¡°ê±´ ì„±ê³µ ë°˜í™˜
            response.door_opened = False
        
        return response
    
    def detect_and_publish_glass_door_status(self, objects, mode_id):
        """ìœ ë¦¬ ë¬¸ ìƒíƒœ ê°ì§€ ë° ë°œí–‰ (ì´ë²¤íŠ¸ ê¸°ë°˜)"""
        if mode_id != 5:  # ì „ë°© ì¼ë°˜ ì£¼í–‰ ëª¨ë“œì—ì„œë§Œ (ëìŠ¤ ì¹´ë©”ë¼ ì‚¬ìš©)
            return
            
        try:
            # door ê°ì²´ê°€ ê°ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸
            door_detected = False
            
            for obj in objects:
                if obj['class_name'] == 'door':
                    door_detected = True
                    break
            
            # í˜„ì¬ ìƒíƒœ ê³„ì‚° (ë¬¸ì´ ì•ˆ ë³´ì´ë©´ ì—´ë¦° ê²ƒ)
            current_opened = not door_detected
            
            # ì´ì „ ìƒíƒœì™€ ë¹„êµí•˜ì—¬ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ë°œí–‰
            if self.last_glass_door_opened is None:
                # ì²« ë²ˆì§¸ ì‹¤í–‰ ì‹œ ì´ˆê¸°í™”
                self.last_glass_door_opened = current_opened
                self.get_logger().info(f"ğŸšª ìœ ë¦¬ ë¬¸ ìƒíƒœ ì´ˆê¸°í™”: {'ì—´ë¦¼' if current_opened else 'ë‹«í˜'}")
                return
            
            # ìƒíƒœê°€ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ë°œí–‰
            if self.last_glass_door_opened != current_opened:
                # ìœ ë¦¬ ë¬¸ ìƒíƒœ ë©”ì‹œì§€ ìƒì„± ë° ë°œí–‰
                glass_door_msg = GlassDoorStatus()
                glass_door_msg.robot_id = 0
                glass_door_msg.opened = current_opened
                
                self.glass_door_pub.publish(glass_door_msg)
                
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                old_state = "ì—´ë¦¼" if self.last_glass_door_opened else "ë‹«í˜"
                new_state = "ì—´ë¦¼" if current_opened else "ë‹«í˜"
                self.last_glass_door_opened = current_opened
                
                # ë¡œê·¸ ì¶œë ¥
                self.get_logger().info(f"ğŸšª ìœ ë¦¬ ë¬¸ ìƒíƒœ ë³€ê²½: {old_state} â†’ {new_state} (ì´ë²¤íŠ¸ ë°œí–‰)")
                
        except Exception as e:
            self.get_logger().error(f"âŒ ìœ ë¦¬ ë¬¸ ìƒíƒœ ê°ì§€ ë° ë°œí–‰ ì‹¤íŒ¨: {e}")
    

    
    def location_callback(self, request, response):
        """í˜„ì¬ ìœ„ì¹˜ ê°ì§€ ì²˜ë¦¬"""
        try:
            self.get_logger().info(f"ìœ„ì¹˜ ê°ì§€ ìš”ì²­: robot_id={request.robot_id}")
            
            response.robot_id = request.robot_id
            response.success = True
            
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë³„ ìœ„ì¹˜ ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬
            if self.get_active_mode_id() == 100:  # ë°°ì†¡ ì‹œë®¬ë ˆì´ì…˜
                counter = self.simulation_counters[100]
                if counter == 0:
                    location_id = 2  # RES_PICKUP
                    self.get_logger().info("ë°°ì†¡ ì‹œë®¬ë ˆì´ì…˜: í”½ì—… ì¥ì†Œ ë„ì°©")
                elif counter == 1:
                    location_id = 101  # ROOM_101
                    self.get_logger().info("ë°°ì†¡ ì‹œë®¬ë ˆì´ì…˜: 101í˜¸ ë„ì°©")
                else:
                    location_id = 101  # ROOM_101 ìœ ì§€
                    self.get_logger().info("ë°°ì†¡ ì‹œë®¬ë ˆì´ì…˜: 101í˜¸ ëŒ€ê¸° ì¤‘")
                
                self.simulation_counters[100] += 1
                response.location_id = location_id
                
            elif self.get_active_mode_id() == 103:  # ë³µê·€ ì‹œë®¬ë ˆì´ì…˜
                counter = self.simulation_counters[103]
                if counter == 0:
                    location_id = 0  # LOB_WAITING
                    self.get_logger().info("ë³µê·€ ì‹œë®¬ë ˆì´ì…˜: ë¡œë¹„ ëŒ€ê¸° ìœ„ì¹˜ ë„ì°©")
                else:
                    location_id = 0  # LOB_WAITING ìœ ì§€
                    self.get_logger().info("ë³µê·€ ì‹œë®¬ë ˆì´ì…˜: ë¡œë¹„ ëŒ€ê¸° ì¤‘")
                
                self.simulation_counters[103] += 1
                response.location_id = location_id
                
            elif self.current_front_mode_id == 5:  # ì¼ë°˜ ì£¼í–‰ ëª¨ë“œ - ArUco ë§ˆì»¤ ê¸°ë°˜ ìœ„ì¹˜
                current_location = self.detect_and_update_location()
                response.location_id = current_location
                
                location_names = {
                    0: "LOB_WAITING", 1: "LOB_CALL", 2: "RES_PICKUP", 3: "RES_CALL",
                    4: "SUP_PICKUP", 5: "ELE_1", 6: "ELE_2", 101: "ROOM_101",
                    102: "ROOM_102", 201: "ROOM_201", 202: "ROOM_202"
                }
                location_name = location_names.get(current_location, f"UNKNOWN({current_location})")
                
                # ë§ˆì§€ë§‰ ê°ì§€ ì‹œê°„ ì •ë³´ í¬í•¨
                if self.last_detection_time:
                    time_diff = (self.get_clock().now() - self.last_detection_time).nanoseconds / 1e9
                    self.get_logger().debug(f"í˜„ì¬ ìœ„ì¹˜: {location_name} (ArUco ê¸°ë°˜, ë§ˆì§€ë§‰ ê°ì§€: {time_diff:.1f}ì´ˆ ì „)")
                else:
                    self.get_logger().debug(f"í˜„ì¬ ìœ„ì¹˜: {location_name} (ArUco ê¸°ë°˜, ì´ˆê¸°ê°’)")
                    
            else:  # ê¸°íƒ€ ëª¨ë“œ - ê¸°ë³¸ ìœ„ì¹˜ ë°˜í™˜
                response.location_id = self.last_detected_location_id  # ë§ˆì§€ë§‰ ì•Œë ¤ì§„ ìœ„ì¹˜ ìœ ì§€
                mode_name = self.get_active_mode_name()
                self.get_logger().debug(f"ìœ„ì¹˜ ì„œë¹„ìŠ¤: {mode_name}ì—ì„œëŠ” ArUco ì‚¬ìš© ì•ˆí•¨ (ë§ˆì§€ë§‰ ìœ„ì¹˜ ìœ ì§€)")
                
        except Exception as e:
            self.get_logger().error(f"ìœ„ì¹˜ ê°ì§€ ì—ëŸ¬: {e}")
            response.robot_id = request.robot_id
            response.success = False
            response.location_id = self.last_detected_location_id
        
        return response

    def _draw_objects_on_image(self, image: np.ndarray, objects: List[dict], mode_id: int = None) -> np.ndarray:
        """YOLOë¡œ íƒì§€ëœ ê°ì²´ë“¤ì„ ì´ë¯¸ì§€ì— ì‹œê°í™”"""
        import cv2
        
        # í˜„ì¬ ëª¨ë“œ ID ê°€ì ¸ì˜¤ê¸° (ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬ë˜ì§€ ì•Šì€ ê²½ìš°)
        if mode_id is None:
            mode_id = self.get_active_mode_id()
        
        # í™”ë©´ ì¤‘ì‹¬ì  ê³„ì‚°
        image_height, image_width = image.shape[:2]
        screen_center = (image_width // 2, image_height // 2)
        
        # ê°ì²´ íƒ€ì…ë³„ ìƒ‰ìƒ ì •ì˜
        color_map = {
            'person': (255, 0, 0),        # ë¹¨ê°„ìƒ‰ (ë™ì  ì¥ì• ë¬¼)
            'chair': (0, 255, 255),       # ë…¸ë€ìƒ‰ (ì •ì  ì¥ì• ë¬¼)
            'door': (255, 255, 0),        # ì²­ë¡ìƒ‰
            'button': (0, 255, 0),        # ì´ˆë¡ìƒ‰
            'direction_light': (255, 165, 0),  # ì£¼í™©ìƒ‰
            'display': (0, 165, 255),     # ì˜¤ë Œì§€ìƒ‰
        }
        
        for i, obj in enumerate(objects):
            center = obj['center']
            is_pressed = obj.get('is_pressed', False)
            depth_mm = obj['depth_mm']
            class_name = obj.get('class_name', f'obj_{i+1}')
            confidence = obj.get('confidence', 1.0)
            bbox = obj.get('bbox', None)
            model_name = obj.get('model_name', 'unknown')
            
            # YOLO ë°”ìš´ë”©ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            if bbox and len(bbox) == 4:
                x1, y1, x2, y2 = bbox
                
                # ì¥ì• ë¬¼ ì—¬ë¶€ í™•ì¸
                is_obstacle = obj.get('is_obstacle', False)
                
                # ìƒ‰ìƒê³¼ ë‘ê»˜ ê²°ì •
                if class_name == 'button' and is_pressed:
                    color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (ëˆŒë¦° ë²„íŠ¼)
                    thickness = 2
                elif is_obstacle:
                    # ì¥ì• ë¬¼ì¸ ê²½ìš° ë” ë‘ê»ê²Œ í‘œì‹œ
                    color = color_map.get(class_name, (128, 128, 128))
                    thickness = 3
                else:
                    # ì¼ë°˜ ê°ì²´
                    color = color_map.get(class_name, (128, 128, 128))
                    thickness = 2
                
                cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)
                
                # í´ë˜ìŠ¤ ì´ë¦„ê³¼ ì‹ ë¢°ë„ í‘œì‹œ
                if class_name == 'button':
                    # ë§¤í•‘ëœ ë²„íŠ¼ ID í‘œì‹œ
                    button_id = obj.get('button_id', 'unknown')
                    floor_type = obj.get('floor_type', 'unknown')
                    recognition_method = obj.get('recognition_method', 'unknown')
                    
                    # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€ ëª¨ë“œì—ì„œëŠ” CNN ê²°ê³¼ë§Œ í‘œì‹œ
                    if self.get_active_mode_id() == 4:  # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€ ëª¨ë“œ
                        if button_id == 102:
                            label = "OPEN"
                        elif button_id == 103:
                            label = "CLOSE"
                        elif button_id == 101:
                            label = "UP"
                        elif button_id == 100:
                            label = "DOWN"
                        elif button_id == 13:
                            label = "B1"
                        elif button_id == 14:
                            label = "B2"
                        elif isinstance(button_id, int) and button_id > 0:
                            label = f"{button_id}F"
                        else:
                            label = f"{button_id}"
                        
                        # CNN ì‹ ë¢°ë„ í‘œì‹œ
                        cnn_confidence = obj.get('confidence', 0.0)
                        if recognition_method == 'cnn_primary':
                            label += f" ({cnn_confidence:.2f})"
                        elif recognition_method == 'cnn_failed':
                            label += " (FAIL)"
                        elif recognition_method == 'cnn_unavailable':
                            label += " (NO_CNN)"
                    else:
                        # ì—˜ë¦¬ë² ì´í„° ì™¸ë¶€ ëª¨ë“œì—ì„œëŠ” ê¸°ì¡´ ë°©ì‹ ìœ ì§€
                        group_info = obj.get('group_info', '')
                        
                        if button_id == 102:
                            label = "OPEN"
                        elif button_id == 103:
                            label = "CLOSE"
                        elif button_id == 101:
                            label = "UP"
                        elif button_id == 100:
                            label = "DOWN"
                        elif floor_type == 'basement':
                            if button_id == 13:
                                label = "B1"
                            elif button_id == 14:
                                label = "B2"
                            else:
                                label = f"B{button_id}"
                        elif floor_type == 'floor' and isinstance(button_id, int):
                            label = f"{button_id}F"
                        else:
                            label = f"{button_id}"
                        
                        # ê·¸ë£¹ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€ë¡œ í‘œì‹œ
                        if group_info:
                            label += f" ({group_info})"
                elif class_name == 'display':
                    # OCR ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                    floor_number = obj.get('floor_number', None)
                    floor_text = obj.get('ocr_text', '')
                    ocr_success = obj.get('ocr_success', False)
                    digit_bbox = obj.get('digit_bbox', None)
                    
                    # ğŸ¯ ë””ìŠ¤í”Œë ˆì´ ë°”ìš´ë”©ë°•ìŠ¤ë¥¼ ë‘ê»ê²Œ í‘œì‹œ (YOLOê°€ ê°ì§€í•œ ì „ì²´ ë””ìŠ¤í”Œë ˆì´ ì˜ì—­)
                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 165, 255), 3)  # ì£¼í™©ìƒ‰ìœ¼ë¡œ ë” ë‘ê»ê²Œ
                    
                    # ğŸ¯ OCRì´ ì‹¤ì œë¡œ ì¸ì‹í•œ ìˆ«ì ì˜ì—­ í‘œì‹œ (digit_bbox)
                    if digit_bbox and len(digit_bbox) == 4:
                        dx1, dy1, dx2, dy2 = digit_bbox
                        
                        # ğŸ”¥ ìˆ«ì ì˜ì—­ í‘œì‹œ (ë‹¨ìˆœí™”)
                        cv2.rectangle(image, (dx1, dy1), (dx2, dy2), (0, 0, 255), 2)  # ë¹¨ê°„ ë°•ìŠ¤
                    
                    # ë””ìŠ¤í”Œë ˆì´ ë¼ë²¨ (ê°„ë‹¨í•˜ê²Œ)
                    if floor_text and floor_text != "?":
                        label = f"DISPLAY: {floor_text}"
                    elif floor_number is not None:
                        label = f"DISPLAY: F{floor_number}"
                    else:
                        label = f"DISPLAY: {confidence:.2f}"
                elif class_name == 'direction_light':
                    # ğŸš¦ ë°©í–¥ë“± ì •ë³´ í‘œì‹œ (ë¯¸ë¦¬ ê³„ì‚°ëœ ì •ë³´ ì‚¬ìš©)
                    light_position = obj.get('light_position', 'unknown')
                    light_color = obj.get('light_color', 'UNKNOWN')
                    light_brightness = obj.get('light_brightness', 0.0)
                    
                    # ìœ„ì¹˜ì— ë”°ë¥¸ ë¼ë²¨ê³¼ ìƒ‰ìƒ ì„¤ì •
                    if light_position == 'upper':
                        position_text = "UP"
                        position_color = (0, 255, 0)  # ë…¹ìƒ‰
                    elif light_position == 'lower':
                        position_text = "DOWN"
                        position_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰
                    elif light_position == 'middle':
                        position_text = "MID"
                        position_color = (255, 255, 0)  # ë…¸ë€ìƒ‰
                    else:
                        position_text = "UNKNOWN"
                        position_color = (128, 128, 128)  # íšŒìƒ‰
                    
                    # ìƒ‰ìƒì— ë”°ë¥¸ í‘œì‹œê¸°
                    if light_color == 'GREEN':
                        color_indicator = "GREEN"
                    elif light_color == 'RED':
                        color_indicator = "RED"
                    else:
                        color_indicator = "OFF"
                    
                    # ìµœì¢… ë¼ë²¨ ìƒì„± (ë‹¨ìˆœí™”)
                    label = f"{position_text}"  # "UP" ë˜ëŠ” "DOWN"ë§Œ í‘œì‹œ
                    
                    # ë°©í–¥ë“± ì˜¤ë²„ë ˆì´ ì œê±°ë¨ (ê¹”ë”í•œ í‘œì‹œë¥¼ ìœ„í•´)
                    
                    # ìœ„ì¹˜ì— ë”°ë¥¸ ìƒ‰ìƒ ì„¤ì •
                    color = position_color
                else:
                    label = f"{class_name}: {confidence:.2f}"
                
                # ì¥ì• ë¬¼ì¸ ê²½ìš° íŠ¹ë³„í•œ ë¼ë²¨ ìƒì„±
                if is_obstacle:
                    obstacle_type = obj.get('obstacle_type', 'unknown')
                    distance_m = obj.get('distance_m', 0.0)
                    world_x = obj.get('world_x', 0.0)
                    world_y = obj.get('world_y', 0.0)
                    
                    # ì¥ì• ë¬¼ íƒ€ì…ê³¼ ê±°ë¦¬ í‘œì‹œ
                    if obstacle_type == 'dynamic':
                        label = f"DYNAMIC OBSTACLE: {distance_m:.1f}m"
                    else:
                        label = f"STATIC OBSTACLE: {distance_m:.1f}m"
                    
                    # ë¼ë²¨ ë°°ê²½ (ê°€ë…ì„± í–¥ìƒ)
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    cv2.rectangle(image, (x1, y1-25), (x1+label_size[0], y1), color, -1)
                    cv2.putText(image, label, (x1, y1-5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                    
                    # ì›”ë“œ ì¢Œí‘œ í‘œì‹œ (ê°ì²´ ì•„ë˜ìª½)
                    coord_text = f"({world_x:.2f}m, {world_y:.2f}m)"
                    coord_size = cv2.getTextSize(coord_text, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)[0]
                    cv2.rectangle(image, (x1, y2), (x1+coord_size[0], y2+20), (0, 0, 0), -1)
                    cv2.putText(image, coord_text, (x1, y2+15), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
                    
                    # ì¥ì• ë¬¼ ì•„ì´ì½˜ í‘œì‹œ ì œê±° (ì´ëª¨ì§€ë¡œ ì¸í•œ ??? ë¬¸ì œ í•´ê²°)
                else:
                    # ê¸°ì¡´ ê°ì²´ ë¼ë²¨
                    cv2.putText(image, label, (x1, y1-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
                
                # ë²„íŠ¼ì˜ ì¤‘ì‹¬ì  ì¢Œí‘œ í‘œì‹œ
                if class_name == 'button':
                    # í”½ì…€ ì¢Œí‘œ í‘œì‹œ
                    coord_text = f"({center[0]},{center[1]})"
                    cv2.putText(image, coord_text, (center[0]-25, center[1]+15), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
                    
                    # ë²„íŠ¼ ID í‘œì‹œ (ì´ë¯¸ ìˆëŠ” label ì•„ë˜ì— ì¶”ê°€ ì •ë³´)
                    button_id = obj.get('button_id', 'unknown')
                    recognition_method = obj.get('recognition_method', 'unknown')
                    
                    # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€ ëª¨ë“œì—ì„œëŠ” CNN ê´€ë ¨ ì •ë³´ë§Œ í‘œì‹œ
                    if self.get_active_mode_id() == 4:  # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€ ëª¨ë“œ
                        if recognition_method == 'cnn_primary':
                            # CNN ì„±ê³µ ì‹œ ì‹ ë¢°ë„ í‘œì‹œ
                            cnn_confidence = obj.get('confidence', 0.0)
                            id_text = f"CNN:{cnn_confidence:.2f}"
                            cv2.putText(image, id_text, (center[0]-25, center[1]+30), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1)  # ì´ˆë¡ìƒ‰
                        elif recognition_method == 'cnn_failed':
                            # CNN ì‹¤íŒ¨ ì‹œ í‘œì‹œ
                            id_text = "CNN:FAIL"
                            cv2.putText(image, id_text, (center[0]-25, center[1]+30), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 255), 1)  # ë¹¨ê°„ìƒ‰
                        elif recognition_method == 'cnn_unavailable':
                            # CNN ì‚¬ìš© ë¶ˆê°€ ì‹œ í‘œì‹œ
                            id_text = "CNN:UNAVAIL"
                            cv2.putText(image, id_text, (center[0]-30, center[1]+30), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (128, 128, 128), 1)  # íšŒìƒ‰
                    else:
                        # ì—˜ë¦¬ë² ì´í„° ì™¸ë¶€ ëª¨ë“œì—ì„œëŠ” ê¸°ì¡´ ë°©ì‹ ìœ ì§€
                        if button_id != 'unknown':
                            id_text = f"ID:{button_id}"
                            cv2.putText(image, id_text, (center[0]-20, center[1]+30), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 255), 1)
                
                # ëª¨ë¸ ì´ë¦„ í‘œì‹œ ì œê±°ë¨ (ì˜¤ë²„ë ˆì´ ì •ë¦¬)
                
                # ê±°ë¦¬ ì •ë³´ í‘œì‹œ ì œê±°ë¨ (ì˜¤ë²„ë ˆì´ ì •ë¦¬)
                
                # ë²„íŠ¼ ëˆŒë¦¼ ìƒíƒœ í‘œì‹œ (pressed/unpressed + ì‹ ë¢°ë„)
                if class_name == 'button':
                    pressed_confidence = obj.get('pressed_confidence', 0.0)
                    pressed_method = obj.get('pressed_method', 'none')
                    
                    if pressed_method not in ['no_cnn', 'no_model', 'none']:
                        # pressed_probê³¼ unpressed_prob ê°’ ê°€ì ¸ì˜¤ê¸°
                        pressed_prob = obj.get('pressed_prob', 0.0)
                        unpressed_prob = obj.get('unpressed_prob', 0.0)
                        
                        # pressed/unpressed ìƒíƒœ í‘œì‹œ (ë‘ ì‹ ë¢°ë„ ëª¨ë‘ í‘œì‹œ)
                        if is_pressed:
                            pressed_text = f"PRESSED (P:{pressed_prob:.2f} U:{unpressed_prob:.2f})"
                            pressed_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰
                        else:
                            pressed_text = f"UNPRESSED (P:{pressed_prob:.2f} U:{unpressed_prob:.2f})"
                            pressed_color = (0, 255, 0)  # ì´ˆë¡ìƒ‰
                        
                        cv2.putText(image, pressed_text, (center[0]-60, center[1]+45), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.3, pressed_color, 1)
        
        # ğŸš— ì¼ë°˜ì£¼í–‰ ëª¨ë“œì—ì„œ ì¥ì• ë¬¼ ì „ìš© ì‹œê°í™”
        if mode_id == 5:  # ì¼ë°˜ ì£¼í–‰ ëª¨ë“œ
            # í™”ë©´ ì¤‘ì‹¬ì— ìˆ˜ì§ì„  í•­ìƒ í‘œì‹œ (íŒŒë€ìƒ‰)
            cv2.line(image, (screen_center[0], 0), (screen_center[0], image_height), (255, 0, 0), 2)
            
            # ì¥ì• ë¬¼ì— ëŒ€í•´ì„œë§Œ ì²˜ë¦¬
            obstacle_objects = [obj for obj in objects if obj.get('is_obstacle', False)]
            
            for obj in obstacle_objects:
                center = obj['center']
                object_center_x = int(center[0])
                world_x = obj.get('world_x', 0.0)
                
                # ì¥ì• ë¬¼ ì¤‘ì‹¬ì ì— ìˆ˜ì§ì„  ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
                cv2.line(image, (object_center_x, 0), (object_center_x, image_height), (0, 0, 255), 2)
                
                # X ì°¨ì´ ê³„ì‚° (ì›”ë“œ ì¢Œí‘œ ê¸°ì¤€)
                x_diff = abs(world_x)  # í™”ë©´ ì¤‘ì‹¬ì—ì„œì˜ X ê±°ë¦¬ (ë¯¸í„°)
                
                # ì–‘ë°©í–¥ í™”ì‚´í‘œ ê·¸ë¦¬ê¸° (í™”ë©´ í•˜ë‹¨ì—)
                arrow_y = image_height - 50
                arrow_start = screen_center[0]
                arrow_end = object_center_x
                
                # í™”ì‚´í‘œ ì„ 
                cv2.line(image, (arrow_start, arrow_y), (arrow_end, arrow_y), (0, 255, 0), 3)
                
                # í™”ì‚´í‘œ ë¨¸ë¦¬ ê·¸ë¦¬ê¸°
                arrow_size = 10
                if arrow_end > arrow_start:  # ì˜¤ë¥¸ìª½ í™”ì‚´í‘œ
                    cv2.arrowedLine(image, (arrow_end - 20, arrow_y), (arrow_end, arrow_y), (0, 255, 0), 3, tipLength=0.3)
                    cv2.arrowedLine(image, (arrow_start + 20, arrow_y), (arrow_start, arrow_y), (0, 255, 0), 3, tipLength=0.3)
                else:  # ì™¼ìª½ í™”ì‚´í‘œ
                    cv2.arrowedLine(image, (arrow_end + 20, arrow_y), (arrow_end, arrow_y), (0, 255, 0), 3, tipLength=0.3)
                    cv2.arrowedLine(image, (arrow_start - 20, arrow_y), (arrow_start, arrow_y), (0, 255, 0), 3, tipLength=0.3)
                
                # X ì°¨ì´ í…ìŠ¤íŠ¸ í‘œì‹œ (í™”ì‚´í‘œ ìœ„ì—)
                x_diff_text = f"{x_diff:.2f}m"
                text_x = (arrow_start + arrow_end) // 2
                text_size = cv2.getTextSize(x_diff_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
                
                # ë°°ê²½ ì‚¬ê°í˜•
                cv2.rectangle(image, (text_x - text_size[0]//2 - 5, arrow_y - 35), 
                             (text_x + text_size[0]//2 + 5, arrow_y - 10), (0, 0, 0), -1)
                
                # í…ìŠ¤íŠ¸
                cv2.putText(image, x_diff_text, (text_x - text_size[0]//2, arrow_y - 15), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # ğŸ¯ ê¸°ì–µëœ ë°©í–¥ë“± ìœ„ì¹˜ì— ë¼ë²¨ í‘œì‹œ
        if (self.remembered_direction_positions['upper'] and 
            self.remembered_direction_positions['lower']):
            
            # ìœ„ìª½ ë°©í–¥ë“± ìœ„ì¹˜ì— "UP" ë¼ë²¨ í‘œì‹œ
            upper_pos = self.remembered_direction_positions['upper']['center']
            cv2.circle(image, (upper_pos[0], upper_pos[1]), 30, (0, 255, 0), 2)
            cv2.putText(image, "UP", (upper_pos[0] - 15, upper_pos[1] + 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # ì•„ë˜ìª½ ë°©í–¥ë“± ìœ„ì¹˜ì— "DOWN" ë¼ë²¨ í‘œì‹œ
            lower_pos = self.remembered_direction_positions['lower']['center']
            cv2.circle(image, (lower_pos[0], lower_pos[1]), 30, (0, 0, 255), 2)
            cv2.putText(image, "DOWN", (lower_pos[0] - 25, lower_pos[1] + 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        return image

    def _add_info_text(self, image: np.ndarray, objects: List[dict], custom_title: str = None):
        """ë‹¤ì¤‘ ëª¨ë¸ íƒì§€ ê²°ê³¼ ë° ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ì˜ìƒì— í‘œì‹œ"""
        import cv2
        
        # í˜„ì¬ ëª¨ë“œ ì •ë³´
        mode_name = self.get_active_mode_name()
        
        # ìƒë‹¨ì— ì œëª© (custom_titleì´ ìˆìœ¼ë©´ ì‚¬ìš©)
        if custom_title:
            cv2.putText(image, f"Roomie VS - {custom_title}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        else:
            cv2.putText(image, f"Roomie Vision System v3 - {mode_name}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # í˜„ì¬ ëª¨ë“œ ID ì¶”ì¶œ (custom_titleì—ì„œ ì¹´ë©”ë¼ íƒ€ì… ìœ ì¶”)
        current_mode_id = self.get_active_mode_id()
        
        # custom_titleì—ì„œ ì¹´ë©”ë¼ íƒ€ì… íŒë‹¨
        is_webcam = "Webcam" in (custom_title or "")
        is_depth = "Depth" in (custom_title or "")
        is_rear = "Rear" in (custom_title or "")
        
        # custom_titleì—ì„œ ëª¨ë“œ ì¶”ì¶œ
        if "Elevator Out" in (custom_title or ""):
            current_mode_id = 3
        elif "Elevator In" in (custom_title or ""):
            current_mode_id = 4
        elif "ArUco" in (custom_title or "") or "YOLO" in (custom_title or ""):
            current_mode_id = 5
        elif "Standby" in (custom_title or ""):
            current_mode_id = 6 if not is_rear else 0
        else:
            current_mode_id = self.get_active_mode_id()  # í´ë°±
        
        # ì‹¤ì œ ëª¨ë¸ ì ìš© ì—¬ë¶€ íŒë‹¨ (ì¹´ë©”ë¼ íƒ€ì… + ëª¨ë“œ ì¡°í•©)
        model_applied = False
        if is_webcam and current_mode_id in [3, 4]:  # ì—˜ë¦¬ë² ì´í„° ëª¨ë“œì˜ ì›¹ìº 
            model_applied = True
        elif is_depth and current_mode_id == 5:  # ì¼ë°˜ ëª¨ë“œì˜ ëìŠ¤
            model_applied = True
            
        # í˜„ì¬ ëª¨ë¸ ìƒíƒœ ë° ì„¤ì • í‘œì‹œ
        if model_applied:  # ì‹¤ì œë¡œ ëª¨ë¸ì´ ì ìš©ë˜ëŠ” ê²½ìš°
            model_info = self.model_detector.get_current_model_info()
            # ì•ˆì „í•œ ëª¨ë¸ ì´ë¦„ í‘œì‹œ (í•œê¸€ ë¬¸ì œ ë°©ì§€)
            raw_model_name = model_info['model_name']
            if raw_model_name == 'normal':
                current_model = "Normal"
            elif raw_model_name == 'elevator':
                current_model = "Elevator" 
            elif raw_model_name is None:
                current_model = "None"
            else:
                current_model = str(raw_model_name)
        else:  # ëª¨ë¸ì´ ì ìš©ë˜ì§€ ì•ŠëŠ” ê²½ìš° (ì˜ìƒë§Œ í‘œì‹œ)
            current_model = "Off"
            
        flip_status = "ON" if self.flip_horizontal else "OFF"
        
        # ì¹´ë©”ë¼ ì´ë¦„ì€ custom_titleì—ì„œ ì¶”ì¶œí•˜ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
        camera_name_display = custom_title if custom_title else self.current_camera_name
        
        cv2.putText(image, f"Model:{current_model} | Camera:{camera_name_display} | Flip:{flip_status} | Conf:{self.confidence_threshold}", 
                   (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        
        # íƒì§€ëœ ê°ì²´ ìˆ˜
        cv2.putText(image, f"Objects Detected: {len(objects)}", (10, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
        
        # ì¥ì• ë¬¼ ì •ë³´ ì¶”ê°€ (ìœ„ì¹˜ ì¡°ì •í•˜ì—¬ ê²¹ì¹¨ ë°©ì§€)
        obstacle_objects = [obj for obj in objects if obj.get('is_obstacle', False)]
        if obstacle_objects:
            dynamic_count = len([obj for obj in obstacle_objects if obj.get('obstacle_type') == 'dynamic'])
            static_count = len([obj for obj in obstacle_objects if obj.get('obstacle_type') == 'static'])
            
            # ì¥ì• ë¬¼ ìš”ì•½ ì •ë³´ (ë” ì•„ë˜ë¡œ ì´ë™)
            cv2.putText(image, f"OBSTACLES: Dynamic={dynamic_count} | Static={static_count}", 
                       (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)
            
            # ê°€ì¥ ê°€ê¹Œìš´ ì¥ì• ë¬¼ ì •ë³´
            closest_obstacle = min(obstacle_objects, key=lambda x: x.get('distance_m', float('inf')))
            if closest_obstacle:
                obstacle_type = closest_obstacle.get('obstacle_type', 'unknown')
                distance = closest_obstacle.get('distance_m', 0.0)
                world_x = closest_obstacle.get('world_x', 0.0)
                world_y = closest_obstacle.get('world_y', 0.0)
                
                cv2.putText(image, f"CLOSEST: {obstacle_type.upper()} at {distance:.1f}m ({world_x:.2f}, {world_y:.2f})", 
                           (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)
        else:
            cv2.putText(image, "NO OBSTACLES DETECTED", 
                       (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        
        # ğŸ”¥ ë°©í–¥ë“± ê¸°ì–µëœ ìœ„ì¹˜ ì •ë³´ í‘œì‹œ
        if (self.remembered_direction_positions['upper'] and self.remembered_direction_positions['lower']):
            upper_pos = self.remembered_direction_positions['upper']['center']
            lower_pos = self.remembered_direction_positions['lower']['center']
            cv2.putText(image, f"Remembered Positions - UP: ({upper_pos[0]},{upper_pos[1]}) | DOWN: ({lower_pos[0]},{lower_pos[1]}) - TRACKING MODE", 
                       (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        else:
            cv2.putText(image, "No Direction Light Positions Remembered - Waiting for 2 Lights...", 
                       (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
        
                # ğŸ”¥ ê¸°ì–µëœ ìœ„ì¹˜ì—ì„œ í˜„ì¬ ë°ê¸° ì •ë³´ í‘œì‹œ
        if (self.remembered_direction_positions['upper'] and 
            self.remembered_direction_positions['lower'] and 
            image is not None):
            
            # ê¸°ì–µëœ ìœ„ì¹˜ì—ì„œ ì‹¤ì‹œê°„ ë°ê¸° ì¸¡ì •
            upper_brightness = self._get_brightness_at_remembered_position(image, 'upper')
            lower_brightness = self._get_brightness_at_remembered_position(image, 'lower')
            
            cv2.putText(image, f"Current Brightness: UP={upper_brightness:.1f} | DOWN={lower_brightness:.1f}", 
                       (10, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
            
            # ğŸ”¥ ê¹œë¹¡ì„ ìƒíƒœ í‘œì‹œ
            if self.blink_detection_enabled and len(self.brightness_history['upper']) >= 5:
                upper_blink = self._detect_blink_at_position('upper')
                lower_blink = self._detect_blink_at_position('lower')
                
                blink_status = ""
                if upper_blink and lower_blink:
                    blink_status = "BOTH BLINKING"
                    color = (0, 255, 255)  # ë…¸ë€ìƒ‰
                elif upper_blink:
                    blink_status = "UP BLINKING"
                    color = (0, 255, 0)  # ì´ˆë¡ìƒ‰
                elif lower_blink:
                    blink_status = "DOWN BLINKING" 
                    color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰
                else:
                    blink_status = "NO BLINK"
                    color = (128, 128, 128)  # íšŒìƒ‰
                    
                cv2.putText(image, f"Blink Status: {blink_status}", 
                           (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            else:
                cv2.putText(image, "Blink Detection: Collecting History...", 
                           (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
        
        # ì—˜ë¦¬ë² ì´í„° ë°©í–¥ ì •ë³´ í‘œì‹œ (ë‚´ë¶€ ëª¨ë“œì—ì„œëŠ” ì œì™¸)
        if self.current_front_mode_id != 4:  # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ
            direction_text = "UP" if self.last_elevator_direction == 0 else "DOWN"
            cv2.putText(image, f"Elevator Direction: {direction_text}", (10, 170), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
        
        # íƒì§€ëœ ê°ì²´ ë¶„ë¥˜ í‘œì‹œ
        if objects:
            object_counts = {}
            model_counts = {}
            
            for obj in objects:
                class_name = obj.get('class_name', 'unknown') 
                model_name = obj.get('model_name', 'unknown')
                
                object_counts[class_name] = object_counts.get(class_name, 0) + 1
                model_counts[model_name] = model_counts.get(model_name, 0) + 1
            
            if object_counts:
                counts_text = ", ".join([f"{k}:{v}" for k, v in object_counts.items()])
                cv2.putText(image, f"Objects: {counts_text}", (10, 90), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (128, 255, 128), 1)
        
        # ëˆŒë¦° ë²„íŠ¼ í‘œì‹œ
        pressed_buttons = []
        for obj in objects:
            if obj.get('is_pressed', False) and obj.get('class_name') == 'button':
                pressed_buttons.append("BUTTON")
        
        if pressed_buttons:
            pressed_text = f"Pressed: {len(pressed_buttons)} button(s)"
            cv2.putText(image, pressed_text, (10, 110), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)
        
        # ArUco ë§ˆì»¤ ì‹œê°í™” ì¶”ê°€ (ëª¨ë“œ 5ì—ì„œë§Œ)
        if self.current_front_mode_id == 5:
            self._add_aruco_visualization(image)
        
        # í˜„ì¬ ìœ„ì¹˜ ì •ë³´ í‘œì‹œ (ëª¨ë“œ 5ì—ì„œë§Œ)
        if self.current_front_mode_id == 5:
            location_names = {
                0: "LOB_WAITING", 1: "LOB_CALL", 2: "RES_PICKUP", 3: "RES_CALL",
                4: "SUP_PICKUP", 5: "ELE_1", 6: "ELE_2", 101: "ROOM_101",
                102: "ROOM_102", 201: "ROOM_201", 202: "ROOM_202"
            }
            current_location_name = location_names.get(self.last_detected_location_id, f"ID_{self.last_detected_location_id}")
            cv2.putText(image, f"Current Location: {current_location_name}", (10, 130), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 128, 0), 1)
        
        # ğŸ¢ í˜„ì¬ ì—˜ë¦¬ë² ì´í„° ì¸µìˆ˜ í‘œì‹œ (ì—˜ë¦¬ë² ì´í„° ëª¨ë“œì—ì„œë§Œ) - ìš°í•˜ë‹¨ í‘œì‹œ
        if current_mode_id in [3, 4]:  # ì—˜ë¦¬ë² ì´í„° ì™¸ë¶€/ë‚´ë¶€ ëª¨ë“œ
            current_floor = self.display_ocr.get_current_floor_display()
            
            # í™”ë©´ ì˜¤ë¥¸ìª½ í•˜ë‹¨ì— í¬ê²Œ í‘œì‹œ
            text_size = cv2.getTextSize(current_floor, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 2)[0]
            text_x = image.shape[1] - text_size[0] - 15  # ì˜¤ë¥¸ìª½ ì •ë ¬
            text_y = image.shape[0] - 90  # í•˜ë‹¨ì—ì„œ 90í”½ì…€ ìœ„ (ë°©í–¥ í‘œì‹œ ê³µê°„ í™•ë³´)
            
            # í° ë°°ê²½ ë°•ìŠ¤
            cv2.rectangle(image, (text_x-8, text_y-25), (text_x+text_size[0]+8, text_y+8), (0, 0, 0), -1)
            cv2.rectangle(image, (text_x-8, text_y-25), (text_x+text_size[0]+8, text_y+8), (0, 255, 255), 2)
            
            # í˜„ì¬ ì¸µìˆ˜ í…ìŠ¤íŠ¸ (í¬ê²Œ)
            cv2.putText(image, current_floor, (text_x, text_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 2)
            
            # ğŸš¦ ì—˜ë¦¬ë² ì´í„° ë°©í–¥ í‘œì‹œ (ì¸µìˆ˜ ì•„ë˜ì— í¬ê²Œ) - ë‚´ë¶€ ëª¨ë“œì—ì„œëŠ” ì œì™¸
            if self.current_front_mode_id != 4:  # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ
                direction_text = "UP" if self.last_elevator_direction == 0 else "DOWN"
                direction_color = (0, 255, 0) if self.last_elevator_direction == 0 else (0, 0, 255)  # UP: ì´ˆë¡, DOWN: ë¹¨ê°•
                
                # ğŸ”¥ ê¹œë¹¡ì„ ê°ì§€ í‘œì‹œ ì¶”ê°€
                if self.last_blink_detected:
                    direction_text += " âœ¦"  # ê¹œë¹¡ì„ ê°ì§€ ì‹œ ë³„í‘œ ì¶”ê°€
                    direction_color = (0, 255, 255)  # ë…¸ë€ìƒ‰ìœ¼ë¡œ ë³€ê²½
                
                # ë°©í–¥ í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
                dir_text_size = cv2.getTextSize(direction_text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)[0]
                dir_text_x = image.shape[1] - dir_text_size[0] - 15  # ì˜¤ë¥¸ìª½ ì •ë ¬
                dir_text_y = text_y + 45  # ì¸µìˆ˜ ì•„ë˜
                
                # ë°©í–¥ ë°°ê²½ ë°•ìŠ¤ (ê¹œë¹¡ì„ ê°ì§€ ì‹œ ë” ë‘ê»ê²Œ)
                box_thickness = 4 if self.last_blink_detected else 2
                cv2.rectangle(image, (dir_text_x-8, dir_text_y-20), (dir_text_x+dir_text_size[0]+8, dir_text_y+8), (0, 0, 0), -1)
                cv2.rectangle(image, (dir_text_x-8, dir_text_y-20), (dir_text_x+dir_text_size[0]+8, dir_text_y+8), direction_color, box_thickness)
                
                # ë°©í–¥ í…ìŠ¤íŠ¸
                cv2.putText(image, direction_text, (dir_text_x, dir_text_y), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1.0, direction_color, 2)
                
                # ë§ˆì§€ë§‰ ê°ì§€ ì‹œê°„ í‘œì‹œ (ì‘ê²Œ)
                if self.last_direction_detection_time:
                    time_diff = (self.get_clock().now() - self.last_direction_detection_time).nanoseconds / 1e9
                    time_text = f"({time_diff:.1f}ì´ˆ ì „)"
                    cv2.putText(image, time_text, (dir_text_x, dir_text_y + 20), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)
        
        # ì¢…ë£Œ ì•ˆë‚´
        cv2.putText(image, "ESC:Exit, B:Info, M:Status, F:Flip, C:Conf, A:ArUco, D:Reset, L:Remember (Blink Detection ON)", (10, image.shape[0]-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.3, (200, 200, 200), 1)

    def _on_gpu_memory_exceeded(self, used_memory: int, limit_memory: int, violation_count: int):
        """ğŸš¨ GPU ë©”ëª¨ë¦¬ ì œí•œ ì´ˆê³¼ ì‹œ í˜¸ì¶œë˜ëŠ” ì½œë°±"""
        self.get_logger().error(f"ğŸš¨ GPU ë©”ëª¨ë¦¬ í•œê³„ ì´ˆê³¼: {used_memory}MB > {limit_memory}MB (ìœ„ë°˜ #{violation_count})")
        
        # ğŸ¯ ë‹¨ê³„ë³„ ëŒ€ì‘ ë°©ë²•
        if violation_count == 1:
            # 1ì°¨: ê²½ê³ ë§Œ
            self.get_logger().warning("âš ï¸ 1ì°¨ ê²½ê³ : GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì—¬ì£¼ì„¸ìš”")
            
        elif violation_count == 2:
            # 2ì°¨: EasyOCR CPU ëª¨ë“œë¡œ ì „í™˜
            self.get_logger().warning("âš ï¸ 2ì°¨ ëŒ€ì‘: EasyOCRì„ CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤")
            try:
                self.display_ocr.switch_to_cpu_mode()
                self.get_logger().info("âœ… EasyOCR CPU ëª¨ë“œ ì „í™˜ ì™„ë£Œ")
            except Exception as e:
                self.get_logger().error(f"âŒ CPU ëª¨ë“œ ì „í™˜ ì‹¤íŒ¨: {e}")
                
        elif violation_count == 3:
            # 3ì°¨: OCR ê¸°ëŠ¥ ì™„ì „ ë¹„í™œì„±í™”
            self.get_logger().warning("âš ï¸ 3ì°¨ ëŒ€ì‘: OCR ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤")
            try:
                self.display_ocr.disable_ocr()
                self.get_logger().info("âœ… OCR ê¸°ëŠ¥ ë¹„í™œì„±í™” ì™„ë£Œ")
            except Exception as e:
                self.get_logger().error(f"âŒ OCR ë¹„í™œì„±í™” ì‹¤íŒ¨: {e}")
                
        elif violation_count >= 5:
            # ìµœì¢…: vs_node ê°•ì œ ì¢…ë£Œ
            self.get_logger().critical("ğŸš¨ ìµœì¢… ëŒ€ì‘: GPU ë©”ëª¨ë¦¬ í•œê³„ ì´ˆê³¼ë¡œ vs_nodeë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤!")
            self.get_logger().critical(f"ğŸš¨ ì¢…ë£Œ ì‚¬ìœ : {violation_count}íšŒ ì—°ì† GPU ë©”ëª¨ë¦¬ ì œí•œ ì´ˆê³¼")
            
            try:
                # GPU ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
                if hasattr(self, 'gpu_monitor') and self.gpu_monitor:
                    self.gpu_monitor.stop_monitoring()
                
                # ì¹´ë©”ë¼ ì •ë¦¬
                if hasattr(self, 'camera_manager'):
                    self.camera_manager.cleanup_all_cameras()
                
                # ROS2 ë…¸ë“œ ì¢…ë£Œ
                self.destroy_node()
                
                # í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ
                import os
                import signal
                os.kill(os.getpid(), signal.SIGTERM)
                
            except Exception as e:
                self.get_logger().error(f"âŒ ì¢…ë£Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                import sys
                sys.exit(1)
    
    def _on_gpu_error(self, error: Exception):
        """ğŸš¨ GPU ì˜¤ë¥˜ ì‹œ í˜¸ì¶œë˜ëŠ” ì½œë°±"""
        self.get_logger().error(f"ğŸš¨ GPU ì˜¤ë¥˜ ë°œìƒ: {error}")
        
        # GPU ì˜¤ë¥˜ ì‹œ ìë™ìœ¼ë¡œ CPU ëª¨ë“œë¡œ ì „í™˜
        try:
            self.get_logger().warning("âš ï¸ GPU ì˜¤ë¥˜ë¡œ ì¸í•´ EasyOCRì„ CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤")
            self.display_ocr.switch_to_cpu_mode()
            self.get_logger().info("âœ… GPU ì˜¤ë¥˜ ëŒ€ì‘: CPU ëª¨ë“œ ì „í™˜ ì™„ë£Œ")
        except Exception as e:
            self.get_logger().error(f"âŒ GPU ì˜¤ë¥˜ ëŒ€ì‘ ì‹¤íŒ¨: {e}")

    # ğŸ‘¤ ì¶”ì  ê´€ë ¨ ì•¡ì…˜ ë° ì„œë¹„ìŠ¤ ì½œë°± ë©”ì†Œë“œë“¤
    def enroll_action_callback(self, goal_handle):
        """ë“±ë¡ ì•¡ì…˜ ì„œë²„ ì½œë°± - PersonTrackerë¥¼ í†µí•´ ì²˜ë¦¬"""
        self.get_logger().info(f"ğŸ‘¤ ë“±ë¡ ì•¡ì…˜ ìš”ì²­: duration={goal_handle.request.duration_sec}ì´ˆ")
        
        try:
            # PersonTrackerê°€ ì—†ê±°ë‚˜ ë“±ë¡ëª¨ë“œê°€ ì•„ë‹ˆë©´ ì‹¤íŒ¨
            if not hasattr(self, 'person_tracker') or not self.person_tracker:
                goal_handle.abort()
                result = Enroll.Result()
                result.success = False
                self.get_logger().error("ğŸ‘¤ PersonTrackerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return result
            
            if self.person_tracker.current_mode != 1:
                goal_handle.abort()
                result = Enroll.Result()
                result.success = False
                self.get_logger().error("ğŸ‘¤ ë“±ë¡ëª¨ë“œê°€ ì•„ë‹™ë‹ˆë‹¤ (í˜„ì¬ ëª¨ë“œ: {})".format(self.person_tracker.current_mode))
                return result
            
            # ë“±ë¡ ì‹œì‘
            register_result = self.person_tracker.register_target(goal_handle.request.duration_sec)
            if not register_result["success"]:
                goal_handle.abort()
                result = Enroll.Result()
                result.success = False
                self.get_logger().error(f"ğŸ‘¤ ë“±ë¡ ì‹œì‘ ì‹¤íŒ¨: {register_result['message']}")
                return result
            
            goal_handle.succeed()
            
            # ì£¼ê¸°ì ìœ¼ë¡œ í”¼ë“œë°± ì „ì†¡
            duration = goal_handle.request.duration_sec
            start_time = time.time()
            
            while time.time() - start_time < duration:
                if goal_handle.is_cancel_requested:
                    goal_handle.canceled()
                    result = Enroll.Result()
                    result.success = False
                    self.get_logger().info("ğŸ‘¤ ë“±ë¡ ì•¡ì…˜ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
                    return result
                
                # ì§„í–‰ë¥  í”¼ë“œë°±
                progress = self.person_tracker.get_registration_progress()
                feedback = Enroll.Feedback()
                feedback.progress = progress
                goal_handle.publish_feedback(feedback)
                
                time.sleep(0.1)  # 10Hz í”¼ë“œë°±
            
            # ë“±ë¡ ì™„ë£Œ
            result = Enroll.Result()
            result.success = self.person_tracker.target_registered
            
            if result.success:
                self.get_logger().info(f"ğŸ‘¤ ë“±ë¡ ì™„ë£Œ: target_id={self.person_tracker.target_id}")
            else:
                self.get_logger().warning("ğŸ‘¤ ë“±ë¡ ì‹¤íŒ¨: ì í•©í•œ í›„ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
            
            return result
            
        except Exception as e:
            self.get_logger().error(f"ğŸ‘¤ ë“±ë¡ ì•¡ì…˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            goal_handle.abort()
            result = Enroll.Result()
            result.success = False
            return result
    
    def stop_tracking_callback(self, request, response):
        """ì¶”ì  ì¤‘ì§€ ì„œë¹„ìŠ¤ ì½œë°±"""
        self.get_logger().info("ğŸ‘¤ ì¶”ì  ì¤‘ì§€ ìš”ì²­")
        
        try:
            if hasattr(self, 'person_tracker') and self.person_tracker:
                stop_result = self.person_tracker.stop_tracking()
                response.success = stop_result["success"]
                response.message = stop_result["message"]
                self.get_logger().info(f"ğŸ‘¤ ì¶”ì  ì¤‘ì§€ ì™„ë£Œ: {response.message}")
            else:
                response.success = False
                response.message = "PersonTrackerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
                self.get_logger().error("ğŸ‘¤ PersonTrackerê°€ ì—†ì–´ ì¶”ì  ì¤‘ì§€ ì‹¤íŒ¨")
        
        except Exception as e:
            response.success = False
            response.message = f"ì¶”ì  ì¤‘ì§€ ì¤‘ ì˜¤ë¥˜: {e}"
            self.get_logger().error(f"ğŸ‘¤ ì¶”ì  ì¤‘ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return response

    def __del__(self):
        """ì†Œë©¸ì - ë©€í‹° ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ì •ë¦¬"""
        # GPU ëª¨ë‹ˆí„°ë§ ì •ë¦¬
        if hasattr(self, 'gpu_monitor') and self.gpu_monitor:
            self.gpu_monitor.stop_monitoring()
        
        # ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ì •ë¦¬
        if hasattr(self, 'camera_manager'):
            self.camera_manager.cleanup_all_cameras()

    def _update_remembered_positions(self, direction_objects: List[dict]) -> bool:
        """ë°©í–¥ë“± 2ê°œê°€ ê°ì§€ë˜ë©´ ìœ„ì¹˜ë¥¼ ê¸°ì–µí•´ë‘  (ê°„í—ì  ê°ì§€ ëŒ€ë¹„)"""
        try:
            if len(direction_objects) != 2:
                return False
            
            # Y ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìœ„ìª½ì´ ë¨¼ì €)
            sorted_lights = sorted(direction_objects, key=lambda obj: obj['center'][1])
            upper_light = sorted_lights[0]  # Y ì¢Œí‘œê°€ ì‘ì€ ê²ƒ (ìœ„ìª½)
            lower_light = sorted_lights[1]  # Y ì¢Œí‘œê°€ í° ê²ƒ (ì•„ë˜ìª½)
            
            # ìœ„ì¹˜ ì •ë³´ ì €ì¥
            self.remembered_direction_positions['upper'] = {
                'center': upper_light['center'],
                'bbox': upper_light['bbox']
            }
            self.remembered_direction_positions['lower'] = {
                'center': lower_light['center'],
                'bbox': lower_light['bbox']
            }
            
            self.last_position_update = self.get_clock().now()
            
            self.get_logger().info(f"ğŸ¯ ë°©í–¥ë“± ìœ„ì¹˜ ê¸°ì–µ: ìœ„ìª½=({upper_light['center'][0]},{upper_light['center'][1]}), ì•„ë˜ìª½=({lower_light['center'][0]},{lower_light['center'][1]})")
            
            return True
            
        except Exception as e:
            self.get_logger().error(f"ë°©í–¥ë“± ìœ„ì¹˜ ê¸°ì–µ ì—ëŸ¬: {e}")
            return False

    def _get_brightness_at_remembered_position(self, image: np.ndarray, position_type: str) -> float:
        """ê¸°ì–µëœ ìœ„ì¹˜ì—ì„œ ë°ê¸° ì¸¡ì •"""
        try:
            if not self.remembered_direction_positions[position_type] or image is None:
                return 0.0
                
            pos_info = self.remembered_direction_positions[position_type]
            
            # ê°€ìƒì˜ light_obj ìƒì„±í•´ì„œ ê¸°ì¡´ í•¨ìˆ˜ í™œìš©
            virtual_light_obj = {
                'center': pos_info['center'],
                'bbox': pos_info['bbox']
            }
            
            # ê¸°ì¡´ í•¨ìˆ˜ í™œìš©
            return self._get_light_brightness_advanced(image, virtual_light_obj)
            
        except Exception as e:
            self.get_logger().error(f"ê¸°ì–µëœ ìœ„ì¹˜ ë°ê¸° ì¸¡ì • ì—ëŸ¬: {e}")
            return 0.0

    def _update_brightness_history(self, image: np.ndarray):
        """ê¸°ì–µëœ ìœ„ì¹˜ì—ì„œ ë°ê¸° íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸"""
        try:
            if not (self.remembered_direction_positions['upper'] and 
                   self.remembered_direction_positions['lower'] and 
                   image is not None):
                return
                
            # ê° ìœ„ì¹˜ì—ì„œ í˜„ì¬ ë°ê¸° ì¸¡ì •
            upper_brightness = self._get_brightness_at_remembered_position(image, 'upper')
            lower_brightness = self._get_brightness_at_remembered_position(image, 'lower')
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.brightness_history['upper'].append(upper_brightness)
            self.brightness_history['lower'].append(lower_brightness)
            
            # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
            if len(self.brightness_history['upper']) > self.history_size:
                self.brightness_history['upper'].pop(0)
            if len(self.brightness_history['lower']) > self.history_size:
                self.brightness_history['lower'].pop(0)
                
        except Exception as e:
            self.get_logger().error(f"ë°ê¸° íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ ì—ëŸ¬: {e}")

    def _detect_blink_at_position(self, position_type: str) -> bool:
        """íŠ¹ì • ìœ„ì¹˜ì—ì„œ ê¹œë¹¡ì„ ê°ì§€"""
        try:
            history = self.brightness_history[position_type]
            
            # ìµœì†Œ 5í”„ë ˆì„ì˜ íˆìŠ¤í† ë¦¬ê°€ í•„ìš”
            if len(history) < 5:
                return False
                
            # ìµœê·¼ 3í”„ë ˆì„ê³¼ ê·¸ ì´ì „ í”„ë ˆì„ë“¤ ë¹„êµ
            recent_frames = history[-3:]  # ìµœê·¼ 3í”„ë ˆì„
            previous_frames = history[-8:-3]  # ê·¸ ì´ì „ 5í”„ë ˆì„
            
            if len(previous_frames) == 0:
                return False
                
            # í‰ê·  ë°ê¸° ê³„ì‚°
            recent_avg = sum(recent_frames) / len(recent_frames)
            previous_avg = sum(previous_frames) / len(previous_frames)
            
            # ë°ê¸° ë³€í™”ëŸ‰ ê³„ì‚°
            brightness_change = recent_avg - previous_avg
            
            # ê¹œë¹¡ì„ ê°ì§€: ì„ê³„ê°’ ì´ìƒ ë°ì•„ì§
            is_blink = brightness_change > self.brightness_change_threshold_for_blink
            
            if is_blink:
                self.get_logger().info(f"ğŸ”¥ {position_type.upper()} ë°©í–¥ë“± ê¹œë¹¡ì„ ê°ì§€! ë³€í™”ëŸ‰: {brightness_change:.1f}")
                # ğŸ¯ ê¹œë¹¡ì„ ê°ì§€ í›„ íˆìŠ¤í† ë¦¬ ì¼ë¶€ ì´ˆê¸°í™” (ì—°ì† ê¹œë¹¡ì„ ê°ì§€ë¥¼ ìœ„í•´)
                self._reset_brightness_history_for_continuous_detection(position_type)
                
            return is_blink
            
        except Exception as e:
            self.get_logger().error(f"{position_type} ê¹œë¹¡ì„ ê°ì§€ ì—ëŸ¬: {e}")
            return False

    def _reset_brightness_history_for_continuous_detection(self, position_type: str):
        """ê¹œë¹¡ì„ ê°ì§€ í›„ íˆìŠ¤í† ë¦¬ ì¼ë¶€ ì´ˆê¸°í™” (ì—°ì† ê°ì§€ë¥¼ ìœ„í•´)"""
        try:
            if position_type in self.brightness_history:
                # í˜„ì¬ íˆìŠ¤í† ë¦¬ì˜ ë§ˆì§€ë§‰ 3ê°œ ê°’ë§Œ ìœ ì§€ (ë‚˜ë¨¸ì§€ ì œê±°)
                if len(self.brightness_history[position_type]) > 3:
                    self.brightness_history[position_type] = self.brightness_history[position_type][-3:]
                    self.get_logger().info(f"ğŸ”„ {position_type.upper()} ë°©í–¥ë“± íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” (ì—°ì† ê¹œë¹¡ì„ ê°ì§€ìš©)")
        except Exception as e:
            self.get_logger().error(f"íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ì—ëŸ¬: {e}")

    def _classify_light_by_learned_position(self, light_obj: dict) -> str:
        """í•™ìŠµëœ ìœ„ì¹˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°©í–¥ë“±ì„ ìœ„/ì•„ë˜ë¡œ ë¶„ë¥˜"""
        try:
            if (not self.direction_light_positions['upper'] or 
                not self.direction_light_positions['lower']):
                return 'unknown'
            
            light_y = light_obj['center'][1]
            upper_y = self.direction_light_positions['upper']['center'][1]
            lower_y = self.direction_light_positions['lower']['center'][1]
            
            # í•™ìŠµëœ ìœ„ì¹˜ì™€ì˜ ê±°ë¦¬ ê³„ì‚°
            dist_to_upper = abs(light_y - upper_y)
            dist_to_lower = abs(light_y - lower_y)
            
            # ë” ê°€ê¹Œìš´ ìœ„ì¹˜ë¡œ ë¶„ë¥˜ (í—ˆìš© ì˜¤ì°¨ 50í”½ì…€)
            if dist_to_upper < dist_to_lower and dist_to_upper < 50:
                return 'upper'
            elif dist_to_lower < dist_to_upper and dist_to_lower < 50:
                return 'lower'
            else:
                return 'unknown'
                
        except Exception as e:
            self.get_logger().error(f"ë°©í–¥ë“± ìœ„ì¹˜ ë¶„ë¥˜ ì—ëŸ¬: {e}")
            return 'unknown'

    def _detect_with_learned_positions(self, image: np.ndarray, current_lights: List[dict]) -> int:
        """í•™ìŠµëœ ìœ„ì¹˜ ì •ë³´ë¥¼ í™œìš©í•œ ë°©í–¥ ê°ì§€"""
        try:
            # ìœ„ì¹˜ë³„ë¡œ ë¶„ë¥˜
            upper_lights = [light for light in current_lights if light.get('position_type') == 'upper']
            lower_lights = [light for light in current_lights if light.get('position_type') == 'lower']
            
            # ê° ì˜ì—­ì˜ í‰ê·  ë°ê¸° ê³„ì‚°
            upper_avg_brightness = sum([light['brightness'] for light in upper_lights]) / len(upper_lights) if upper_lights else 0
            lower_avg_brightness = sum([light['brightness'] for light in lower_lights]) / len(lower_lights) if lower_lights else 0
            
            self.get_logger().info(f"ğŸ” í•™ìŠµëœ ìœ„ì¹˜ ê¸°ë°˜ - ìœ„ìª½ í‰ê·  ë°ê¸°: {upper_avg_brightness:.1f}, ì•„ë˜ìª½ í‰ê·  ë°ê¸°: {lower_avg_brightness:.1f}")
            
            # ë°ê¸° ì°¨ì´ë¡œ ë°©í–¥ íŒë‹¨
            brightness_diff = upper_avg_brightness - lower_avg_brightness
            threshold = 40.0  # ë°ê¸° ì°¨ì´ ì„ê³„ê°’ (ì•ˆì •ì„± ìš°ì„ )
            
            self.get_logger().info(f"ğŸ’¡ ë°ê¸° ì°¨ì´: {brightness_diff:.1f} (ì„ê³„ê°’: Â±{threshold})")
            
            if brightness_diff > threshold:
                self.get_logger().debug("ğŸ”¥ ìœ„ìª½ ë°©í–¥ë“±ì´ ë” ë°ìŒ â†’ ìƒí–‰")
                return 0  # ìƒí–‰
            elif brightness_diff < -threshold:
                self.get_logger().debug("ğŸ”¥ ì•„ë˜ìª½ ë°©í–¥ë“±ì´ ë” ë°ìŒ â†’ í•˜í–‰") 
                return 1  # í•˜í–‰
            else:
                # ì°¨ì´ê°€ ë¯¸ë¯¸í•˜ë©´ ê¸°ì¡´ ë°©í–¥ ìœ ì§€
                self.get_logger().debug(f"ğŸ“Š ë°ê¸° ì°¨ì´ê°€ ì„ê³„ê°’ ì´í•˜ â†’ ê¸°ì¡´ ë°©í–¥ ìœ ì§€")
                return self.last_elevator_direction
                
        except Exception as e:
            self.get_logger().error(f"í•™ìŠµëœ ìœ„ì¹˜ ê¸°ë°˜ ê°ì§€ ì—ëŸ¬: {e}")
            return self.last_elevator_direction

    def _detect_direction_by_lights(self, image: np.ndarray, direction_objects: List[dict]) -> int:
        """ğŸ”¥ ê¹œë¹¡ì„ ê°ì§€ ê¸°ë°˜ ë°©í–¥ íŒë‹¨ (ìœ„ì¹˜ ê¸°ì–µ + ë°ê¸° ë³€í™” ì¶”ì )"""
        try:
            current_count = len(direction_objects)
            
            # 1ë‹¨ê³„: ë°©í–¥ë“± 2ê°œê°€ ê°ì§€ë˜ë©´ ìœ„ì¹˜ ì—…ë°ì´íŠ¸
            if current_count == 2:
                self._update_remembered_positions(direction_objects)
            
            # 2ë‹¨ê³„: ê¸°ì–µëœ ìœ„ì¹˜ê°€ ìˆìœ¼ë©´ ë°ê¸° íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            if (self.remembered_direction_positions['upper'] and 
                self.remembered_direction_positions['lower'] and 
                image is not None):
                
                # ë°ê¸° íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
                self._update_brightness_history(image)
                
                # 3ë‹¨ê³„: ê¹œë¹¡ì„ ê°ì§€ ìš°ì„  (ë°©í–¥ ë³€í™” ê°ì§€)
                if self.blink_detection_enabled:
                    upper_blink = self._detect_blink_at_position('upper')
                    lower_blink = self._detect_blink_at_position('lower')
                    
                    if upper_blink and not lower_blink:
                        self.get_logger().info("ğŸ”¥ğŸ”¥ ìœ„ìª½ ë°©í–¥ë“± ê¹œë¹¡ì„ ê°ì§€ â†’ ìƒí–‰!")
                        self.last_blink_detected = True
                        return 0  # ìƒí–‰
                    elif lower_blink and not upper_blink:
                        self.get_logger().info("ğŸ”¥ğŸ”¥ ì•„ë˜ìª½ ë°©í–¥ë“± ê¹œë¹¡ì„ ê°ì§€ â†’ í•˜í–‰!")
                        self.last_blink_detected = True
                        return 1  # í•˜í–‰
                    elif upper_blink and lower_blink:
                        self.get_logger().info("âš ï¸ ì–‘ìª½ ëª¨ë‘ ê¹œë¹¡ì„ ê°ì§€ë¨, ë°ê¸° ì°¨ì´ë¡œ íŒë‹¨")
                        self.last_blink_detected = True
                        # ì–‘ìª½ ëª¨ë‘ ê¹œë¹¡ì´ë©´ ë°ê¸° ì°¨ì´ë¡œ íŒë‹¨
                    else:
                        # ê¹œë¹¡ì„ì´ ì—†ìœ¼ë©´ ë°ê¸° ì°¨ì´ë¡œ íŒë‹¨
                        self.last_blink_detected = False
                
                # 4ë‹¨ê³„: ê¹œë¹¡ì„ì´ ì—†ê±°ë‚˜ ì–‘ìª½ ëª¨ë‘ ê¹œë¹¡ì´ë©´ ë°ê¸° ì°¨ì´ë¡œ íŒë‹¨
                upper_brightness = self._get_brightness_at_remembered_position(image, 'upper')
                lower_brightness = self._get_brightness_at_remembered_position(image, 'lower')
                
                brightness_diff = upper_brightness - lower_brightness
                threshold = 40.0
                
                self.get_logger().debug(f"ğŸ’¡ ê¸°ì–µëœ ìœ„ì¹˜ ë°ê¸°: ìœ„ìª½={upper_brightness:.1f}, ì•„ë˜ìª½={lower_brightness:.1f}, ì°¨ì´={brightness_diff:.1f}")
                
                if brightness_diff > threshold:
                    self.get_logger().debug("ğŸ”¥ ìœ„ìª½ ë°©í–¥ë“±ì´ ë” ë°ìŒ â†’ ìƒí–‰")
                    return 0  # ìƒí–‰
                elif brightness_diff < -threshold:
                    self.get_logger().debug("ğŸ”¥ ì•„ë˜ìª½ ë°©í–¥ë“±ì´ ë” ë°ìŒ â†’ í•˜í–‰")
                    return 1  # í•˜í–‰
                else:
                    self.get_logger().debug("ğŸ“Š ë°ê¸° ì°¨ì´ê°€ ì„ê³„ê°’ ì´í•˜ â†’ ê¸°ì¡´ ë°©í–¥ ìœ ì§€")
                    return self.last_elevator_direction
            else:
                # ê¸°ì–µëœ ìœ„ì¹˜ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©í–¥ ìœ ì§€
                if current_count == 0:
                    self.get_logger().debug("ë°©í–¥ë“± ë¯¸ê°ì§€, ê¸°ì–µëœ ìœ„ì¹˜ ì—†ìŒ â†’ ê¸°ì¡´ ë°©í–¥ ìœ ì§€")
                else:
                    self.get_logger().info(f"ë°©í–¥ë“± {current_count}ê°œ ê°ì§€ë¨ (2ê°œ í•„ìš”), ê¸°ì–µëœ ìœ„ì¹˜ ì—†ìŒ")
                return self.last_elevator_direction
            
        except Exception as e:
            self.get_logger().error(f"Direction light ê°ì§€ ì—ëŸ¬: {e}")
            return self.last_elevator_direction

    def _analyze_light_color(self, image: np.ndarray, light_obj: dict) -> str:
        """ë°©í–¥ë“± ì˜ì—­ì˜ ìƒ‰ìƒ ë¶„ì„"""
        try:
            bbox = light_obj.get('bbox')
            if not bbox:
                return 'UNKNOWN'
            
            x1, y1, x2, y2 = bbox
            
            # ë°©í–¥ë“± ì˜ì—­ í¬ë¡­
            light_region = image[y1:y2, x1:x2]
            
            if light_region.size == 0:
                return 'UNKNOWN'
            
            # BGR â†’ HSV ë³€í™˜
            hsv = cv2.cvtColor(light_region, cv2.COLOR_BGR2HSV)
            
            # ë…¹ìƒ‰ ë²”ìœ„ ê²€ì¶œ
            green_mask = cv2.inRange(hsv, 
                                   np.array([40, 50, 50]),    # ë…¹ìƒ‰ í•˜í•œ
                                   np.array([80, 255, 255]))  # ë…¹ìƒ‰ ìƒí•œ
            
            # ë¹¨ê°„ìƒ‰ ë²”ìœ„ ê²€ì¶œ
            red_mask1 = cv2.inRange(hsv,
                                   np.array([0, 50, 50]),     # ë¹¨ê°„ìƒ‰ í•˜í•œ1
                                   np.array([10, 255, 255]))  # ë¹¨ê°„ìƒ‰ ìƒí•œ1
            
            red_mask2 = cv2.inRange(hsv,
                                   np.array([170, 50, 50]),   # ë¹¨ê°„ìƒ‰ í•˜í•œ2  
                                   np.array([180, 255, 255])) # ë¹¨ê°„ìƒ‰ ìƒí•œ2
            
            red_mask = cv2.bitwise_or(red_mask1, red_mask2)
            
            # ìƒ‰ìƒë³„ í”½ì…€ ìˆ˜ ê³„ì‚°
            green_pixels = cv2.countNonZero(green_mask)
            red_pixels = cv2.countNonZero(red_mask)
            total_pixels = light_region.shape[0] * light_region.shape[1]
            
            # ë¹„ìœ¨ ê³„ì‚°
            green_ratio = green_pixels / total_pixels
            red_ratio = red_pixels / total_pixels
            
            # ì„ê³„ê°’ (ì „ì²´ ì˜ì—­ì˜ 10% ì´ìƒì´ë©´ í•´ë‹¹ ìƒ‰ìƒìœ¼ë¡œ íŒë‹¨)
            threshold = 0.1
            
            if green_ratio > threshold and green_ratio > red_ratio:
                return 'GREEN'
            elif red_ratio > threshold and red_ratio > green_ratio:
                return 'RED'
            else:
                return 'UNKNOWN'
                
        except Exception as e:
            self.get_logger().error(f"ë°©í–¥ë“± ìƒ‰ìƒ ë¶„ì„ ì—ëŸ¬: {e}")
            return 'UNKNOWN'

    def _fallback_direction_by_brightness(self, image: np.ndarray, upper_light: dict, lower_light: dict) -> int:
        """ìƒ‰ìƒì´ ë¶ˆë¶„ëª…í•  ë•Œ ë°ê¸°ë¡œ ë°©í–¥ íŒë‹¨"""
        try:
            upper_brightness = self._get_light_brightness(image, upper_light)
            lower_brightness = self._get_light_brightness(image, lower_light)
            
            self.get_logger().info(f"ë°©í–¥ë“± ë°ê¸°: ìœ„ìª½={upper_brightness:.2f}, ì•„ë˜ìª½={lower_brightness:.2f}")
            
            # ë” ë°ì€ ìª½ì´ ì¼œì§„ ê²ƒìœ¼ë¡œ ê°€ì •
            if upper_brightness > lower_brightness * 1.2:  # 20% ì´ìƒ ì°¨ì´
                return 0  # ìƒí–‰ (ìœ„ìª½ì´ ë°ìŒ)
            elif lower_brightness > upper_brightness * 1.2:
                return 1  # í•˜í–‰ (ì•„ë˜ìª½ì´ ë°ìŒ)
            else:
                return 0  # ê¸°ë³¸ ìƒí–‰
                
        except Exception as e:
            self.get_logger().error(f"ë°ê¸° ê¸°ë°˜ ë°©í–¥ íŒë‹¨ ì—ëŸ¬: {e}")
            return 0

    def _get_light_brightness(self, image: np.ndarray, light_obj: dict) -> float:
        """ë°©í–¥ë“±ì˜ í‰ê·  ë°ê¸° ê³„ì‚°"""
        try:
            bbox = light_obj.get('bbox')
            if not bbox:
                return 0.0
            
            x1, y1, x2, y2 = bbox
            light_region = image[y1:y2, x1:x2]
            
            if light_region.size == 0:
                return 0.0
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ í›„ í‰ê·  ë°ê¸°
            gray = cv2.cvtColor(light_region, cv2.COLOR_BGR2GRAY)
            return np.mean(gray)
            
        except Exception as e:
            return 0.0

    def _detect_by_disappearance(self, image: np.ndarray, current_lights: List[dict]) -> int:
        """ì†Œì‹¤ ê°ì§€: ì‚¬ë¼ì§„ ë°©í–¥ë“±ì˜ ìœ„ì¹˜ë¡œ ë°©í–¥ íŒë‹¨"""
        try:
            if not self.previous_direction_lights:
                return -1
            
            # ì´ì „ í”„ë ˆì„ê³¼ ë¹„êµí•˜ì—¬ ì‚¬ë¼ì§„ ê°ì²´ ì°¾ê¸°
            prev_positions = [(obj['center'][1], obj) for obj in self.previous_direction_lights]
            curr_positions = [obj['center'][1] for obj in current_lights]
            
            prev_positions.sort(key=lambda x: x[0])  # Y ì¢Œí‘œë¡œ ì •ë ¬
            
            disappeared_lights = []
            for y_pos, prev_obj in prev_positions:
                # í˜„ì¬ í”„ë ˆì„ì—ì„œ ë¹„ìŠ·í•œ ìœ„ì¹˜ì˜ ê°ì²´ê°€ ìˆëŠ”ì§€ í™•ì¸
                found = False
                for curr_y in curr_positions:
                    if abs(y_pos - curr_y) < 50:  # 50í”½ì…€ ì´ë‚´ë©´ ê°™ì€ ê°ì²´ë¡œ ê°„ì£¼
                        found = True
                        break
                
                if not found:
                    disappeared_lights.append(prev_obj)
            
            if disappeared_lights:
                # ì‚¬ë¼ì§„ ë°©í–¥ë“±ì´ ìœ„ìª½ì¸ì§€ ì•„ë˜ìª½ì¸ì§€ íŒë‹¨
                disappeared_y = [obj['center'][1] for obj in disappeared_lights]
                avg_disappeared_y = sum(disappeared_y) / len(disappeared_y)
                
                # ì „ì²´ ì´ë¯¸ì§€ ì¤‘ì•™ê³¼ ë¹„êµ
                image_center_y = image.shape[0] // 2
                
                if avg_disappeared_y < image_center_y:
                    self.get_logger().info("ğŸ”¥ ìœ„ìª½ ë°©í–¥ë“± ì†Œì‹¤ ê°ì§€ â†’ ìƒí–‰ (ìœ„ìª½ì´ ì¼œì§)")
                    return 0  # ìƒí–‰
                else:
                    self.get_logger().info("ğŸ”¥ ì•„ë˜ìª½ ë°©í–¥ë“± ì†Œì‹¤ ê°ì§€ â†’ í•˜í–‰ (ì•„ë˜ìª½ì´ ì¼œì§)")
                    return 1  # í•˜í–‰
            
            return -1
            
        except Exception as e:
            self.get_logger().error(f"ì†Œì‹¤ ê°ì§€ ì—ëŸ¬: {e}")
            return -1

    def _match_lights_by_position(self, prev_lights: List[dict], curr_lights: List[dict]) -> List[tuple]:
        """ğŸ” ì´ì „ í”„ë ˆì„ê³¼ í˜„ì¬ í”„ë ˆì„ì˜ ë°©í–¥ë“±ì„ ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ë§¤ì¹­"""
        try:
            matched_pairs = []
            
            for prev_light in prev_lights:
                prev_center = prev_light['center']
                best_match = None
                best_distance = float('inf')
                
                for curr_light in curr_lights:
                    curr_center = curr_light['center']
                    
                    # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
                    distance = ((prev_center[0] - curr_center[0]) ** 2 + 
                               (prev_center[1] - curr_center[1]) ** 2) ** 0.5
                    
                    if distance < self.position_tolerance and distance < best_distance:
                        best_distance = distance
                        best_match = curr_light
                
                if best_match:
                    matched_pairs.append((prev_light, best_match))
            
            self.get_logger().info(f"ğŸ”— ë§¤ì¹­ëœ ë°©í–¥ë“±: {len(matched_pairs)}ìŒ")
            return matched_pairs
            
        except Exception as e:
            self.get_logger().error(f"ë°©í–¥ë“± ë§¤ì¹­ ì—ëŸ¬: {e}")
            return []

    def _detect_by_absolute_brightness(self, current_lights: List[dict]) -> int:
        """ì ˆëŒ€ ë°ê¸° ê¸°ë°˜ ê°ì§€: ë„ˆë¬´ ë°ì€ ê²ƒ = ì¼œì§„ ê²ƒ"""
        try:
            if len(current_lights) < 2:
                return -1
            
            # ìœ„ìª½/ì•„ë˜ìª½ ë¶„ë¥˜ (í•™ìŠµëœ ìœ„ì¹˜ ì •ë³´ê°€ ìˆì„ ë•Œë§Œ)
            upper_lights = []
            lower_lights = []
            has_position_info = False
            
            for light in current_lights:
                if light.get('position_type') == 'upper':
                    upper_lights.append(light)
                    has_position_info = True
                elif light.get('position_type') == 'lower':
                    lower_lights.append(light)
                    has_position_info = True
                # ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¶„ë¥˜í•˜ì§€ ì•ŠìŒ (ì•ˆì „)
            
            # ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ íŒë‹¨ ë³´ë¥˜
            if not has_position_info:
                self.get_logger().warn("âš ï¸ í•™ìŠµëœ ìœ„ì¹˜ ì •ë³´ê°€ ì—†ì–´ ì ˆëŒ€ ë°ê¸° ê°ì§€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
                return -1
            
            # ê° ì˜ì—­ì—ì„œ ê°€ì¥ ë°ì€ ë°©í–¥ë“± ì°¾ê¸°
            upper_max_brightness = max([light['brightness'] for light in upper_lights]) if upper_lights else 0
            lower_max_brightness = max([light['brightness'] for light in lower_lights]) if lower_lights else 0
            
            self.get_logger().info(f"ğŸ’¡ ì ˆëŒ€ ë°ê¸°: ìœ„ìª½ ìµœëŒ€={upper_max_brightness:.1f}, ì•„ë˜ìª½ ìµœëŒ€={lower_max_brightness:.1f} (ì„ê³„ê°’: {self.brightness_threshold})")
            
            # ë§¤ìš° ë°ì€ ì˜ì—­ì€ ì¼œì§„ ê²ƒìœ¼ë¡œ íŒë‹¨
            upper_too_bright = upper_max_brightness > self.brightness_threshold
            lower_too_bright = lower_max_brightness > self.brightness_threshold
            
            if upper_too_bright and not lower_too_bright:
                self.get_logger().info("ğŸ”¥ ìœ„ìª½ ë°©í–¥ë“±ì´ ë§¤ìš° ë°ìŒ â†’ ìƒí–‰")
                return 0  # ìƒí–‰
            elif lower_too_bright and not upper_too_bright:
                self.get_logger().info("ğŸ”¥ ì•„ë˜ìª½ ë°©í–¥ë“±ì´ ë§¤ìš° ë°ìŒ â†’ í•˜í–‰")
                return 1  # í•˜í–‰
            
            return -1
            
        except Exception as e:
            self.get_logger().error(f"ì ˆëŒ€ ë°ê¸° ê°ì§€ ì—ëŸ¬: {e}")
            return -1

    def _detect_by_count_pattern(self) -> int:
        """ê°œìˆ˜ íŒ¨í„´ ë¶„ì„: ê°‘ì‘ìŠ¤ëŸ° ê°ì†ŒëŠ” ì¼œì§„ ê²ƒ"""
        try:
            if len(self.direction_light_history) < 3:
                return -1
            
            recent_counts = self.direction_light_history[-3:]  # ìµœê·¼ 3í”„ë ˆì„
            
            # 2ê°œ â†’ 1ê°œ ë˜ëŠ” 2ê°œ â†’ 0ê°œ íŒ¨í„´ ê°ì§€
            if recent_counts[-2] >= 2 and recent_counts[-1] < recent_counts[-2]:
                # ê°‘ì‘ìŠ¤ëŸ½ê²Œ ê°ì†Œí•œ ê²½ìš°
                self.get_logger().info(f"ğŸ” ê°œìˆ˜ íŒ¨í„´ ë¶„ì„: {recent_counts} â†’ ë°©í–¥ë“±ì´ ì¼œì ¸ì„œ ê°ì§€ ë¶ˆê°€")
                
                # íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ì „ ë°©í–¥ ìœ ì§€í•˜ë˜, ë³€í™” ê°€ëŠ¥ì„± ê³ ë ¤
                return self.last_elevator_direction
            
            return -1
            
        except Exception as e:
            self.get_logger().error(f"íŒ¨í„´ ë¶„ì„ ì—ëŸ¬: {e}")
            return -1

    def _get_light_brightness_advanced(self, image: np.ndarray, light_obj: dict) -> float:
        """ë°©í–¥ë“± ì˜ì—­ì˜ í‰ê·  ë°ê¸° ê³„ì‚° (ê°œì„ ëœ ë²„ì „)"""
        try:
            bbox = light_obj.get('bbox')
            if not bbox:
                return 0.0
            
            x1, y1, x2, y2 = bbox
            light_region = image[y1:y2, x1:x2]
            
            if light_region.size == 0:
                return 0.0
            
            # BGR â†’ Grayscale ë³€í™˜
            gray = cv2.cvtColor(light_region, cv2.COLOR_BGR2GRAY)
            
            # ìƒìœ„ 20% í”½ì…€ì˜ í‰ê·  ë°ê¸° (ê°€ì¥ ë°ì€ ë¶€ë¶„)
            flat_pixels = gray.flatten()
            flat_pixels.sort()
            top_20_percent = flat_pixels[int(len(flat_pixels) * 0.8):]
            
            return float(np.mean(top_20_percent))
            
        except Exception as e:
            self.get_logger().error(f"ë°ê¸° ê³„ì‚° ì—ëŸ¬: {e}")
            return 0.0

    def _get_lights_with_brightness(self, image: np.ndarray, direction_objects: List[dict]) -> List[dict]:
        """ğŸ”¥ ê° ë°©í–¥ë“±ì˜ ìœ„ì¹˜ì™€ ë°ê¸° ì •ë³´ ì¶”ì¶œ"""
        try:
            lights_with_brightness = []
            
            for obj in direction_objects:
                center = obj.get('center', [0, 0])
                brightness = self._get_light_brightness_advanced(image, obj)
                
                light_info = {
                    'center': center,
                    'brightness': brightness,
                    'bbox': obj.get('bbox'),
                    'original_obj': obj
                }
                lights_with_brightness.append(light_info)
            
            return lights_with_brightness
            
        except Exception as e:
            self.get_logger().error(f"ë°©í–¥ë“± ë°ê¸° ì •ë³´ ì¶”ì¶œ ì—ëŸ¬: {e}")
            return []

    def _detect_by_position_brightness_change(self, current_lights: List[dict]) -> int:
        """ğŸ”¥ ê°œë³„ ìœ„ì¹˜ë³„ ë°ê¸° ë³€í™” ê°ì§€ (í•µì‹¬ ë¡œì§)"""
        try:
            if not self.previous_direction_lights or not current_lights:
                return -1
            
            # ì´ì „ í”„ë ˆì„ê³¼ í˜„ì¬ í”„ë ˆì„ì˜ ë°©í–¥ë“± ë§¤ì¹­
            matched_lights = self._match_lights_by_position(self.previous_direction_lights, current_lights)
            
            if not matched_lights:
                return -1
            
            # ê° ë§¤ì¹­ëœ ë°©í–¥ë“±ì˜ ë°ê¸° ë³€í™” ê³„ì‚°
            brightness_changes = []
            for prev_light, curr_light in matched_lights:
                prev_brightness = prev_light['brightness']
                curr_brightness = curr_light['brightness']
                change = curr_brightness - prev_brightness
                
                # í•™ìŠµëœ ìœ„ì¹˜ ì •ë³´ê°€ ìˆì„ ë•Œë§Œ íŒë‹¨
                position_type = curr_light.get('position_type')
                if position_type == 'upper':
                    is_upper = True
                elif position_type == 'lower':
                    is_upper = False
                else:
                    # ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì´ ë°©í–¥ë“±ì€ ê±´ë„ˆëœ€
                    continue
                
                light_info = {
                    'center': curr_light['center'],
                    'prev_brightness': prev_brightness,
                    'curr_brightness': curr_brightness,
                    'change': change,
                    'is_upper': is_upper
                }
                brightness_changes.append(light_info)
                
                self.get_logger().info(f"ğŸ”„ ìœ„ì¹˜({curr_light['center'][0]},{curr_light['center'][1]}): {prev_brightness:.1f} â†’ {curr_brightness:.1f} (ë³€í™”: {change:+.1f})")
            
            # ğŸ”¥ ë°ê¸° ê¸‰ì¦í•œ ë°©í–¥ë“± ì°¾ê¸° (ì¼œì§„ ê²ƒ)
            significant_increases = [light for light in brightness_changes if light['change'] > self.brightness_change_threshold]
            
            if significant_increases:
                # ìœ„ìª½/ì•„ë˜ìª½ ë¶„ë¥˜
                upper_increases = [light for light in significant_increases if light['is_upper']]
                lower_increases = [light for light in significant_increases if not light['is_upper']]
                
                if upper_increases and not lower_increases:
                    self.get_logger().info(f"ğŸ”¥ ìœ„ìª½ ë°©í–¥ë“± {len(upper_increases)}ê°œ ë°ê¸° ê¸‰ì¦ â†’ ìƒí–‰")
                    return 0  # ìƒí–‰
                elif lower_increases and not upper_increases:
                    self.get_logger().info(f"ğŸ”¥ ì•„ë˜ìª½ ë°©í–¥ë“± {len(lower_increases)}ê°œ ë°ê¸° ê¸‰ì¦ â†’ í•˜í–‰")  
                    return 1  # í•˜í–‰
            
            # ë³€í™”ê°€ ë¯¸ë¯¸í•œ ê²½ìš°
            return -1
            
        except Exception as e:
            self.get_logger().error(f"ìœ„ì¹˜ë³„ ë°ê¸° ë³€í™” ê°ì§€ ì—ëŸ¬: {e}")
            return -1
    
    def _apply_button_recog_1(self, objects: List[dict]) -> List[dict]:
        """button_recog_1: ì—˜ë¦¬ë² ì´í„° ì™¸ë¶€ - ìƒí•˜ ìœ„ì¹˜ ê¸°ë°˜ ë¶„ë¥˜"""
        button_objects = [obj for obj in objects if obj.get('class_name') == 'button']
        
        if len(button_objects) < 2:
            return objects  # ë²„íŠ¼ì´ 2ê°œ ë¯¸ë§Œì´ë©´ ì›ë³¸ ë°˜í™˜
            
        # ë²„íŠ¼ë“¤ì„ Y ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìœ„ì—ì„œ ì•„ë˜ë¡œ)
        button_objects.sort(key=lambda x: x['center'][1])
        
        updated_objects = []
        
        for obj in objects:
            if obj.get('class_name') == 'button':
                # ì •ë ¬ëœ ë²„íŠ¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ í˜„ì¬ ë²„íŠ¼ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
                center_y = obj['center'][1]
                button_index = None
                for i, btn in enumerate(button_objects):
                    if btn['center'][1] == center_y and btn['center'][0] == obj['center'][0]:
                        button_index = i
                        break
                
                # ìƒìœ„ 50% ì¸ë±ìŠ¤ëŠ” UP, í•˜ìœ„ 50% ì¸ë±ìŠ¤ëŠ” DOWN
                if button_index is not None:
                    mid_index = len(button_objects) // 2
                    if button_index < mid_index:
                        obj['button_id'] = 101  # ìƒí–‰ë²„íŠ¼ (UP)
                        obj['floor_type'] = 'up'
                    else:
                        obj['button_id'] = 100  # í•˜í–‰ë²„íŠ¼ (DOWN)
                        obj['floor_type'] = 'down'
                else:
                    # ë§¤ì¹­ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
                    obj['button_id'] = 100  # í•˜í–‰ë²„íŠ¼
                    obj['floor_type'] = 'down'
                    
                obj['recognition_method'] = 'button_recog_1'
                
            updated_objects.append(obj)
            
        return updated_objects
    

    
    def _apply_enhanced_button_recognition(self, objects: List[dict], color_image: np.ndarray, mode_id: int = 0) -> List[dict]:
        """ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€: CNN ì „ìš©, ì™¸ë¶€: ë°°ì—´ ìš°ì„  + CNN í´ë°±"""
        button_objects = [obj for obj in objects if obj.get('class_name') == 'button']
        
        if not button_objects:
            return objects
        
        # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€(mode_id=4)ì¼ ë•Œ CNN ìš°ì„ , ì™¸ë¶€(mode_id=3)ì¼ ë•Œ ë°°ì—´ ìš°ì„ 
        if mode_id == 4:  # ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€ - CNN ìš°ì„  (ë°°ì—´ í´ë°± ì œê±°)
            # CNN ëª¨ë¸ ì¸ì‹ë§Œ ì‚¬ìš©
            for obj in button_objects:
                if 'bbox' in obj and self.cnn_classifier.model is not None:
                    cnn_result = self.cnn_classifier.classify_button(color_image, obj['bbox'])
                    if cnn_result and cnn_result['confidence'] > 0.6:  # ì‹ ë¢°ë„ ì„ê³„ê°’
                        # CNN ê²°ê³¼ë¡œ ì—…ë°ì´íŠ¸
                        original_class_name = obj.get('class_name')
                        obj.update(cnn_result)
                        obj['class_name'] = original_class_name
                        obj['recognition_method'] = 'cnn_primary'
                    else:
                        # CNN ì‹¤íŒ¨ ì‹œ unmappedë¡œ ì„¤ì • (ë°°ì—´ í´ë°± ì—†ìŒ)
                        obj['button_id'] = 'unmapped'
                        obj['recognition_method'] = 'cnn_failed'
                else:
                    # CNN ëª¨ë¸ì´ ì—†ê±°ë‚˜ bboxê°€ ì—†ëŠ” ê²½ìš°
                    obj['button_id'] = 'unmapped'
                    obj['recognition_method'] = 'cnn_unavailable'
            
            return objects
            
        else:  # ì—˜ë¦¬ë² ì´í„° ì™¸ë¶€(mode_id=3) ë˜ëŠ” ê¸°íƒ€ ëª¨ë“œ - ê¸°ì¡´ ë°°ì—´ ìš°ì„  ë°©ì‹ ìœ ì§€
            
            # 1ìˆœìœ„: ê¸°ì¡´ ë°°ì—´ ê¸°ë°˜ ì¸ì‹
            processed_objects = objects
            
            if mode_id == 3:  # ì—˜ë¦¬ë² ì´í„° ì™¸ë¶€
                processed_objects = self._apply_button_recog_1(objects)
            
            # 2ìˆœìœ„: ë°°ì—´ ì¸ì‹ ì‹¤íŒ¨í•œ ë²„íŠ¼ë“¤ì— CNN ì ìš©
            successful_buttons = []
            failed_buttons = []
            
            for obj in processed_objects:
                if obj.get('class_name') == 'button':
                    if (obj.get('button_id') not in ['unmapped', None] and 
                        obj.get('recognition_method') == 'button_recog_1'):
                        successful_buttons.append(obj)
                    else:
                        failed_buttons.append(obj)
            
            # CNN í´ë°± ì ìš©
            cnn_success_count = 0
            if failed_buttons and self.cnn_classifier.model is not None:
                for obj in failed_buttons:
                    if 'bbox' in obj:
                        cnn_result = self.cnn_classifier.classify_button(color_image, obj['bbox'])
                        if cnn_result and cnn_result['confidence'] > 0.6:
                            original_class_name = obj.get('class_name')
                            obj.update(cnn_result)
                            obj['class_name'] = original_class_name
                            obj['recognition_method'] = 'cnn_fallback'
                            successful_buttons.append(obj)
                            cnn_success_count += 1
            
            return processed_objects


    def _start_rear_camera_streaming(self):
        """í›„ë°© ì¹´ë©”ë¼ UDP ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"""
        try:
            if not hasattr(self, 'streaming_active'):
                self.streaming_active = False
                self.streaming_thread = None
            
            # ì¹´ë©”ë¼ ìœ ë¬´ì™€ ë¬´ê´€í•˜ê²Œ ìŠ¤íŠ¸ë¦¬ë° ìŠ¤ë ˆë“œë¥¼ ì‹œì‘í•˜ê³ ,
            # ë£¨í”„ ë‚´ì—ì„œ ì¹´ë©”ë¼ê°€ ì¤€ë¹„ë˜ì—ˆì„ ë•Œë§Œ í”„ë ˆì„ì„ ì „ì†¡í•œë‹¤.
            if not self.streaming_active:
                self.streaming_active = True
                self.streaming_thread = threading.Thread(target=self._rear_camera_streaming_loop, daemon=True)
                self._rear_first_send_logged = False
                self._rear_wait_log_emitted = False
                self.streaming_thread.start()
                self.get_logger().info("ğŸ“¹ í›„ë°© ì¹´ë©”ë¼ UDP ìŠ¤íŠ¸ë¦¬ë° ìŠ¤ë ˆë“œ ì‹œì‘ (ì¹´ë©”ë¼ ì¤€ë¹„ì™€ ë¬´ê´€í•˜ê²Œ ì‹œì‘)")
                
        except Exception as e:
            self.get_logger().error(f"UDP ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì‹¤íŒ¨: {e}")
    
    def _stop_rear_camera_streaming(self):
        """í›„ë°© ì¹´ë©”ë¼ UDP ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€"""
        try:
            if hasattr(self, 'streaming_active') and self.streaming_active:
                self.streaming_active = False
                if hasattr(self, 'streaming_thread') and self.streaming_thread:
                    self.streaming_thread.join(timeout=1.0)
                self.get_logger().info("ğŸ“¹ í›„ë°© ì¹´ë©”ë¼ UDP ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€")
                
        except Exception as e:
            self.get_logger().error(f"UDP ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ ì‹¤íŒ¨: {e}")
    
    def _rear_camera_streaming_loop(self):
        """í›„ë°© ì¹´ë©”ë¼ í”„ë ˆì„ì„ ì£¼ê¸°ì ìœ¼ë¡œ UDPë¡œ ì „ì†¡í•˜ëŠ” ë£¨í”„"""
        try:
            while self.streaming_active and rclpy.ok():
                try:
                    if self.current_rear_camera is not None:
                        # í›„ë°© ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° (WebCamCamera: (depth=None, color) ë°˜í™˜)
                        _, color_frame = self.current_rear_camera.get_frames()
                        
                        if color_frame is not None:
                            # ğŸ‘¤ PersonTrackerì— í”„ë ˆì„ ì „ë‹¬
                            if hasattr(self, 'person_tracker') and self.person_tracker:
                                self.person_tracker.push_frame(color_frame)
                            
                            # PersonTracker ì˜¤ë²„ë ˆì´ ì ìš© (ì„ íƒì )
                            display_frame = color_frame
                            if hasattr(self, 'person_tracker') and self.person_tracker:
                                display_frame = self.person_tracker.get_overlay_frame(color_frame)
                            
                            # UDPë¡œ í”„ë ˆì„ ì „ì†¡ (BGR í˜•ì‹)
                            sent = self.udp_streamer.send_frame_bgr(display_frame)
                            if sent and not getattr(self, '_rear_first_send_logged', False):
                                ip, prt = self.udp_streamer.addr
                                h, w = color_frame.shape[:2]
                                self.get_logger().info(f"ğŸ“¤ í›„ë°© UDP ì²« í”„ë ˆì„ ì „ì†¡: {w}x{h} â†’ {ip}:{prt}")
                                self._rear_first_send_logged = True
                            self._rear_wait_log_emitted = True
                        else:
                            # ì¹´ë©”ë¼ í”„ë ˆì„ì´ ì—†ìœ¼ë©´ 1ì´ˆ ê°„ê²©ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì†¡ì¶œ
                            import time as _t
                            last_ts = getattr(self, '_rear_last_test_ts', 0.0)
                            if _t.time() - last_ts > 1.0:
                                import numpy as _np, cv2 as _cv2
                                test = _np.full((360, 640, 3), 255, dtype=_np.uint8)
                                ts = _t.strftime('%H:%M:%S')
                                _cv2.putText(test, ts, (50, 190), _cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 255), 4)
                                # ì›€ì§ì´ëŠ” ë°” ì¶”ê°€ë¡œ ê°±ì‹  ê°€ì‹œí™”
                                bar_x = int((_t.time() * 50) % 600)
                                _cv2.rectangle(test, (bar_x, 320), (bar_x + 40, 350), (0, 128, 255), -1)
                                self.udp_streamer.send_frame_bgr(test, quality=85)
                                if not getattr(self, '_rear_test_send_logged', False):
                                    self.get_logger().info("ğŸ§ª í›„ë°© UDP í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì „ì†¡ (ì¹´ë©”ë¼ í”„ë ˆì„ ì—†ìŒ)")
                                    self._rear_test_send_logged = True
                                self._rear_last_test_ts = _t.time()
                    else:
                        if not getattr(self, '_rear_wait_log_emitted', False):
                            ip, prt = self.udp_streamer.addr
                            self.get_logger().info(f"â³ í›„ë°© ì¹´ë©”ë¼ ëŒ€ê¸° ì¤‘... (UDP ëŒ€ìƒ: {ip}:{prt})")
                            self._rear_wait_log_emitted = True
                        # ì¹´ë©”ë¼ê°€ ì—†ì„ ë•Œë„ 1ì´ˆ ê°„ê²© í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì†¡ì¶œ
                        import time as _t
                        last_ts = getattr(self, '_rear_last_test_ts', 0.0)
                        if _t.time() - last_ts > 1.0:
                            import numpy as _np, cv2 as _cv2
                            test = _np.full((360, 640, 3), 255, dtype=_np.uint8)
                            _cv2.putText(test, 'NO CAMERA', (120, 190), _cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 255), 4)
                            bar_x = int((_t.time() * 50) % 600)
                            _cv2.rectangle(test, (bar_x, 320), (bar_x + 40, 350), (0, 128, 255), -1)
                            self.udp_streamer.send_frame_bgr(test, quality=85)
                            if not getattr(self, '_rear_test_send_logged', False):
                                self.get_logger().info("ğŸ§ª í›„ë°© UDP í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì „ì†¡ (ì¹´ë©”ë¼ ì—†ìŒ)")
                                self._rear_test_send_logged = True
                            self._rear_last_test_ts = _t.time()
                    
                    # FPS ì œí•œ (15fps ~= 66.7ms) â†’ ì•½ê°„ ì—¬ìœ ë¥¼ ë‘ 
                    time.sleep(0.070)
                    
                except Exception as e:
                    self.get_logger().warning(f"í”„ë ˆì„ ì „ì†¡ ì˜¤ë¥˜: {e}")
                    time.sleep(0.1)  # ì—ëŸ¬ ì‹œ ì ì‹œ ëŒ€ê¸°
                    
        except Exception as e:
            self.get_logger().error(f"UDP ìŠ¤íŠ¸ë¦¬ë° ë£¨í”„ ì˜¤ë¥˜: {e}")
        finally:
            self.streaming_active = False


def main(args=None):
    rclpy.init(args=args)
    
    try:
        node = VSNode()
        
        # ë©”ì¸ ì“°ë ˆë“œì—ì„œ GUIì™€ ROS2ë¥¼ í•¨ê»˜ ì²˜ë¦¬
        node.get_logger().info("ë©”ì¸ ì“°ë ˆë“œì—ì„œ GUI ì‹œì‘!")
        
        import cv2
        frame_count = 0
        
        try:
            while rclpy.ok():
                frame_count += 1
                
                # GUI ì²˜ë¦¬ë¥¼ ìš°ì„ ìˆœìœ„ë¡œ
                try:
                    active_cameras = node.get_active_cameras()
                    
                    for camera_info in active_cameras:
                        camera = camera_info['camera']
                        depth_camera = camera_info['depth_camera']
                        camera_name = camera_info['name']
                        camera_type = camera_info['type']
                        mode_id = camera_info['mode_id']
                        
                        # ë””ë²„ê·¸: ì¹´ë©”ë¼ ì •ë³´ ì¶œë ¥
                        if frame_count % 100 == 1:
                            node.get_logger().info(f"ğŸ” GUI ì¹´ë©”ë¼: name={camera_name}, type={camera_type}")
                        
                        depth_image, color_image = None, None
                        
                        # ë©”ì¸ ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ íšë“
                        if camera:
                            try:
                                depth_image, color_image = camera.get_frames()
                            except Exception as e:
                                if frame_count % 100 == 1:
                                    node.get_logger().warning(f"{camera_name} í”„ë ˆì„ íšë“ ì‹¤íŒ¨: {e}")
                        
                        # ì¶”ê°€ ëìŠ¤ ì¹´ë©”ë¼ê°€ ìˆìœ¼ë©´ ëìŠ¤ë§Œ ë‹¤ì‹œ íšë“
                        if depth_camera and depth_camera != camera:
                            try:
                                additional_depth, _ = depth_camera.get_frames()
                                if additional_depth is not None:
                                    depth_image = additional_depth
                            except Exception as e:
                                if frame_count % 100 == 1:
                                    node.get_logger().warning(f"{camera_name} ëìŠ¤ ì¹´ë©”ë¼ í”„ë ˆì„ íšë“ ì‹¤íŒ¨: {e}")
                        
                        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ ì¹´ë©”ë¼ë¡œ
                        if color_image is None:
                            if frame_count % 100 == 1:
                                node.get_logger().warning(f"âŒ {camera_name}: color_imageê°€ Noneì…ë‹ˆë‹¤")
                            continue
                        
                        # ì´ë¯¸ì§€ ì¢Œìš°ë°˜ì „ (ëìŠ¤ ì¹´ë©”ë¼ë§Œ)
                        if camera_type == 'front_depth':
                            if color_image is not None:
                                color_image = cv2.flip(color_image, 1)
                            if depth_image is not None:
                                depth_image = cv2.flip(depth_image, 1)
                        
                        # ArUco ë§ˆì»¤ ìë™ ê°ì§€ (ì¼ë°˜ ëª¨ë“œì˜ ì „ë°© ì›¹ìº ì—ì„œë§Œ)
                        if color_image is not None and camera_type == 'front_webcam' and mode_id == 5:
                            node.detect_and_update_location()
                        
                        # ê°ì²´ íƒì§€ ë° ì‹œê°í™”
                        objects = []
                        if color_image is not None:
                            # ëª¨ë“œë³„ + ì¹´ë©”ë¼ íƒ€ì…ë³„ ì„¸ë¶„í™”
                            if camera_type == 'front_webcam':
                                if mode_id in [3, 4]:  # ì—˜ë¦¬ë² ì´í„° ëª¨ë“œ: ì›¹ìº ì— ì—˜ë¦¬ë² ì´í„° YOLO
                                    detected_objects = node.model_detector.detect_objects(color_image, depth_image, node.confidence_threshold, mode_id)
                                    
                                    # ğŸ¯ OCR ë¦¬ì†ŒìŠ¤ ì ˆì•½: ì§€ì •ëœ í”„ë ˆì„ ê°„ê²©ë§ˆë‹¤ë§Œ OCR ìˆ˜í–‰
                                    node.ocr_counter += 1
                                    if node.ocr_counter >= node.ocr_skip_frames:
                                        enhanced_objects = node._enhance_objects_with_ocr(color_image, detected_objects)
                                        # button_statusì™€ ë™ì¼í•œ ê³ ê¸‰ ë²„íŠ¼ ì¸ì‹ ë¡œì§ ì¶”ê°€
                                        objects = node._apply_enhanced_button_recognition(enhanced_objects, color_image, mode_id)
                                        node.last_ocr_objects = objects  # ê²°ê³¼ ìºì‹±
                                        node.ocr_counter = 0  # ì¹´ìš´í„° ë¦¬ì…‹
                                        if frame_count % 100 == 1:
                                            node.get_logger().debug(f"ğŸ”„ OCR ìˆ˜í–‰ë¨ (ë§¤ {node.ocr_skip_frames}í”„ë ˆì„ë§ˆë‹¤)")
                                    else:
                                        # OCR ê±´ë„ˆë›°ê³  ì´ì „ ê²°ê³¼ ì¬ì‚¬ìš© (ê°ì²´ ê°ì§€ëŠ” ê³„ì†)
                                        objects = detected_objects.copy()
                                        # ì´ì „ OCR ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë³‘í•©
                                        if hasattr(node, 'last_ocr_objects') and node.last_ocr_objects:
                                            for old_obj in node.last_ocr_objects:
                                                if old_obj.get('class_name') == 'display' and old_obj.get('ocr_text'):
                                                    # ì´ì „ OCR ê²°ê³¼ë¥¼ í˜„ì¬ display ê°ì²´ì— ì ìš©
                                                    for new_obj in objects:
                                                        if (new_obj.get('class_name') == 'display' and 
                                                            not new_obj.get('ocr_text')):
                                                            new_obj['ocr_text'] = old_obj.get('ocr_text', '')
                                                            new_obj['floor_number'] = old_obj.get('floor_number')
                                                            new_obj['ocr_success'] = old_obj.get('ocr_success', False)
                                                            new_obj['digit_bbox'] = old_obj.get('digit_bbox')
                                                            break
                                        # button_statusì™€ ë™ì¼í•œ ê³ ê¸‰ ë²„íŠ¼ ì¸ì‹ ë¡œì§ ì¶”ê°€
                                        objects = node._apply_enhanced_button_recognition(objects, color_image, mode_id)
                                elif mode_id == 5:  # ì¼ë°˜ ëª¨ë“œ: ArUcoë§Œ (ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬)
                                    pass
                                elif mode_id == 6:  # ëŒ€ê¸° ëª¨ë“œ: ì˜ìƒë§Œ
                                    pass
                            elif camera_type == 'front_depth':
                                if mode_id == 5:  # ì¼ë°˜ ëª¨ë“œ: ëìŠ¤ì— ì¼ë°˜ YOLO (OCR ë¶ˆí•„ìš” - ArUcoë§Œ)
                                    detected_objects = node.model_detector.detect_objects(color_image, depth_image, node.confidence_threshold, mode_id)
                                    objects = detected_objects  # OCR ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                                    
                                    # ğŸš§ ì¥ì• ë¬¼ ê°ì§€ ë° ë°œí–‰ ì¶”ê°€
                                    node.detect_and_publish_obstacles(
                                        objects, depth_camera, mode_id
                                    )
                                    
                                    # ğŸšª ìœ ë¦¬ ë¬¸ ìƒíƒœ ê°ì§€ ë° ë°œí–‰ ì¶”ê°€
                                    node.detect_and_publish_glass_door_status(
                                        objects, mode_id
                                    )
                                elif mode_id in [3, 4, 6]:  # ì—˜ë¦¬ë² ì´í„°/ëŒ€ê¸° ëª¨ë“œ: ëìŠ¤ëŠ” ì˜ìƒë§Œ
                                    pass
                            elif camera_type in ['rear', 'front']:
                                # í›„ë°© ì¹´ë©”ë¼ë‚˜ ê¸°íƒ€ ì „ë°© ì¹´ë©”ë¼: ì˜ìƒë§Œ
                                pass
                            
                            # ğŸ¯ ë§ˆì§€ë§‰ ê°ì§€ëœ ê°ì²´ë“¤ ì €ì¥ (Lí‚¤ìš©)
                            if objects and mode_id in [3, 4] and camera_type == 'front_webcam':
                                node.last_detected_objects = objects.copy()
                            
                            # ğŸ¯ ë©”ì¸ ë£¨í”„ì—ì„œ ë°©í–¥ë“± ìœ„ì¹˜ ê¸°ì–µ + ì‹¤ì‹œê°„ ë°©í–¥ ê°ì§€ (ì—˜ë¦¬ë² ì´í„° ëª¨ë“œì—ì„œë§Œ)
                            if mode_id in [3, 4] and camera_type == 'front_webcam':
                                if objects:
                                    direction_objects = [obj for obj in objects if obj.get('class_name') == 'direction_light']
                                    if len(direction_objects) == 2:
                                        node._update_remembered_positions(direction_objects)
                                
                                # ê¸°ì–µëœ ìœ„ì¹˜ê°€ ìˆìœ¼ë©´ í•­ìƒ ë°ê¸° íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ + ë°©í–¥ ê°ì§€
                                if (node.remembered_direction_positions['upper'] and 
                                    node.remembered_direction_positions['lower']):
                                    node._update_brightness_history(color_image)
                                    
                                    # ğŸš¦ ë©”ì¸ ë£¨í”„ì—ì„œë„ ì‹¤ì‹œê°„ ë°©í–¥ ê°ì§€ (GUI ì—…ë°ì´íŠ¸ìš©)
                                    direction_objects_for_detection = []
                                    if objects:
                                        direction_objects_for_detection = [obj for obj in objects if obj.get('class_name') == 'direction_light']
                                    
                                    detected_direction = node._detect_direction_by_lights(color_image, direction_objects_for_detection)
                                    
                                    # ë°©í–¥ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ê¹œë¹¡ì„ì´ ê°ì§€ëœ ê²½ìš° ì—…ë°ì´íŠ¸
                                    if detected_direction != -1:
                                        if (detected_direction != node.last_elevator_direction or node.last_blink_detected):
                                            node.last_elevator_direction = detected_direction
                                            node.last_direction_detection_time = node.get_clock().now()
                                            blink_info = " (ê¹œë¹¡ì„ ê°ì§€)" if node.last_blink_detected else ""
                                            node.get_logger().info(f"ğŸ¯ [ë©”ì¸ë£¨í”„] ë°©í–¥ ì—…ë°ì´íŠ¸: {'ìƒí–‰' if detected_direction == 0 else 'í•˜í–‰'}{blink_info}")
                                            
                                            # ê¹œë¹¡ì„ ì²˜ë¦¬ ì™„ë£Œ í›„ í”Œë˜ê·¸ ì´ˆê¸°í™”
                                            if node.last_blink_detected:
                                                node.last_blink_detected = False
                            
                            display_image = color_image.copy()
                            if objects:
                                display_image = node._draw_objects_on_image(display_image, objects, mode_id)
                            node._add_info_text(display_image, objects, camera_name)
                            
                            # GUI í‘œì‹œ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ)
                            if not node.headless_mode:
                                # ì°½ ì´ë¦„ì„ ì¹´ë©”ë¼ íƒ€ì… ê¸°ì¤€ìœ¼ë¡œ ê³ ì • (ëª¨ë“œ ë³€ê²½ ì‹œ ì°½ ì¬ì‚¬ìš©)
                                if camera_type == 'front_webcam':
                                    window_name = 'Roomie VS - Front Webcam'
                                elif camera_type == 'front_depth':
                                    window_name = 'Roomie VS - Front Depth'
                                elif camera_type in ['rear', 'front']:
                                    if 'Rear' in camera_name:
                                        window_name = 'Roomie VS - Rear Webcam'
                                    else:
                                        window_name = 'Roomie VS - Front Webcam'
                                else:
                                    window_name = f'Roomie VS - {camera_type}'
                                
                                cv2.imshow(window_name, display_image)
                                cv2.waitKey(1)
                    
                    # í‚¤ ì²˜ë¦¬ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ)
                    if not node.headless_mode:
                        key = cv2.waitKey(30) & 0xFF
                        
                        if key == 27:  # ESC
                            node.get_logger().info("ESC í‚¤ ëˆŒë¦¼ - GUI ì¢…ë£Œ")
                            break
                        elif key == ord('r') or key == ord('R'):  # Rí‚¤: ì¶”ì  ì‹œë®¬ë ˆì´ì…˜ (ì‚­ì œë¨)
                            node.get_logger().info("'R' í‚¤ ëˆŒë¦¼ - ì¶”ì  ì‹œë®¬ë ˆì´ì…˜ ê¸°ëŠ¥ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤")
                        elif key == ord('t') or key == ord('T'):  # Tí‚¤: ë‹¨ì¼ ì¶”ì  ì´ë²¤íŠ¸ (ì‚­ì œë¨)
                            node.get_logger().info("'T' í‚¤ ëˆŒë¦¼ - ì¶”ì  ì´ë²¤íŠ¸ ë°œí–‰ ê¸°ëŠ¥ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤")
                        elif key == ord('g') or key == ord('G'):  # Gí‚¤: ë“±ë¡ ì™„ë£Œ ì´ë²¤íŠ¸ (ì‚­ì œë¨)
                            node.get_logger().info("'G' í‚¤ ëˆŒë¦¼ - ë“±ë¡ ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰ ê¸°ëŠ¥ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤")
                        elif key == ord('b') or key == ord('B'):  # Bí‚¤: ê°ì²´ íƒì§€ ê²°ê³¼ ì¶œë ¥
                            model_info = node.model_detector.get_current_model_info()
                            # ì•ˆì „í•œ ëª¨ë¸ ì´ë¦„ í‘œì‹œ
                            raw_model_name = model_info['model_name']
                            if raw_model_name == 'normal':
                                current_model = "Normal"
                            elif raw_model_name == 'elevator':
                                current_model = "Elevator"
                            else:
                                current_model = raw_model_name or "None"
                            
                            if objects:
                                button_objects = [obj for obj in objects if obj.get('class_name') == 'button']
                                other_objects = [obj for obj in objects if obj.get('class_name') != 'button']
                                
                                node.get_logger().info(f"'B' í‚¤ ëˆŒë¦¼ - ê°ì²´ íƒì§€ ê²°ê³¼ (ëª¨ë¸: {current_model}):")
                                node.get_logger().info(f"  ì „ì²´ ê°ì²´: {len(objects)}ê°œ")
                                node.get_logger().info(f"  ë²„íŠ¼: {len(button_objects)}ê°œ")
                                node.get_logger().info(f"  ê¸°íƒ€ ê°ì²´: {len(other_objects)}ê°œ")
                                
                                if button_objects:
                                    node.get_logger().info("  íƒì§€ëœ ë²„íŠ¼ë“¤:")
                                    for i, obj in enumerate(button_objects):
                                        confidence = obj.get('confidence', 1.0)
                                        pressed = "ëˆŒë¦¼" if obj.get('is_pressed', False) else "ì•ˆëˆŒë¦¼"
                                        model_name = obj.get('model_name', 'unknown')
                                        button_id = obj.get('button_id', 'unknown')
                                        recognition_method = obj.get('recognition_method', 'none')
                                        floor_type = obj.get('floor_type', 'unknown')
                                        
                                        # ë²„íŠ¼ ì´ë¦„ ë³€í™˜
                                        if isinstance(button_id, int):
                                            if button_id == 100:
                                                button_name = "DOWN"
                                            elif button_id == 101:
                                                button_name = "UP"
                                            elif button_id == 102:
                                                button_name = "OPEN"
                                            elif button_id == 103:
                                                button_name = "CLOSE"
                                            elif button_id == 13:
                                                button_name = "B1F"
                                            elif button_id == 14:
                                                button_name = "B2F"
                                            else:
                                                button_name = f"{button_id}F"
                                        else:
                                            button_name = str(button_id)
                                        
                                        node.get_logger().info(f"    {i+1}. {button_name} ({model_name}/{recognition_method}) - ì‹ ë¢°ë„:{confidence:.2f}, {pressed}, {obj['depth_mm']}mm")
                                
                                if other_objects:
                                    node.get_logger().info("  ê¸°íƒ€ ê°ì²´ë“¤:")
                                    for i, obj in enumerate(other_objects):
                                        class_name = obj.get('class_name', 'unknown')
                                        confidence = obj.get('confidence', 1.0)
                                        model_name = obj.get('model_name', 'unknown')
                                        node.get_logger().info(f"    {i+1}. {class_name} ({model_name}) - ì‹ ë¢°ë„:{confidence:.2f}, {obj['depth_mm']}mm")
                            else:
                                node.get_logger().info(f"'B' í‚¤ ëˆŒë¦¼ - íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë¸: {current_model})")
                        elif key == ord('f') or key == ord('F'):  # Fí‚¤: ì¢Œìš°ë°˜ì „ í† ê¸€
                            node.flip_horizontal = not node.flip_horizontal
                            status = "ì¼œì§" if node.flip_horizontal else "êº¼ì§"
                            node.get_logger().info(f"'F' í‚¤ ëˆŒë¦¼ - ì¢Œìš°ë°˜ì „: {status}")
                        elif key == ord('c') or key == ord('C'):  # Cí‚¤: ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì •
                            current_conf = node.confidence_threshold
                            if current_conf == 0.7:
                                node.confidence_threshold = 0.5
                            elif current_conf == 0.5:
                                node.confidence_threshold = 0.9
                            else:
                                node.confidence_threshold = 0.7
                            
                            node.get_logger().info(f"'C' í‚¤ ëˆŒë¦¼ - ì‹ ë¢°ë„ ì„ê³„ê°’: {current_conf:.2f} â†’ {node.confidence_threshold:.2f}")

                        elif key == ord('m') or key == ord('M'):  # Mí‚¤: í˜„ì¬ ëª¨ë“œ í™•ì¸
                            current_mode = node.get_active_mode_name()
                            model_info = node.model_detector.get_current_model_info()
                            model_status = "âœ…" if model_info['is_active'] else "âŒ"
                            # ì•ˆì „í•œ ëª¨ë¸ ì´ë¦„ í‘œì‹œ
                            raw_model_name = model_info['model_name']
                            if raw_model_name == 'normal':
                                current_model = "Normal"
                            elif raw_model_name == 'elevator':
                                current_model = "Elevator"
                            else:
                                current_model = raw_model_name or "None"
                            aruco_status = "âœ…" if node.aruco_dict else "âŒ"
                            
                            node.get_logger().info(f"'M' í‚¤ ëˆŒë¦¼ - í˜„ì¬ ìƒíƒœ:")
                            node.get_logger().info(f"  VS ëª¨ë“œ - ì „ë°©: {node.mode_names[node.current_front_mode_id]} (ID:{node.current_front_mode_id}), í›„ë°©: {node.mode_names[node.current_rear_mode_id]} (ID:{node.current_rear_mode_id})")
                            node.get_logger().info(f"  í˜„ì¬ ëª¨ë¸: {current_model} {model_status}")
                            node.get_logger().info(f"  ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {model_info['available_models']}")
                            node.get_logger().info(f"  í˜„ì¬ ì¹´ë©”ë¼: {node.current_camera_name}")
                            node.get_logger().info(f"  ArUco ì‹œìŠ¤í…œ: {aruco_status}")
                            node.get_logger().info(f"  ì¢Œìš°ë°˜ì „: {'ON' if node.flip_horizontal else 'OFF'}")
                            node.get_logger().info(f"  ì‹ ë¢°ë„ ì„ê³„ê°’: {node.confidence_threshold}")
                            
                            # í˜„ì¬ ìœ„ì¹˜ ì •ë³´
                            location_names = {
                                0: "LOB_WAITING", 1: "LOB_CALL", 2: "RES_PICKUP", 3: "RES_CALL",
                                4: "SUP_PICKUP", 5: "ELE_1", 6: "ELE_2", 101: "ROOM_101",
                                102: "ROOM_102", 201: "ROOM_201", 202: "ROOM_202"
                            }
                            current_location_name = location_names.get(node.last_detected_location_id, f"ID_{node.last_detected_location_id}")
                            node.get_logger().info(f"  í˜„ì¬ ìœ„ì¹˜: {current_location_name}")
                            
                            if model_info['is_active']:
                                supported_classes = model_info['class_names']
                                node.get_logger().info(f"  ê°ì§€ ê°€ëŠ¥í•œ ê°ì²´: {supported_classes}")
                            else:
                                node.get_logger().info(f"  ê°ì§€ ê°€ëŠ¥í•œ ê°ì²´: ì—†ìŒ (ëª¨ë¸ ë¹„í™œì„±í™”)")
                            
                            node.get_logger().info("í›„ë°© ì¹´ë©”ë¼ ëª¨ë“œ: 0(ëŒ€ê¸°), 1(ë“±ë¡), 2(ì¶”ì )")
                            node.get_logger().info("ì „ë°© ì¹´ë©”ë¼ ëª¨ë“œ: 3(ì—˜ë¦¬ë² ì´í„° ì™¸ë¶€), 4(ì—˜ë¦¬ë² ì´í„° ë‚´ë¶€), 5(ì¼ë°˜), 6(ëŒ€ê¸°)")
                            node.get_logger().info("ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: 100(ë°°ì†¡), 101(í˜¸ì¶œ), 102(ê¸¸ì•ˆë‚´), 103(ë³µê·€), 104(ì—˜ë¦¬ë² ì´í„°)")
                            node.get_logger().info("í‚¤ë³´ë“œ: A(ArUcoí…ŒìŠ¤íŠ¸), F(ì¢Œìš°ë°˜ì „), C(ì‹ ë¢°ë„ì¡°ì •)")
                        elif key == ord('a') or key == ord('A'):  # Aí‚¤: ArUco ê°ì§€ í…ŒìŠ¤íŠ¸
                            node.test_aruco_detection()
                        elif key == ord('d') or key == ord('D'):  # Dí‚¤: ë°©í–¥ë“± ìœ„ì¹˜ ë¦¬ì…‹
                            node.remembered_direction_positions = {'upper': None, 'lower': None}
                            node.last_position_update = None
                            node.brightness_history = {'upper': [], 'lower': []}
                            node.get_logger().info("ğŸ”„ ë°©í–¥ë“± ìœ„ì¹˜ì™€ ë°ê¸° íˆìŠ¤í† ë¦¬ë¥¼ ë¦¬ì…‹í–ˆìŠµë‹ˆë‹¤. ë°©í–¥ë“± 2ê°œê°€ ê°ì§€ë˜ë©´ ë‹¤ì‹œ ê¸°ì–µì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                        elif key == ord('l') or key == ord('L'):  # Lí‚¤: ê°•ì œ ë°©í–¥ë“± ìœ„ì¹˜ ê¸°ì–µ
                            # ë§ˆì§€ë§‰ìœ¼ë¡œ ê°ì§€ëœ direction_light ê°ì²´ë“¤ë¡œ ê°•ì œ ìœ„ì¹˜ ê¸°ì–µ
                            if node.last_detected_objects:
                                direction_objects = [obj for obj in node.last_detected_objects if obj.get('class_name') == 'direction_light']
                                if len(direction_objects) == 2:
                                    node.get_logger().info(f"ğŸ”¥ [MANUAL] Lí‚¤ë¡œ ê°•ì œ ìœ„ì¹˜ ê¸°ì–µ ì‹œë„! ë°©í–¥ë“± {len(direction_objects)}ê°œ ê°ì§€ë¨")
                                    # ì¢Œí‘œ ì •ë³´ ì¶œë ¥
                                    for i, obj in enumerate(direction_objects):
                                        node.get_logger().info(f"ğŸ”¥ [MANUAL] ë°©í–¥ë“±[{i}]: center={obj['center']}, bbox={obj['bbox']}")
                                    success = node._update_remembered_positions(direction_objects)
                                    node.get_logger().info(f"ğŸ”¥ [MANUAL] ê°•ì œ ìœ„ì¹˜ ê¸°ì–µ ê²°ê³¼: {success}")
                                elif len(direction_objects) == 0:
                                    node.get_logger().warn("ğŸ”¥ [MANUAL] ë°©í–¥ë“±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                                else:
                                    node.get_logger().warn(f"ğŸ”¥ [MANUAL] ë°©í–¥ë“±ì´ 2ê°œê°€ ì•„ë‹˜: {len(direction_objects)}ê°œ")
                                    for i, obj in enumerate(direction_objects):
                                        node.get_logger().info(f"ğŸ”¥ [MANUAL] ë°©í–¥ë“±[{i}]: center={obj['center']}")
                            else:
                                node.get_logger().warn("ğŸ”¥ [MANUAL] ë§ˆì§€ë§‰ ê°ì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤")
                        elif key != 255 and key != -1:  # ë‹¤ë¥¸ í‚¤ê°€ ëˆŒë ¸ì„ ë•Œ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì œì™¸)
                            if 32 <= key <= 126:
                                node.get_logger().info(f"'{chr(key)}' í‚¤ ëˆŒë¦¼")
                                node.get_logger().info("ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤:")
                                node.get_logger().info("   R(ì¶”ì ì‹œë®¬ë ˆì´ì…˜), T(ì¶”ì ì´ë²¤íŠ¸), G(ë“±ë¡ì™„ë£Œ)")
                                node.get_logger().info("   B(ë²„íŠ¼ì •ë³´), M(ìƒíƒœí™•ì¸), A(ArUcoí…ŒìŠ¤íŠ¸)")
                                node.get_logger().info("   F(ì¢Œìš°ë°˜ì „), C(ì‹ ë¢°ë„), D(ìœ„ì¹˜ë¦¬ì…‹), L(ìœ„ì¹˜ê¸°ì–µ), ESC(ì¢…ë£Œ)")
                            else:
                                node.get_logger().info(f"í‚¤ ì½”ë“œ {key} ëˆŒë¦¼")
                            
                except Exception as e:
                    node.get_logger().error(f"í”„ë ˆì„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    time.sleep(0.1)
                
                # GUI ì²˜ë¦¬ ì™„ë£Œ í›„ì— ROS2 ì½œë°±ì„ ë¹„ì¤‘ë‹¨ì ìœ¼ë¡œ ì²˜ë¦¬
                try:
                    rclpy.spin_once(node, timeout_sec=0.001)  # 1msë§Œ
                except Exception as ros_error:
                    if frame_count % 1000 == 1:
                        node.get_logger().warning(f"ROS2 ì½œë°± ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {ros_error}")
                    
        except KeyboardInterrupt:
            node.get_logger().info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
        finally:
            # ì •ë¦¬
            if hasattr(node, 'camera_manager'):
                node.camera_manager.cleanup_all_cameras()
            
            # GUI ìœˆë„ìš° ì •ë¦¬ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ)
            if hasattr(node, 'headless_mode') and not node.headless_mode:
                cv2.destroyAllWindows()
            node.destroy_node()
            
    except RuntimeError as e:
        print(f"ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("í•´ê²° ë°©ë²•:")
        print("   1. Astra ì¹´ë©”ë¼ê°€ USBì— ì œëŒ€ë¡œ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        print("   2. OpenNI2ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        print("   3. ì¹´ë©”ë¼ ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        print("   4. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ê³  ìˆì§€ ì•Šì€ì§€ í™•ì¸")
    except Exception as e:
        print(f"ë…¸ë“œ ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")
        import traceback
        print(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
    finally:
        try:
            if rclpy.ok():
                rclpy.shutdown()
        except Exception as e:
            pass

if __name__ == '__main__':
    main() 