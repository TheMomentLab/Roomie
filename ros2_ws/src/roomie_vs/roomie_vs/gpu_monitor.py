#!/usr/bin/env python3

import os
import sys
import time
import threading
from typing import Optional, Callable

try:
    import pynvml
    PYNVML_AVAILABLE = True
except ImportError:
    PYNVML_AVAILABLE = False

class GPUResourceMonitor:
    """GPU ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ë° ìë™ ì œì–´ í´ë˜ìŠ¤"""
    
    def __init__(self, logger, max_memory_mb: int = 4096, check_interval: float = 5.0):
        self.logger = logger
        self.max_memory_mb = max_memory_mb  # GPU ë©”ëª¨ë¦¬ ì œí•œ (MB)
        self.check_interval = check_interval  # ëª¨ë‹ˆí„°ë§ ì£¼ê¸° (ì´ˆ)
        
        # GPU ëª¨ë‹ˆí„°ë§ ìƒíƒœ
        self.monitoring = False
        self.monitor_thread = None
        self.gpu_available = False
        self.handle = None
        
        # ì½œë°± í•¨ìˆ˜ë“¤
        self.on_memory_exceeded: Optional[Callable] = None  # ë©”ëª¨ë¦¬ ì´ˆê³¼ ì‹œ í˜¸ì¶œ
        self.on_gpu_error: Optional[Callable] = None  # GPU ì˜¤ë¥˜ ì‹œ í˜¸ì¶œ
        
        # í†µê³„
        self.violation_count = 0
        self.max_memory_used = 0
        
        self._initialize_gpu()
    
    def _initialize_gpu(self):
        """GPU ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™”"""
        if not PYNVML_AVAILABLE:
            self.logger.warning("âŒ pynvml ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GPU ëª¨ë‹ˆí„°ë§ ë¹„í™œì„±í™”")
            return
        
        try:
            pynvml.nvmlInit()
            self.handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # ì²« ë²ˆì§¸ GPU
            
            # GPU ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            raw_name = pynvml.nvmlDeviceGetName(self.handle)
            # ìµœì‹  pynvmlì—ì„œëŠ” ì´ë¯¸ stringìœ¼ë¡œ ë°˜í™˜ë  ìˆ˜ ìˆìŒ
            if isinstance(raw_name, bytes):
                name = raw_name.decode('utf-8')
            else:
                name = str(raw_name)
            memory_info = pynvml.nvmlDeviceGetMemoryInfo(self.handle)
            total_memory_mb = memory_info.total // (1024 * 1024)
            
            self.gpu_available = True
            self.logger.info(f"ğŸ® GPU ëª¨ë‹ˆí„°ë§ í™œì„±í™”: {name}")
            self.logger.info(f"ğŸ“Š ì´ GPU ë©”ëª¨ë¦¬: {total_memory_mb}MB, ì œí•œ: {self.max_memory_mb}MB")
            
        except Exception as e:
            self.logger.warning(f"âŒ GPU ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.gpu_available = False
    
    def get_gpu_memory_usage(self) -> dict:
        """í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (MB ë‹¨ìœ„)"""
        if not self.gpu_available:
            return {"used": 0, "free": 0, "total": 0, "utilization": 0}
        
        try:
            memory_info = pynvml.nvmlDeviceGetMemoryInfo(self.handle)
            utilization = pynvml.nvmlDeviceGetUtilizationRates(self.handle)
            
            return {
                "used": memory_info.used // (1024 * 1024),  # MB
                "free": memory_info.free // (1024 * 1024),  # MB  
                "total": memory_info.total // (1024 * 1024),  # MB
                "utilization": utilization.gpu  # GPU ì‚¬ìš©ë¥  %
            }
        except Exception as e:
            self.logger.error(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"used": 0, "free": 0, "total": 0, "utilization": 0}
    
    def start_monitoring(self):
        """GPU ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if not self.gpu_available:
            self.logger.warning("âš ï¸ GPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•˜ì—¬ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        if self.monitoring:
            self.logger.warning("âš ï¸ GPU ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return True
        
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        
        self.logger.info(f"ğŸ” GPU ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì œí•œ: {self.max_memory_mb}MB, ì£¼ê¸°: {self.check_interval}ì´ˆ)")
        return True
    
    def stop_monitoring(self):
        """GPU ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        if not self.monitoring:
            return
        
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2.0)
        
        self.logger.info(f"ğŸ›‘ GPU ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ (ìœ„ë°˜ íšŸìˆ˜: {self.violation_count})")
    
    def _monitor_loop(self):
        """GPU ëª¨ë‹ˆí„°ë§ ë©”ì¸ ë£¨í”„"""
        while self.monitoring:
            try:
                memory_info = self.get_gpu_memory_usage()
                used_memory = memory_info["used"]
                utilization = memory_info["utilization"]
                
                # ìµœëŒ€ ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
                if used_memory > self.max_memory_used:
                    self.max_memory_used = used_memory
                
                # ë©”ëª¨ë¦¬ ì œí•œ ì´ˆê³¼ í™•ì¸
                if used_memory > self.max_memory_mb:
                    self.violation_count += 1
                    self.logger.warning(f"ğŸš¨ GPU ë©”ëª¨ë¦¬ ì œí•œ ì´ˆê³¼! ì‚¬ìš©ëŸ‰: {used_memory}MB > ì œí•œ: {self.max_memory_mb}MB")
                    self.logger.warning(f"ğŸš¨ ìœ„ë°˜ íšŸìˆ˜: {self.violation_count}, GPU ì‚¬ìš©ë¥ : {utilization}%")
                    
                    # ì½œë°± í˜¸ì¶œ
                    if self.on_memory_exceeded:
                        try:
                            self.on_memory_exceeded(used_memory, self.max_memory_mb, self.violation_count)
                        except Exception as e:
                            self.logger.error(f"ë©”ëª¨ë¦¬ ì´ˆê³¼ ì½œë°± ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                
                else:
                    # ì •ìƒ ìƒíƒœ ë¡œê¹… (ê°€ë”ì”©ë§Œ)
                    if self.violation_count % 12 == 0:  # 1ë¶„ë§ˆë‹¤ (5ì´ˆ * 12)
                        self.logger.debug(f"ğŸ“Š GPU ìƒíƒœ: ë©”ëª¨ë¦¬ {used_memory}MB/{memory_info['total']}MB, ì‚¬ìš©ë¥  {utilization}%")
                
                time.sleep(self.check_interval)
                
            except Exception as e:
                self.logger.error(f"GPU ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                if self.on_gpu_error:
                    try:
                        self.on_gpu_error(e)
                    except:
                        pass
                time.sleep(self.check_interval)
    
    def set_memory_exceeded_callback(self, callback: Callable):
        """ë©”ëª¨ë¦¬ ì´ˆê³¼ ì‹œ í˜¸ì¶œí•  ì½œë°± í•¨ìˆ˜ ì„¤ì •"""
        self.on_memory_exceeded = callback
        self.logger.info("ğŸ”§ GPU ë©”ëª¨ë¦¬ ì´ˆê³¼ ì½œë°± ì„¤ì •ë¨")
    
    def set_gpu_error_callback(self, callback: Callable):
        """GPU ì˜¤ë¥˜ ì‹œ í˜¸ì¶œí•  ì½œë°± í•¨ìˆ˜ ì„¤ì •"""
        self.on_gpu_error = callback
        self.logger.info("ğŸ”§ GPU ì˜¤ë¥˜ ì½œë°± ì„¤ì •ë¨")
    
    def get_statistics(self) -> dict:
        """GPU ëª¨ë‹ˆí„°ë§ í†µê³„ ë°˜í™˜"""
        current_memory = self.get_gpu_memory_usage()
        return {
            "monitoring": self.monitoring,
            "gpu_available": self.gpu_available,
            "violation_count": self.violation_count,
            "max_memory_used": self.max_memory_used,
            "current_memory": current_memory,
            "memory_limit": self.max_memory_mb
        }
    
    def __del__(self):
        """ì†Œë©¸ì - ëª¨ë‹ˆí„°ë§ ì •ë¦¬"""
        self.stop_monitoring()
        if PYNVML_AVAILABLE and self.gpu_available:
            try:
                pynvml.nvmlShutdown()
            except:
                pass 